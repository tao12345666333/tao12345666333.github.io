<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kubernetes on MoeLove</title><link>https://moelove.info/tags/Kubernetes/</link><description>Recent content in Kubernetes on MoeLove</description><generator>Hugo -- gohugo.io</generator><language>zh</language><lastBuildDate>Sun, 08 Mar 2020 22:47:41 +0800</lastBuildDate><atom:link href="https://moelove.info/tags/Kubernetes/index.xml" rel="self" type="application/rss+xml"/><item><title>K8S 生态周报| Docker v19.03.7 发布</title><link>https://moelove.info/2020/03/08/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Docker-v19.03.7-%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 08 Mar 2020 22:47:41 +0800</pubDate><guid>https://moelove.info/2020/03/08/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Docker-v19.03.7-%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Docker v19.03.7 发布 我在之前的两次周报 《K8S 生态周报| Docker CE v19.03.6 正式发布》 和《K8S 生态周报| containerd v1.2.13 发布》 中已经介绍过了 Docker CE v19.03.6 在单核机器上 会由于 containerd 中的一个 bug 导致任务 hang 住。本周发布的 v19.03.7 已经将默认的 containerd 版本升级至 v1.2.13 ，该版本中包含了对此 bug 的修复。
此外这个版本中还包含了一个小的优化，可以让 docker stats 比之前的启动速度更快一点，直观上的感受目前可能还不是很明显。但如果是针对于某些特殊需求，需要采集使用量分析的时候，那就会比较明显了。
注意 升级到此版本后, 如果你在使用 overlay2 存储驱动时，可能会有人在执行 docker info 时，Backing Filesystem 那一栏显示会有点问题，这是因为代码里面移除了一些文件系统的检查逻辑，导致赋值也有些问题，之后会做修复。
你可能会得到类似下面的输出，不用太紧张。
(MoeLove) ➜ ~ docker info --format '{{ index .DriverStatus 0 }}' [Backing Filesystem &amp;lt;unknown&amp;gt;] 更多信息请参考 ReleaseNote</description></item><item><title>K8S 生态周报| rkt 项目正式归档并宣布终止</title><link>https://moelove.info/2020/02/29/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-rkt-%E9%A1%B9%E7%9B%AE%E6%AD%A3%E5%BC%8F%E5%BD%92%E6%A1%A3%E5%B9%B6%E5%AE%A3%E5%B8%83%E7%BB%88%E6%AD%A2/</link><pubDate>Sat, 29 Feb 2020 12:45:36 +0800</pubDate><guid>https://moelove.info/2020/02/29/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-rkt-%E9%A1%B9%E7%9B%AE%E6%AD%A3%E5%BC%8F%E5%BD%92%E6%A1%A3%E5%B9%B6%E5%AE%A3%E5%B8%83%E7%BB%88%E6%AD%A2/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
rkt 项目正式归档并宣布终止 rkt 项目我在之前的周报《K8S 生态周报| rkt 项目正式被 CNCF 归档》 就已经详细介绍过了，这里不再赘述。
从去年 rkt 项目正式被 CNCF 归档后，直到现在 rkt 项目的维护者们也终于在 GitHub 上归档该项目，并宣布此项目正式终止。
公告信息请参考 rkt/rkt@bbd90a1 。
再次感谢 rkt 在容器生态领域做出的贡献！（大概以后也不会再提到 rkt 了）
Kubernetes NGINX Ingress 发布 v0.30.0 Kuberentes NGINX Ingress 近期相继发布了 v0.29 和 v0.30 两个版本，变更较频繁。主要值得注意的内容如下：
NGINX 升级到了 v1.17.8 版本； 允许 ExternalName 类型的 service 有不同的 port 和 targetPort（这是一个 bugfix）; 顺便聊个无关紧要的内容，这个版本中有一个 commit 比较有趣，请看 #5041 。这个 commit 其实是由一个 bot 生成的，专门用来做图片优化的应用， 通过这个 ImgBot 使得该项目中图片资源的体积减少了 36.</description></item><item><title>K8S 生态周报| containerd v1.2.13 发布</title><link>https://moelove.info/2020/02/23/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-containerd-v1.2.13-%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 23 Feb 2020 11:56:55 +0800</pubDate><guid>https://moelove.info/2020/02/23/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-containerd-v1.2.13-%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
containerd v1.2.13 发布 上周的 K8S 生态周报 中，我在 Docker CE v19.03.6 正式发布 的部分，介绍了 Docker v19.03.6 在单核的机器/虚拟机中，可能会由于 containerd 的一个 bug 导致任务 hang 住。
本周 containerd v1.2.13 发布了，此版本中已经包含了对该内容的修复。
如果受到此问题影响的用户， 可直接下载安装使用 containerd v1.2.13 以修复此问题。
近期 Docker v19.03.7 也将发布，将会默认使用 containerd v1.2.13 ，届时直接重装/升级均可规避此问题。
Helm v3.1.1 发布 上周 Helm 3.1.0 刚发布便马上迎来了 v3.1.1 版本，这是一个 bugfix 版本，包含了几个主要的修复：
修复了 helm list 不能正确抛出错误信息的问题，原因是代码中有个错误未被捕获； 现在，如果设置了 --wait 参数时，service 不会等待 externalIPs 便可以返回了，可规避一些类似 helm upgrade --wait 时可能超时的问题； 上游进展 #87714 kubectl 的 --server-dry-run 被标记为废弃，并且可以通过使用 --dry-run=server 替代。并且 kubectl 的 --dry-run 参数接收的值，也变成了 client, server 以及 none； #86810 kubeadm config images list 实现了结构化输出，支持文本，JSON，YAML 和 GO 模板等。（我个人认为，这个功能不错的，但目前我还没想到什么情况下我会需要它）； #87975 kubeadm upgrade node config 从 v1.</description></item><item><title>K8S 生态周报| Helm v3.1.0 正式发布</title><link>https://moelove.info/2020/02/15/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Helm-v3.1.0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</link><pubDate>Sat, 15 Feb 2020 23:12:46 +0800</pubDate><guid>https://moelove.info/2020/02/15/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Helm-v3.1.0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Docker CE v19.03.6 正式发布 在上次的周报 K8S 生态周报| Docker v19.03.6-rc2 发布 中，我已经介绍了 Docker v19.03.6 中包含的主要更新了。
这里我要额外增加一点提醒：
如果你在使用单核的机器/虚拟机，在升级 v19.03.6 后，可能会由于 containerd 中的一个 bug 而导致任务 hang 住
比较常见的一个可能出错的地方就是使用 GitLab.com 的共享 runner （单核的 vm），如果你没有将 dind（Docker In Docker）镜像指定为具体的版本号，而是使用类似 docker:dind 这样的 tag 时，你可能已经遇到相关的问题了。推荐当前固定为 docker:19.03.5-dind ，待后续修正。
containerd v1.2.13 中将会包含此修复（尚未发布），或者临时解决办法可以是暂时降级 containerd 。
当 container 发布新版本后，可以通过重新安装/升级 containerd 来解决此问题。
Helm v3.1.0 正式发布 自 2019 年 11 月 13 日 Helm 正式发布 v3.0.0 至今已过了三个月，Helm 终于迎来了新的特性版本， v3.</description></item><item><title>K8S 生态周报| Docker v19.03.6-rc2 发布</title><link>https://moelove.info/2020/02/09/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Docker-v19.03.6-rc2-%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 09 Feb 2020 17:14:37 +0800</pubDate><guid>https://moelove.info/2020/02/09/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Docker-v19.03.6-rc2-%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Docker v19.03.6-rc2 发布 自 2019 年 11 月 15 日 Docker v19.03.5 发布后，Docker Inc. 包括社区都发生了不少的变化。
v19.03.6 将会是 v19.03 系列的下一个 bugfix 版本。在此版本中，有几个比较值得注意的内容：
buildkit: 修复了在触发 ONBUILD 规则之后，未清理掉 ONBUILD 规则的问题。对于依赖 ONBUILD 指令，且使用 buildkit 的用户而言是个重要修复； buildkit: 修复了启用了 userns 时，可能导致权限错误的问题； 使用了 libnetwork 的短 ID, 以避免遇到 UNIX_PATH_MAX 的错误; 说到这个问题，其实也蛮有趣的，可能不少人都遇到过类似的问题。当然我也想在这个 UNIX_PATH_MAX 的问题上稍微多聊一点。
这个问题其实在四五年前我在 Docker 项目中其他的部分就遇到过，解决起来也简单就是缩短路径长度即可。但你可能会好奇，要缩短到什么程度呢？多长是合理值呢？
其实这个问题要深究的话，背后有蛮多历史的，这里我先跳过。我主要说下目前的限制是什么，这个限制可以在 Linux 的源码中找到的。
// include/uapi/linux/un.h #ifndef _LINUX_UN_H #define _LINUX_UN_H #include &amp;lt;linux/socket.h&amp;gt; #define UNIX_PATH_MAX 108 struct sockaddr_un { __kernel_sa_family_t sun_family; /* AF_UNIX */ char sun_path[UNIX_PATH_MAX]; /* pathname */ }; #define SIOCUNIXFILE (SIOCPROTOPRIVATE + 0) /* open a socket file with O_PATH */ #endif /* _LINUX_UN_H */ 可以看到现在头文件中定义的是 108 。（ 注意我此处使用的是 Linux 5.</description></item><item><title>使用 Kind 在离线环境创建 K8S 集群</title><link>https://moelove.info/2020/02/05/%E4%BD%BF%E7%94%A8-Kind-%E5%9C%A8%E7%A6%BB%E7%BA%BF%E7%8E%AF%E5%A2%83%E5%88%9B%E5%BB%BA-K8S-%E9%9B%86%E7%BE%A4/</link><pubDate>Wed, 05 Feb 2020 12:14:04 +0800</pubDate><guid>https://moelove.info/2020/02/05/%E4%BD%BF%E7%94%A8-Kind-%E5%9C%A8%E7%A6%BB%E7%BA%BF%E7%8E%AF%E5%A2%83%E5%88%9B%E5%BB%BA-K8S-%E9%9B%86%E7%BE%A4/</guid><description>Kind 是我很喜欢也一直在参与的项目，我计划将 Kind 相关的文章写成一个系列。这是第二篇。
背景 Kind 是 Kubernetes In Docker 的缩写，顾名思义是使用 Docker 容器作为 Node 并将 Kubernetes 部署至其中的一个工具。现在包括 Kubernetes 自身在内的很多云原生基础项目都将 Kind 应用于自身的 e2e 测试或项目的入门示例中。
默认情况下使用 Kind 创建 Kubernetes 集群，只需要先安装好 Kind 执行 kind create cluster 便可， Kind 会自动下载所需的 Docker 镜像，并启动集群。
但是，在某些情况下，我们也会有需要在离线环境中启动 Kubernetes 集群的需求。本篇文章我来为你介绍两种使用 Kind 在离线环境创建 Kubernetes 集群的方式。
使用预构建镜像 Kind 在每次发布版本时，会同时构建并发布默认使用的镜像，目前托管在 Docker Hub 上。建议你使用在每次 ReleaseNote 中指定了 shasum 的镜像。
当你在离线环境中想要使用 Kind 预构建的镜像创建集群时，你可以在任意可联网的机器上或目标机器上有网络的情况下，提前下载该镜像，并拷贝至需要创建集群的目标机器上。
如果你的机器上已经安装了 Docker，那可以直接使用 docker pull 命令下载镜像：
(MoeLove) ➜ ~ docker pull kindest/node:v1.</description></item><item><title>K8S 生态周报| Rook v1.2.3 发布</title><link>https://moelove.info/2020/02/02/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Rook-v1.2.3-%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 02 Feb 2020 17:45:03 +0800</pubDate><guid>https://moelove.info/2020/02/02/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Rook-v1.2.3-%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Rook v1.2.3 发布 Rook 昨天发布了 v1.2.3 版本，此版本中仍然重点是对 Ceph 相关的内容做了改进。值得关注的内容如下：
允许使用 Ceph-CSI v2.0.0 驱动了，不过默认还是使用 CSI v1.2.2 ； 修正了 prepare job 资源配额的处理逻辑； 改善 ceph-volume 的日志输出，暴露每个 pvc ceph-volume 日志； 修正了 CSI 驱动的垃圾回收机制，这个问题根本原因是资源的 OwnerReference 所使用的 API 错了。可能导致的情况是，某些情况下 CSI 相关的 Pod 被清掉了； 对此版本感兴趣的朋友可参考其 ReleaseNote
CoreDNS v1.6.7 发布 本周 CoreDNS v1.6.7 发布了，是个小版本的更新，需要注意的更新如下：
plugin/{kubernetes, etcd}：允许通过 CNAME 解析 TXT 记录。这个更新是为 backend_lookup.go 中的 TXT 方法增加了一个参数，需要注意的是当前已经更新了 kubernetes 和 etcd 插件的相关调用，如果有自己实现或者使用其他第三方 plugin 的话，需要注意。 其他更新请参考 ReleaseNote</description></item><item><title>K8S 生态周报| runc v1.0.0-rc10 正式发布</title><link>https://moelove.info/2020/01/26/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-runc-v1.0.0-rc10-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 26 Jan 2020 10:21:24 +0800</pubDate><guid>https://moelove.info/2020/01/26/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-runc-v1.0.0-rc10-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kubernetes 发布 v1.18.0-alpha.2 版本 这个版本包含了不少变更，这里列一些我个人感觉比较重要的内容：
修复了一个 kubectl apply --prune 时，未接收 kubectl 指定 namespace 的问题 #85357; 为 kubeadm 在 pull image 时增加了自动重试，默认是 5 次； kubelet 的一些 metrics 标记过期； 可以为 kubelet 传递 --node-ip :: 默认设置 IPv6 地址为主地址了； 关于此版本的其他变更，请查看 ReleaseNote
runc v1.0.0-rc10 正式发布 runc 想必大家不会太陌生，关注我的朋友大多都看到过我之前几篇关于 runc 的文章，这里不再赘述。
本次发布的版本最主要的目的是修复 CVE-2019-19921 ，由于 runc 是个基础软件，目前也已经将 containerd 和 Docker 做了相应的更新升级以应对此漏洞。
关于这个漏洞的修复主要就是避免挂载 /proc 到非目录，以避免攻击者利用软链的方式利用 runc 将 /proc 挂载到其他的地方实现攻击。
另一个重要变更是在 runc 中增加了 cgroups2 的支持。</description></item><item><title>K8S 生态周报| Kind v0.7.0 正式发布</title><link>https://moelove.info/2020/01/19/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Kind-v0.7.0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 19 Jan 2020 08:24:28 +0800</pubDate><guid>https://moelove.info/2020/01/19/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Kind-v0.7.0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kind (Kubernetes in Docker) 正式发布 v0.7.0 Kind (Kubernetes in Docker) 是我很喜欢也一直在参与的项目，现在在 GitHub 上有 4.3k 的 star ，本周正式发布了 v0.7.0 我们一起来看看在此版本中增加了哪些有用的特性。
重大变更 Kubernetes 版本升级，现在默认的 Kubernetes 版本升级为 v1.17.0 , 在 kind v0.6+ 时候默认的 Kubernetes 版本是 v1.16.3; 使用 kind v0.7.0 构建的镜像有很多改进，需要至少 v0.5+ 版本才能保持兼容，如果是想要使用在 v0.7 版本中新增的全部特性，建议同时升级 kind 二进制文件以及更新 node 镜像; 新特性增加 通过集成 rancher.io/localhost-path 提供了开箱即用的动态存储卷的支持； 提供了使用 Ingress 暴露部署在 Kind 中服务的多种方式的文档，包括 Contour 和 NGINX Ingress ; 更新了相关的依赖，包括修复 CNI portmap 插件以提高稳定性； 修复问题 提升日志消息的可读性; 修正 kind load 镜像到 node 节点上之后的检查逻辑； 当默认的 $HOME/.</description></item><item><title>K8S 生态周报| Istio v1.4.3 发布</title><link>https://moelove.info/2020/01/12/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Istio-v1.4.3-%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 12 Jan 2020 20:18:09 +0800</pubDate><guid>https://moelove.info/2020/01/12/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Istio-v1.4.3-%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Prometheus v2.15.2 发布 本周 Prometheus 发布了 v2.15.2 版本，其修复了两个 TSDB 相关的问题。
修复对 2.1.0 之前版本构建的 TSDB 块的支持，这个问题直接影响的是那些直接从 2.1.0 版本之前直接升级到 2.15 的用户，根本原因是在 2.1.0 版本加入的一个对 key 排序的特性； 修复了 TSDB 在 Windows 下的压缩问题； 其他变化，感兴趣的朋友可以参看其 ReleaseNote
Istio v1.4.3 发布 Istio 发布了 v1.4.3 版本，带来了众多 bugfix 和改进，我们来具体看看：
修复了 Mixer 为 secret 创建大量 watcher 可能导致 Kubernetes api-server OOM 的问题 #19481 ; 修复了注入相关的模板。当 POD 有多个 container 但 container 未暴露端口时，istio-proxy 无法启动的问题。#18594；</description></item><item><title>K8S 生态周报| 终端下的 K8S 资源树查看器</title><link>https://moelove.info/2020/01/05/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-%E7%BB%88%E7%AB%AF%E4%B8%8B%E7%9A%84-K8S-%E8%B5%84%E6%BA%90%E6%A0%91%E6%9F%A5%E7%9C%8B%E5%99%A8/</link><pubDate>Sun, 05 Jan 2020 09:52:30 +0800</pubDate><guid>https://moelove.info/2020/01/05/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-%E7%BB%88%E7%AB%AF%E4%B8%8B%E7%9A%84-K8S-%E8%B5%84%E6%BA%90%E6%A0%91%E6%9F%A5%E7%9C%8B%E5%99%A8/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
上游进展 Kubernetes v1.17.0 中，如果将 CIDR 设置为低于 /16 位，则 IP 分配器可能会报错。这个问题当前已经在 #86534中修复，将随着 v1.17.1 发布，如果尚未升级至 v1.17.0 的朋友可以稍后； api-server 的 bind-address 最近稍作了调整，如果未指定或者使用 0.0.0.0 或 :: 则会监听本地的所有可用的地址。 项目推荐 kubectl-tree 是一个用于在终端内以树形结构展示 Kubernetes 资源的 Kubectl 插件。（已经登上了 GitHub 的趋势榜）
使用效果如图：
在我的终端下，它不能对齐，不过我还没来得及具体去看原因。
新项目：APISIX-ingress-controller 最近看到一个为 Apache APISIX 实现 Ingress Controller 的项目 APISIX-ingress-controller
同时也看到了一篇文章: 为什么我们重新写了一个 k8s ingress controller 文章的作者解释了为何要重新写一个 Ingress Controller。
在我个人看来，多实现一种 Ingress Controller 对社区而言是好事儿，让大家有了更多的选择，另一方面，这个项目刚起步不久，如果有对实现 APISIX Ingress Controller 感兴趣的朋友可以尽早加入。
( 抛开此项目不谈，单纯谈写一个简单的自定义 Ingress Controller 其实比较简单，倒也挺有趣的，只不过在处理一些高级特性及处理大量请求时，不同的实现会有些区别。 推荐大家都尝试下</description></item><item><title>2019 小回顾</title><link>https://moelove.info/2020/01/01/2019-%E5%B0%8F%E5%9B%9E%E9%A1%BE/</link><pubDate>Wed, 01 Jan 2020 22:01:00 +0800</pubDate><guid>https://moelove.info/2020/01/01/2019-%E5%B0%8F%E5%9B%9E%E9%A1%BE/</guid><description>这篇文章起笔于上周（年底），不过工作比较忙，一直耽搁到今天（1 月 1 日）才抽出时间，索性就重写了。算是一篇岁岁念，想到什么就写点。
转眼已是 2020 年 1 月 1 日了，惯例做个小回顾。 2019 年发生了太多事情，非常值得好好回顾一下。每年的回顾不仅是对过去一年的总结，也是对新的一年做个计划。 依旧按照我每年的习惯，分别从工作和生活来聊聊。
工作 2019 年我做的事情，主要涉及以下几个方面：
Docker 容器化和 Kubernetes API Gateway CI/CD 存储 监控 告警信息收敛 也算是比较典型的云原生工程师的工作内容了，感谢同事们的支持和配合。
2019 年是云原生形势大好的一年，这一年整个行业内都发生了不小的变动，关注我每周推送的「k8s 生态周报」的小伙伴可能已经发现，周报中最多的内容是 K8S 生态中比较核心的软件的版本发布及功能变更或漏洞相关的信息。
为什么这类信息会这么多呢？主要还是因为 2019 年云原生或者说 Kubernetes 的普及越来越广泛，需求增多，场景愈发复杂，相应的像 Docker, Kubernetes, Prometheus 这类基础软件也就需要提供更多的特性支持，或者 bugfix 。所以我在这方面投入的时间也就更多一些。
此外，从 19 年 3 月底，我开始了每周 「k8s 生态周报」 的推送，直到今天共计推送了 41 篇周报，未曾落下，也积累了不少读者，感谢大家关注。
今年在 PyCon China 的角色从讲师变成了出品人，原本计划会有一个主题演讲，但是由于跟我的婚礼时间冲突了，所以未能参加。感谢 PyCon China 的一众小伙伴的谅解和支持。
在国庆假期结束后，我在 GitChat 上发布的专栏《Docker 核心知识必知必会》正式上线了，至今专栏内容已经更新了一半，按照 GitChat 的字数统计现在写了大概是 9w 字左右（这个统计包括了我之前发布的五篇 Chat 文章）。感谢我的小可爱一直督促我，感谢编辑们的辛苦，感谢读者的信任和支持。</description></item><item><title>K8S 生态周报| Prometheus v2.15.0 正式发布</title><link>https://moelove.info/2019/12/29/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Prometheus-v2.15.0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 29 Dec 2019 16:55:31 +0800</pubDate><guid>https://moelove.info/2019/12/29/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Prometheus-v2.15.0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Prometheus v2.15.0 正式发布 本周 Prometheus 发布了 v2.15.0 版本，这个版本在 TSDB 方面有诸多改进，以及提升了 PromQL 解析器的性能。
TSDB 方面主要是对内存使用相关的优化。
按照此版本中 对 PromQL 解析器相关变更的 PR，本次解析器性能的提升能达到之前的 7 倍。
同时，此版本中也存在一个 bug，可能会导致并发查询数据时，出现 checksum 不匹配的情况，最直接的影响就是 Grafana 的图表会显示不出来。
所以之后也快速发布了 v2.15.1 版本。建议如果使用 v2.15.0 的朋友可以快速升级至 v2.15.1 以规避此问题。
更多关于此版本的变更，请查看其 ReleaseNote
Rancher v2.4.0-alpha1 发布 Rancher 本周发布了 v2.4.0-alpha1 , 此版本中在用户角色方面有两个挺不错的改进。
管理员可以自定义全局范围内的角色，并且可以让用户登录后默认使用该角色。 在使用外部认证方式时，管理员也可以默认设置属于某个组的用户，默认授予的权限。（比较类似于 Grafana 使用 LDAP 认证时，默认给用户设置的权限，但更灵活一些。) 更多关于此版本的信息，可参考其 ReleaseNote
题外话 这是今年 「K8S 生态周报」的最后一篇了，本篇中没有上游进展，上游最近的变更并不频繁，(大概是年底休假的原因）
从 2019 年 3 月份开始，便一直保持着每周更新。新的一年，我也将继续保持更新，与你分享我所接触到的 K8S 生态相关的每周值得推荐的一些信息。</description></item><item><title>K8S 生态周报| TUF 正式从 CNCF 毕业</title><link>https://moelove.info/2019/12/21/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-TUF-%E6%AD%A3%E5%BC%8F%E4%BB%8E-CNCF-%E6%AF%95%E4%B8%9A/</link><pubDate>Sat, 21 Dec 2019 16:55:31 +0800</pubDate><guid>https://moelove.info/2019/12/21/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-TUF-%E6%AD%A3%E5%BC%8F%E4%BB%8E-CNCF-%E6%AF%95%E4%B8%9A/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
TUF 正式从 CNCF 毕业 本周 The Update Framework (TUF) 正式从 CNCF 毕业，现在 TUF 的官方 Python 实现有 954 个 star ，142 个 fork 以及 43 位贡献者和 3525 次 commit 记录。
TUF 是从 CNCF 正式毕业的第 9 个项目，没记错的话也是至今为止唯一一个 star 数未上千就正式毕业的项目。不过 TUF 项目本身与其他项目不同，star 数也说明不了项目状态。
可能不少人觉得 TUF 项目的存在感很低，或是没有了解或使用过 TUF 项目，我姑且对它做一点介绍。
TUF 项目大概是十年前启动，并于 2017 年开始托管于 CNCF，它的主要目标正如它的名字一般，提供用于更新的框架，但它更重要的点在于它的安全性设计上。
它充分考虑到了各个环节可能出现的攻击，在提供更新功能的同时，也可以很好的保护现有程序或者是验证待更新版本的安全和可靠性。你可能想问它是如何做到这一点的，其实它主要是提供了一套标准规范，并在各个环节中增加了更多的元数据和相关的检查，包括签名信息，文件 hash ，元数据签名和过期时间等。
至于它的存在感嘛，不知道你是否有使用过 Docker Content Trust(DCT) 相关的功能，简单来说你可以当作就是 docker trust 所涉及到的相关功能，这其中的部分功能是构建在 Docker Notary 之上的，而 Docker Notary 则是使用 TUF 作为其基础安全框架的。(PS：Docker Inc 也已经将 Docker Notary 捐献给了 CNCF)</description></item><item><title>K8S 生态周报| Kubernetes v1.17 正式发布</title><link>https://moelove.info/2019/12/15/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Kubernetes-v1.17-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 15 Dec 2019 23:16:14 +0800</pubDate><guid>https://moelove.info/2019/12/15/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Kubernetes-v1.17-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kubernetes v1.17 正式发布 本周 Kubernetes v1.17 正式发布了，这是 2019 年的第四次发布，当然也是今年最后一次了。Kubernetes v1.17 包含 22 个增强功能，其中 14 个已经 stable ，4 个 beta 以及剩余 4 个 alpha 。
本次版本的主题是 Stability，在发布之时 Kubernetes 官方博客上已经有了一篇 Kubernetes 1.17: Stability 文章介绍，加上每周的周报中也都有上游进展的介绍，我在这里就不赘述了，稍微聊两三个我个人认为比较有用的内容。
rbac.authorization.k8s.io/v1alpha1 和 rbac.authorization.k8s.io/v1beta1 在 v1.17 被标记为废弃，并且在 v1.20 将被废弃； kubectl logs 增加了一个 --prefix 的选项，使用此选项可以在输出日志的时候展示一个前缀，格式是 [pod/name/containerName] 废弃和添加了一大堆 metrics， 感兴趣的朋友可以参考下 ReleaseNote 中 metrics 的部分 其余内容建议参考下完整的 ReleaseNote
Harbor v1.10 正式发布 Harbor 目前在 GitHub 有 10.</description></item><item><title>K8S 生态周报| containerd v1.3.2 发布</title><link>https://moelove.info/2019/12/09/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-containerd-v1.3.2-%E5%8F%91%E5%B8%83/</link><pubDate>Mon, 09 Dec 2019 01:09:07 +0800</pubDate><guid>https://moelove.info/2019/12/09/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-containerd-v1.3.2-%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kind v0.6.1 发布 本周 Kind Kubernetes In Docker 发布了 v0.6.1 版本，这是对 v0.6.0 的一个小 patch 版本，主要变更如下：
修复 containerd 在多 control plane 节点集群下的配置； 修正了 v1alpha4 API 中的 protocol 和 propagation 配置； 重新推送了镜像，v0.6.0 发布的时候忘记把 CNI 的镜像给预加载到 Node 镜像中了。现在的默认镜像是 kindest/node:v1.16.3@sha256:70ce6ce09bee5c34ab14aec2b84d6edb260473a60638b1b095470a3a0f95ebec 另外：Kind 的 Node 镜像在 DockerHub 上的下载量超过了 500K+ ，也说明其正在被广泛使用。（查看了下我自己发布的镜像中，下载量最多的也才只有 50K+）恭喜 Kind ！
containerd v1.3.2 发布 这是 containerd 在 v1.3 系列的第二个 patch 版本。 此版本主要的修复内容如下：
修复了一个容器 pid 的问题，会导致 Docker 卡住； 使用已缓存的状态而不是每次都执行 runc state 获取容器状态，相关影响是 Kubernetes 启用 liveness 和 readiness 探针会造成 CPU 飙高以及 Docker 容器使用健康检查也会造成 CPU 飙高； 综合来看，建议更新到此版本。</description></item><item><title>K8S 生态周报| Rancher v2.3.3 发布</title><link>https://moelove.info/2019/12/01/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Rancher-v2.3.3-%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 01 Dec 2019 10:15:15 +0800</pubDate><guid>https://moelove.info/2019/12/01/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Rancher-v2.3.3-%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Rancher v2.3.3 发布 本周 Rancher v2.3.3 发布，正式支持 Kubernetes v1.16，并将 v1.16.3 设置为 Rancher 默认的 Kubernetes 版本。
在此版本中，值得关注的修复如下：
修复了其不支持 kube-proxy 使用 IPVS 模式的问题; 已知问题：
Rancher v2.3.3 在开启 SELinux 的 RHEL 7.7 上使用 RHEL Docker 1.13 时，部署集群将导致失败； 更多关于此版本的特性及已知问题，请关注 ReleaseNote
上游进展 api-server 的 --runtime-config 可使用 api/beta=false 参数禁用所有内置的符合 v[0-9]+beta[0-9]+ 版本的 REST API；同时 --feature-gates 可使用 AllBeta=false 禁用所有内置的 beta 特性。#84304
downward API 为 Dualstack 增加了支持，参数名为 status.</description></item><item><title>K8S 生态周报| containerd v1.3.1 发布</title><link>https://moelove.info/2019/11/25/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-containerd-v1.3.1-%E5%8F%91%E5%B8%83/</link><pubDate>Mon, 25 Nov 2019 04:52:31 +0800</pubDate><guid>https://moelove.info/2019/11/25/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-containerd-v1.3.1-%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
containerd v1.3.1 发布 本周 containerd v1.3.1 发布了，我们一起看看其中值得注意的变化：
将 runc 更新至 v1.0.0-rc9 ， 其中包含了对 CVE-2019-16884 的修复，关于此漏洞的更多细节也可参考 https://github.com/opencontainers/runc/issues/2128 ； 修复了一个 v1.3.0 在拉取镜像遇到错误时，解包过程中的死锁问题 #3816 ; 定位了一个 containerd 在主机意外重启时，可能无法恢复损坏的镜像的问题，这个问题是比较有意思的，可能遇到这种情况的环境主要是 containerd 数据目录挂载至非根目录所在的盘中（多数环境中，系统盘的空间并不会很大，所以这种安装情况也算比较常见）。发生此问题的根本原因就在于重启后启动的时机不对（我倾向于这样表述，虽然实际的逻辑是 gc 删除了一些元数据，但它本身的行为是正常的）。所以修复的办法也比较简单， 如果你的 containerd 是使用 systemd 进行管理的，那么可以在 service 的配置文件的 After 块中增加 local-fs.target 的配置
local-fs.target 是 systemd 中一个特殊的单元，和 dbus.service 之类的很多单元类似，都属于特殊的那一类。具体来说它是用来集合本地文件系统挂载点的目标单元，听起来可能比较抽象。实际上就是 systemd-fstab-generator 会在所有本地文件系统挂载单元中添加 Before=local-fs.target 这一条，所以呢，当在 local-fs.target 之后执行的，就表示现在机器上的所有本地文件系统均已经正确挂载。(这也是我认为这个问题有意思的地方）
以上就是我认为在此版本中比较值得注意的点了，对此版本有兴趣的朋友可参阅 ReleaseNote
Kubernetes v1.17.0-rc.1 发布 虽然本周在举行 KubeCon 但 Kubernetes 的发布进度也没受太多影响，本周顺利发布了 v1.</description></item><item><title>K8S 生态周报| Helm v3.0.0 正式发布</title><link>https://moelove.info/2019/11/17/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Helm-v3.0.0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 17 Nov 2019 22:15:01 +0800</pubDate><guid>https://moelove.info/2019/11/17/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Helm-v3.0.0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Helm v3.0.0 正式发布 本周 Helm v3.0.0 正式发布了。在 Helm v3 发布第一个 alpha 版时，我就写了一篇 《初试 Helm 3》 在那篇文章中，我介绍了一些 Helm 3 的变化及特性。 现在正式版发布了，我们来正式的看看这个版本带来了哪些值得期待的内容。（PS：我不会在本文中介绍其全部特性，只会聊聊我感兴趣的，对全部特性感兴趣的朋友可以参考其官方文档 https://helm.sh/docs/ ）
移除 Tiller 这个特性想必在任何介绍 Helm 3 的文章中都会有提到，当然在我之前的文章中也有提到。在 Helm 2 时，对于启动了 RBAC 的 Kubernetes 集群而言，在生产环境中想要安全的管理 Tiller 的权限是比较麻烦的。
如果使用默认配置（简单来说也就是没啥特别的限制），那么上手很容易，但对于多租户的集群而言，就没那么安全了。
在 Helm 2 时期，为了简单或者说为了安全，我们可以使用 Tillerless 的方式，来避免在集群中安装 Tiller， 同时还可以正常的使用 Helm 的功能。（很早前计划写篇文章介绍一下这个经验来着，结果至今也还没有腾出时间写，现在 Helm 3 发布，也就不用写了，这里大概聊一下）
Tillerless 是什么含义呢？ 也就是在本地启动一个 Tiller 的服务，让它使用你本地的 KUBECONFIG 的配置文件与集群进行交互，而 Helm 在初始化时，只需要初始化 client 即可， 然后可通过 $HELM_HOST 变量控制连接到本地所启动的 Tiller， 之后便可以正常使用了。(每次部署完成后，将 Tiller 关闭即可)</description></item><item><title>2019 容器使用量报告</title><link>https://moelove.info/2019/11/17/2019-%E5%AE%B9%E5%99%A8%E4%BD%BF%E7%94%A8%E9%87%8F%E6%8A%A5%E5%91%8A/</link><pubDate>Sun, 17 Nov 2019 16:18:15 +0800</pubDate><guid>https://moelove.info/2019/11/17/2019-%E5%AE%B9%E5%99%A8%E4%BD%BF%E7%94%A8%E9%87%8F%E6%8A%A5%E5%91%8A/</guid><description>最近 sysdig 发布了 2019 容器使用报告，内容还比较有趣，特别来介绍一下。 关注公众号「Moelove」回复 docker2019 即可获取完整 PDF 报告。
关键信息 容器运行时 Docker 仍然是占据市场规模最大的容器运行时 （79%），而其他的，类似 rkt，lxc，podman 之类的市场占比微乎其微，甚至没有在报告中出现。
containerd 源自 Docker，现在也占据了一席之地；而对于 cri-o 报告中指出，之后市场份额可能会增加。
在我个人看来，近一年内 Docker 在企业生产环境的使用规模仍然会保持最大。
编排 可以看到 Kubernetes 遥遥领先，加上构建在 Kubernetes 之上的 OpenShift 和 Rancher ，这个霸主地位是非常稳了。
个人看来，近一年内，Kubernetes 的地位是不可能被撼动了，越来越多的企业也都会将技术栈迁移上去或者调研基于 Kubernetes 的云原生解决方案。
metrics Prometheus 已经成为事实标准，加上 Prometheus 作为 CNCF 毕业项目，以及围绕 CNCF 及云原生相关的各类基础软件等，都增加了各类 metrics，以及各类 exporter 越来越多，几乎可以涵盖生产中所需的各类 metrics 的需求了。
报警 这个图也可以从侧面反映出，节点的稳定性是大多数用户所关注的焦点。(无论上层如何调度，底层的稳定性依然很重要)
Pods 规模 多数集群属于中小规模的（也说明是个正在发展的阶段）
结论 容器仍然在应用交付上发挥着重要的作用，从去年发布报告（在公众号后台回复 docker2018 获取）以来，容器技术的采用率仍在加速，容器密度翻了一番，并且随着技术的成熟，也有了越来越多的成熟案例。
Prometheus 已经成为了云原生应用指标的标准化方案，容器编排技术 Kubernetes 成为了事实的标准，企业应该在 Kubernetes 上进行投资，以跟上技术潮流的步伐。
可以通过下面二维码订阅我的文章公众号【MoeLove】， 在公众号后台回复 docker2019 可下载完整报告。</description></item><item><title>K8S 生态周报| Vitess 正式从 CNCF 毕业</title><link>https://moelove.info/2019/11/10/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Vitess-%E6%AD%A3%E5%BC%8F%E4%BB%8E-CNCF-%E6%AF%95%E4%B8%9A/</link><pubDate>Sun, 10 Nov 2019 23:17:45 +0800</pubDate><guid>https://moelove.info/2019/11/10/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Vitess-%E6%AD%A3%E5%BC%8F%E4%BB%8E-CNCF-%E6%AF%95%E4%B8%9A/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Vitess 正式从 CNCF 毕业 CNCF（云原生计算基金会）在美国时间 2019 年 11 月 5 日宣布 Vitess 正式毕业了。
这是 CNCF 中第 8 个正式毕业的项目，最近的几次周报中，基本都会谈到关于 CNCF 项目毕业相关的信息（忙碌的 Q4 啊）
Vitess 最初由 YouTube 在 2010 年创建， 主要是用于 MySQL 横向扩展的数据库系统。据说 Vitess 一直为 YouTube 的所有数据库提供服务，国内貌似是京东使用比较多。
补一张 Vitess 的架构图：
最后，再次 恭喜 Vitess 顺利毕业!
Helm v2.16.0 正式发布 在之前的 K8S 生态周报| Helm v2 最后一个特性版本发布中，我介绍了 Helm 正式发布了 v2.15.0 作为 v2 版本的最后一个特性版本。
而本次发布的 v2.16.0 也确实没有主要的特性更新，都是一些问题修复和安全更新等；（在这次版本中是 13 个独立 committers 之一 :) ）</description></item><item><title>K8S 生态周报| Helm v2 爆出全版本漏洞</title><link>https://moelove.info/2019/11/03/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Helm-v2-%E7%88%86%E5%87%BA%E5%85%A8%E7%89%88%E6%9C%AC%E6%BC%8F%E6%B4%9E/</link><pubDate>Sun, 03 Nov 2019 23:17:05 +0800</pubDate><guid>https://moelove.info/2019/11/03/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Helm-v2-%E7%88%86%E5%87%BA%E5%85%A8%E7%89%88%E6%9C%AC%E6%BC%8F%E6%B4%9E/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Jaeger 顺利从 CNCF 毕业 CNCF（云原生计算基金会）在美国时间 2019 年 10 月 31 日宣布 Jaeger 正式毕业了。
这是 CNCF 中第 7 个正式毕业的项目，在上次周报的最后 我才刚提过一些项目提交了毕业申请，也同时以 Jaeger 为时一年的毕业申请申请举了个例子，没想到本周就毕业了。:)
Jaeger 最初是由 Uber 受 Dapper 和 OpenZipkin 启发，开源出来的一套分布式追踪系统。它主要可用于微服务架构下的分布式系统的根因分析，性能/延迟优化，服务依赖等方面。截至目前，它在 GitHub 上有 9.4k 的 star ，986 个 fork 以及 115 位贡献者。
它现在的存储后端主要就支持两种 Cassandra 3.4+ 和 Elasticsearch 5.x/6.x ，在这种系统中，随着服务规模的扩大，对后端存储的要求也会很高。另外，它有一套比较现代化的 UI，是基于 react 开发的。
整体来看的话，在使用上基本技术栈就会成为下面这样：
当然实际的架构也可能会因为基础设施而改变，比如说如果已经使用了 SkyWalking 的话，两者倒是也可以结合，大概就会变成下面这样：
不过，对于技术方案的选择，我个人建议是考虑实际需求，以及对各方案进行理性的权衡，否则的话，说不定什么时候就演变成了下面这样：（这个调用链虽然是可以走通的，但此处我是开个玩笑的， 请勿当真）
最后，再次恭喜 Jaeger 顺利毕业！
Helm 2 爆出全版本受影响的漏洞 本周 Helm 官方披露出来一个全版本 (Helm 在 2.</description></item><item><title>K8S 生态周报| Helm v3 最后一个beta版本发布</title><link>https://moelove.info/2019/10/27/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Helm-v3-%E6%9C%80%E5%90%8E%E4%B8%80%E4%B8%AAbeta%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 27 Oct 2019 23:01:41 +0800</pubDate><guid>https://moelove.info/2019/10/27/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Helm-v3-%E6%9C%80%E5%90%8E%E4%B8%80%E4%B8%AAbeta%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Helm v3.0.0-beta.5 发布 这将是最后一个 beta 版本，下一个版本将会是 Helm v3.0.0-rc.1 。现在主要精力都集中在一些 bugfix 上，也会有一些设计方面的事情还需要最终确认。
快速的看一下在此版本中新增的内容：
为了能提供更多子命令，现在 helm get 和 helm show 分别移动到了 helm get all 和 helm show all， 这是一个破坏性变更; 对 helm get values 增加了一个 --output 的选项，现在支持三种格式 table, json, yaml； helm test 新增了一个 --logs 的参数，这是在 Helm 2 中新增的； 对此版本感兴趣的朋友可以参考 ReleaseNote
Docker Hub 新增双因素认证功能 最近 Docker Hub 上线了 双因素认证 的功能。这个事情主要有两个方面的考虑：
DockerHub 希望能给用户更多的安全性，以及提供更完善的功能，以此来吸引个人用户/开源项目/组织/企业等使用； 这个事情其实也算是 4 月份被攻击事件的后续，在上个月的周报中，我也介绍了 Docker Hub 上线了 Access Token 的功能。而这次上线 2FA 更是进一步提高了其安全性！ 关于如何启用 2FA 可直接参考 Docker Hub 的文档 https://docs.</description></item><item><title>K8S 生态周报| Helm v2 最后一个特性版本发布</title><link>https://moelove.info/2019/10/21/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Helm-v2-%E6%9C%80%E5%90%8E%E4%B8%80%E4%B8%AA%E7%89%B9%E6%80%A7%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Mon, 21 Oct 2019 10:01:23 +0800</pubDate><guid>https://moelove.info/2019/10/21/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Helm-v2-%E6%9C%80%E5%90%8E%E4%B8%80%E4%B8%AA%E7%89%B9%E6%80%A7%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。 文末有活动，欢迎参与。
Docker 19.03.4 正式发布 在本周 Docker 发布了 19.03.4 版本，这个版本主要是为了修复上周周报中介绍的 DOCKER-USER iptables 链丢失的问题。
如果要升级 Docker 版本的话，可选择升级到此版本。
Kubernetes 修复全版本影响漏洞 上周周报中的 上游进展 部分，介绍了对 CVE-2019-11253 的修复，限制 YAML/JSON 的解码大小为 3M 。本周相继发布了以下版本，包含了对此漏洞的修复。
v1.13.12 v1.14.8 v1.15.5 v1.16.2 实际受此漏洞影响的版本是：
Kubernetes v1.0.0-1.12.x Kubernetes v1.13.0-1.13.11 (修复于 v1.13.12) Kubernetes v1.14.0-1.14.7 (修复于 v1.14.8) Kubernetes v1.15.0-1.15.4 (修复于 v1.15.5) Kubernetes v1.16.0-1.16.1 (修复于 v1.16.2) 建议对集群进行升级。 但是升级前，请务必先阅读完 https://github.com/kubernetes/kubernetes/issues/83253 的内容 在清楚了解不同版本的行为后，再做升级。
对此漏洞感兴趣的朋友，也可参阅社区公告
Prometheus Pushgateway v1.0 正式发布 Prometheus Pushgateway v1.</description></item><item><title>K8S 生态周报| Docker 19.03.3 DNS 不再区分大小写</title><link>https://moelove.info/2019/10/13/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Docker-19.03.3-DNS-%E4%B8%8D%E5%86%8D%E5%8C%BA%E5%88%86%E5%A4%A7%E5%B0%8F%E5%86%99/</link><pubDate>Sun, 13 Oct 2019 22:42:59 +0800</pubDate><guid>https://moelove.info/2019/10/13/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Docker-19.03.3-DNS-%E4%B8%8D%E5%86%8D%E5%8C%BA%E5%88%86%E5%A4%A7%E5%B0%8F%E5%86%99/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。 文末有活动，欢迎参与。
Docker 19.03.3 正式发布 在本周 Docker 发布了 19.03.3 版本，这个版本的变更内容 很重要，我会将主要内容都列出来。(上周周报介绍了 19.03.3-rc1 的一些情况)
已知问题 DOCKER-USER iptables 链丢失；如果你并不需要在 DOCKER-USER 链上定义规则的话，那你也并不会受此问题的影响。
临时解决办法：手动添加丢失的链，操作如下：
iptables -N DOCKER-USER iptables -I FORWARD -j DOCKER-USER iptables -A DOCKER-USER -j RETURN 这个问题会在 19.03.4 中进行修复, 很快会进行发布； 实际会把 libnetwork 中有问题的那段代码先去掉。 如果已经升级了此版本的用户，受到此问题影响的话，可以使用上述方式进行临时解决。
安全问题 将 runc 更新到了 v1.0.0-rc8-92-g84373aaa 这其中包含了 runc 中对 CVE-2017-18367 的修复，该漏洞的根本原因在于 libseccomp-golang 中一个错误的逻辑运算 ，有兴趣的朋友可以点开链接看看实际的修复代码，并且也可以发现该代码其实在 2017 年 4 月就已经合并进 libseccomp-golang 的主干中了，但实际上在今年 6 月在 runc 中才真正修复。 这个问题其实反映出来的是当我们在维护项目时，对自己所用的各种依赖需要有所了解和把握，整体来讲，尽可能避免依赖项过旧是个好事儿；并且安全问题非常值得关注。</description></item><item><title>Docker 核心知识必知必会</title><link>https://moelove.info/2019/10/08/Docker-%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/</link><pubDate>Tue, 08 Oct 2019 23:58:14 +0800</pubDate><guid>https://moelove.info/2019/10/08/Docker-%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/</guid><description>自 2013 年起，随着 Docker 的正式面世，容器技术迅速成为了基础技术领域中的热门。而在近两三年中，随着容器编排领域的混战结束，Kubernetes 已经成为了容器编排领域事实上的标准。
有一些人存在误解，认为 Kubernetes 的出现取代了 Docker。但事实上，Docker 与 Kubernetes 是相辅相成的。Kubernetes 使用 Docker 作为容器运行时，用来启动应用；当 Docker 容器规模变大时，自然是需要有容器编排工具进行管理的。引用最近一次的网络研讨会后的文章内容：
In fact, Kubernetes is better with Docker. And Docker is better with Kubernetes.
无论在使用 Docker 或是 Kubernetes 亦或者是使用基于这些技术的其他衍生技术时，都有可能会遇到一些意料之外的情况，当问题发生时，我们总是希望可以快速定位问题，并且从根本上解决问题。
一般情况下，上层的问题比较容易解决，但如果问题发生在运行时/Docker 或容器上时，如果没有系统性的知识，很难从根本上解决问题；当然，有些时候通过搜索引擎可以帮我们找到一些问题的解决办法，但如果不将其彻底搞懂，以后遇到类似问题可能还是没法快速解决。
我自 Docker 0.9 版本时开始学习和使用，自己踩过了很多坑，活跃在社区中，也帮别人解决了很多问题。现在我的新专栏《Docker 核心知识必知必会》正式上线了，共 51 节，从 7 个核心维度来 系统性 的讲解 Docker 容器技术的核心特性及原理，实践与源码相结合；部分内容会深入到 Linux 内核源码，以此来建立起从内核到 Docker 容器技术的知识体系。
我希望借由这个课程，将 Docker 容器技术的本质和思想与我在开发和运维 Docker 过程中对其原理和实践经验的总结讲清楚，并将结合着实践和核心特性的原理，加深对 Docker 容器技术的理解。
因此，我把课程划分成了三大模块：
Docker 入门: 这个模块分成了三篇内容，通过第一篇，带你了解 Docker 容器技术生态的发展脉络；第二篇，是为刚入门 Docker 的读者准备的，也是为后续章节进行铺垫；第三篇是很多读者或公司都常会困惑的问题，Docker 与 Linux 内核兼容性如何，要上生产环境该选择哪个版本？我会在这一篇中与你分享，让你不再困惑。</description></item><item><title>K8S 生态周报| runc v1.0.0-rc9 发布</title><link>https://moelove.info/2019/10/06/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-runc-v1.0.0-rc9-%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 06 Oct 2019 23:07:49 +0800</pubDate><guid>https://moelove.info/2019/10/06/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-runc-v1.0.0-rc9-%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
runc v1.0.0-rc9 发布 不知不觉，runc v1.0.0-rc9 于近日发布了。早先关注过我文章的朋友们应该看到过我从去年开始每次在 runc 新版本发布时都有专门写一篇文章进行介绍。这次版本的定位主要是修复 CVE-2019-16884 所以我也就不再单独写文章介绍了（另一个原因是现在在假期，还是多抽空陪陪家人）
先对 CVE-2019-16884 做个简单的介绍。这是一个中等级别的漏洞，其主要影响是 runc 源码中的 libcontainer/rootfs_linux.go 在文件挂载至 /proc 时，少做了一些检查，可绕过 AppArmor 的限制，所以可能导致被一些恶意镜像所利用。
主要的修复方式是将原先的 checkMountDestination 函数改写为 checkProcMount，并在其中添加了对源文件类型的判断，只允许 procfs 类型的文件挂载至 /proc 。
此漏洞影响到的范围是 runc 以及一些使用 runc 作为基础组件的容器管理软件。请尽快进行升级。
此版本的地址是：https://github.com/opencontainers/runc/releases/tag/v1.0.0-rc9
Docker v19.03.3-rc1 发布 自从 Docker 修改维护周期后，Docker 对软件的质量要求有了显著提高，每次版本发布前会经历多阶段的测试和回归，确保软件没有什么问题后才会发布正式版。
按现在的进度来看 v19.03.3 应该会在一两周内放出。新版本会将 containerd 升级至最新的 1.2.10 ，并修复了一个在 5.2 版本内核上 overlay2 文件系统挂载时的错误。
关于此版本感兴趣的朋友可以参考 ReleaseNote
上游进展 Kubernetes v1.17 已经进入发布周期，这个版本的发布周期会比较短，现在已经发布了 v1.17.0-alpha 版本，计划是在 12 月 9 日可以最终发布。(想想看，距现在也就两个月的时间，你的集群现在是哪个版本呢？)</description></item><item><title>K8S 生态周报| containerd v1.3 正式发布</title><link>https://moelove.info/2019/09/29/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-containerd-v1.3-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 29 Sep 2019 21:44:09 +0800</pubDate><guid>https://moelove.info/2019/09/29/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-containerd-v1.3-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
containerd v1.3.0 正式发布 在上个主版本（v1.2.0）后经过 11 个月，我们终于迎来了 containerd v1.3.0 的发布，当然这个版本也是 containerd 自 CNCF 毕业后的首个主版本。（关于 containerd 毕业的信息可参考我之前的文章）
在三周前 containerd v1.3.0-rc.0 发布时，我也提到过一些，现在我们来整体看一下。
增加了 Windows v2 的 runtime API， 同时移除了 Windows v1 API； 为修复 CVE-2019-16884 更新了 runc 依赖；
可配置的插件目录；
允许插件注册为一个 TCP Server ，通过这种机制其实可以做到很多的事情了；
增加了流式处理的插件，允许在解包的时候处理自定义资源类型（设计上考虑可使用此功能进行加解密相关的逻辑）；
支持跨仓库推送镜像；
新增了 devicemapper 的快照支持，然而需要注意的是 Docker 已经将 devicemapper 的存储驱动标记为了过期，推荐大家使用 Overlay2 的存储驱动；
在 CRI 方面 io.containerd.runtime.v1.linux 仍然是默认的运行时，可选配置为新的 io.containerd.runc.v2，新的版本</description></item><item><title>K8S 生态周报| Kubernetes v1.16 正式发布</title><link>https://moelove.info/2019/09/22/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Kubernetes-v1.16-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 22 Sep 2019 23:45:37 +0800</pubDate><guid>https://moelove.info/2019/09/22/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Kubernetes-v1.16-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kubernetes v1.16 正式发布 正如我在上次周报中所说，本周 Kubernetes v1.16 正式发布了。此版本中共包含 31 项功能增强：其中 8 项处于 stable 阶段，8 项处于 beta 阶段，剩下的 15 项处于 alpha 阶段。
如果一直关注本周报系列文章的话，这个版本中比较重要的功能我基本都已经提到过了（这里划个重点）。
CRD 达到 GA ，这是当前社区最为推崇的一种扩展 Kubernetes 的方式，并且自从 1.7 加入后，也被越来越广泛的使用了； 准入控制 webhooks 达到 GA ，准入控制在 Kubernetes 中太过于重要了，自 1.9 该功能加入以来，被广泛用于扩展 Kubernetes 相关功能； 现在 CSI 规范中支持调整卷大小，当前正在迁移至 Beta 阶段； IPv4/IPv6 双栈支持； 为了更好的控制 kube-apiserver 的网络流量，正在尝试给它增加一个代理，详情可点击链接查看； 其余还有一些比较重要的内容：
现在 kubeadm 在 TLS bootstrap 之后，将会删除 bootstrap-kubelet.conf，如果有依赖此文件的小伙伴，请尽快迁移使用 kubelet.conf ，此外也建议先看看 RBAC 相关的内容，了解下切换的意义； beta.</description></item><item><title>K8S 生态周报| Istio 1.3 正式发布</title><link>https://moelove.info/2019/09/15/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Istio-1.3-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 15 Sep 2019 23:45:23 +0800</pubDate><guid>https://moelove.info/2019/09/15/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Istio-1.3-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Istio 1.3.0 正式发布 上周 k8s 生态周报中，我推送了关于 Istio 1.3.0-rc2 发布的消息后，有小伙伴专门私聊我，说想问问 Istio 1.3 到底有什么新特性；以及为何上次没有对 Istio 1.3 的新特性进行介绍。
这里我来做下说明，首先关于为何上次没有对 Istio 1.3 新特性进行介绍。有两个主要原因：1. 上周时，正式版尚未发布；2. 对 1.3 这个版本而言没有太多新特性，此版本主要在于改善用户体验。
对 Istio 而言，今年是个很重要的节点，而且自从 3 月份发布 1.1 版本以来， Istio 的更新频率基本稳定在了 3 个月发布一个版本。1.1 版本专注于企业就绪，在此版本中一方面是提升系统的稳定性，另一方面则是解决企业落地时，可能遇到的一些问题，所以 1.1 中有大量的新特性。而 1.2 版本其实也类似，虽然花费了很多精力在保证质量上，但其中也有不少功能从 Beta 到了 Stable 阶段。
其次是关于 1.3 版本到底有哪些新特性：
出站流量自动确定协议：之前版本中，Istio 要求 Service 需要按照指定的规则进行命名才可以自动确认其协议，而在此版本中则可以自动确认其是 HTTP 或 HTTP/2 流量，如果无法自动确认，则认为其是纯 TCP 流量，如果是通过 Helm 安装的话，可以使用 --set pilot.enableProtocolSniffing=false 关闭此功能； Pod spec 中不再需要定义 containerPort，默认情况下会捕获所有端口，当然你也可以通过 traffic.</description></item><item><title>K8S 生态周报| Harbor v1.9 带来众多新特性</title><link>https://moelove.info/2019/09/08/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Harbor-v1.9-%E5%B8%A6%E6%9D%A5%E4%BC%97%E5%A4%9A%E6%96%B0%E7%89%B9%E6%80%A7/</link><pubDate>Sun, 08 Sep 2019 22:43:44 +0800</pubDate><guid>https://moelove.info/2019/09/08/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Harbor-v1.9-%E5%B8%A6%E6%9D%A5%E4%BC%97%E5%A4%9A%E6%96%B0%E7%89%B9%E6%80%A7/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Docker CE 19.03.2 发布 Docker CE 19.03.2 已于近日发布，事实上此版本内更新的内容本该在 19.03.1 中发布的，不过 19.03.1 主要是为了修正 CVE-2019-14271 如果你正在使用 19.03.0 那我建议你进行升级。
为了保证尽可能快的修复问题，所以专程发布了 19.03.1 版本，而把原先预期的功能转移至 19.03.2 中进行发布。这其实也是 Docker 做的比较好的一个事情，Docker 的版本发布很有原则。
我们来看看 19.03.2 中带来了哪些变化：
修正了Docker CLI 对 HTTP Proxy 环境变量的支持； 修正了一个为容器使用 XFS 磁盘配额可能产生的 panic； 其他变化，感兴趣的朋友可以参看其 ReleaseNote
containerd 1.3.0-rc.0 发布 1.3 将会是 containerd 的下一个主版本；而自 containerd 1.2 发布以来已经过去了近 9 个月。我们来大致看看 1.3 中有哪些值得期待的功能。
增加了 Windows v2 的 runtime API， 同时移除了 Windows v1 API； 新增了 devicemapper 的快照支持，然而需要注意的是 Docker 已经将 devicemapper 的存储驱动标记为了过期，推荐大家使用 Overlay2 的存储驱动； 允许插件注册为一个 TCP Server ，通过这种机制其实可以做到很多的事情了； 可配置的插件目录； 在 CRI 方面 io.</description></item><item><title>K8S 生态周报| etcd v3.4.0 带来众多更新</title><link>https://moelove.info/2019/09/01/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-etcd-v3.4.0-%E5%B8%A6%E6%9D%A5%E4%BC%97%E5%A4%9A%E6%9B%B4%E6%96%B0/</link><pubDate>Sun, 01 Sep 2019 23:56:38 +0800</pubDate><guid>https://moelove.info/2019/09/01/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-etcd-v3.4.0-%E5%B8%A6%E6%9D%A5%E4%BC%97%E5%A4%9A%E6%9B%B4%E6%96%B0/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Helm 3 beta2 发布 Helm 3 从 Alpha 之后，就一直进入了持续改进阶段。终于现在 beta2 发布了，按现在社区的开发进度来看，今年发布正式版的希望还是很大的。
感兴趣还是建议可以先尝试下，以免之后升级时带来不适。
CoreDNS v1.6.3 发布 federation 将在 1.7.0 中被完全废弃； 新增两个插件 clouddns 和 sign，其中 clouddns 顾名思义是为云环境设计的，现在它支持 GCP （Google Cloud Platform）Cloud DNS 提供的 zone 数据，实际上它是通过 Google Cloud 的 API 来获取这些信息的，如果你没有在使用 GCP Cloud DNS 的话，目前这个插件应该是用不到的；sign 插件则是根据 RFC 6781 对 Zone 使用 NSEC 签名，但需要注意的是签名是有时效的，如果到了过期时间，则 Zone 信息会变成 Bad 状态（RFC 4035），所以如果你想要使用这个插件，请明确知道自己需要做什么以及为何使用它； file 插件修复了一些内存泄漏的问题； 除了上述提到的内容外，想稍微再提一下在 v1.6.2 中新增的 azure 插件，它其实和 clouddns 做的事情类似，只不过是从 Azure 获取记录罢了。另外从 v1.</description></item><item><title>K8S 生态周报| cilium 1.6 发布 100% kube-proxy 的替代品</title><link>https://moelove.info/2019/08/25/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-cilium-1.6-%E5%8F%91%E5%B8%83-100-kube-proxy-%E7%9A%84%E6%9B%BF%E4%BB%A3%E5%93%81/</link><pubDate>Sun, 25 Aug 2019 21:19:10 +0800</pubDate><guid>https://moelove.info/2019/08/25/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-cilium-1.6-%E5%8F%91%E5%B8%83-100-kube-proxy-%E7%9A%84%E6%9B%BF%E4%BB%A3%E5%93%81/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kind(Kubernetes In Docker) v0.5.1 正式发布 Kind(Kubernetes In Docker) 已经广泛的应用于 Kubernetes 上游及相关项目的 CI 环境中，作为个人本地的测试环境也很方便，推荐大家尝试。
本次发布，将默认的 Kubernetes 版本更新为 v1.15.3 ；支持了 UDP 和 SCTP 协议的端口转发；对构建 Node 镜像进行了优化，使它更快；同时也对 arm32 增加了有限的支持。
对 kind load-image 进行了改进，从原先的只是判断镜像名称和 tag 到现在增加了对哈希值的校验；修正了在使用 Proxy 时，部分服务可能受代理影响导致的问题（对国内用户友好）。
更多关于此版本的内容，请参考 ReleaseNote，欢迎使用和反馈。
Kubernetes 受 Go 的 net/http 安全漏洞影响 Kubernetes 近期紧急发布了 v1.15.3, v1.14.6, v1.13.10 版本，距离上个集体更新发布仅过了两周而已，上次的说明请参考两周前的 k8s 生态周报，不过本次的漏洞的根本原因不在 Kubernetes 的功能逻辑上，还是在于其使用的 Go 语言的 net/http 库的安全漏洞 CVE-2019-9512 和 CVE-2019-9514 。
关于此次漏洞的信息，可参考 golang/go#33606，另外 Go 最近陆续发布了几个版本，建议大家也最好升到 v1.</description></item><item><title>K8S 生态周报| 2019-08-12~2019-08-18</title><link>https://moelove.info/2019/08/19/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-08-12~2019-08-18/</link><pubDate>Mon, 19 Aug 2019 01:08:00 +0800</pubDate><guid>https://moelove.info/2019/08/19/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-08-12~2019-08-18/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
rkt 项目正式被 CNCF 归档 8 月 16 日，CNCF 宣布技术委员会已经投票通过将 rkt 项目归档。
这个事情，我在几周前的周报大概介绍过，既然现在已经尘埃落定，不如一起来看看 rkt 的前世今生，毕竟它在容器技术的发展中也曾做出了很多贡献。
rkt 最早是由 CoreOS 公司创建的，而 CoreOS 最早应该也算是 Docker 的用户之一。但是随着 Docker 发展的日趋壮大，CoreOS 就想要脱离 Docker，成立自己的标准。
之后 CoreOS 发布了 AppC 规范（这个规范我也曾仔细研究过），而 CoreOS 主打的旗号是开放，毕竟当时 Docker 一枝独秀，所以也就吸引了不少的伙伴参与。当然 rkt 也就借着这股风，得到了不少人的青睐。
这里且不说 rkt 功能或是规范如何，我们单独来看看那场容器市场份额的争夺战是如何打的。
在那时候，同时进行的另外一场战役是容器编排系统的战役。所以 rkt 也算是做了努力，它选择了与 Kubernetes 的合作（大概算是共同阵营的合作吧），所以在 2016 年 Kubernetes 1.3 版本中，宣布了支持 rkt 作为容器运行时的一个可选想。
但 Docker 的发展（指 Docker 项目），却几乎没有受到影响。为什么呢？ Docker 早已凭借自身的稳定性和易用性占领了大批的用户，即使有用户选择 rkt 大多也只是用于尝试（心疼选择 rkt 放入生产环境中的那批）。而且不得不说，Docker 在用户心中几乎是容器的代名词，是一个默认选项。</description></item><item><title>K8S 生态周报| 2019-08-05~2019-08-11</title><link>https://moelove.info/2019/08/12/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-08-05~2019-08-11/</link><pubDate>Mon, 12 Aug 2019 07:14:40 +0800</pubDate><guid>https://moelove.info/2019/08/12/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-08-05~2019-08-11/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kubernetes 两个重要漏洞修复 最近 Kubernetes 发布了 1.13.9, 1.14.5, 和 1.15.2 版本，旨在修复两个重要漏洞对 Kubernetes 带来的影响， 强烈建议将集群及 kubectl 进行升级
CVE-2019-11247 简单来说其影响就是可以访问单个命名空间中的自定义资源的用户可以访问具有集群范围的自定义资源。当然，这里的修正主要是 针对 CRD 。核心的修正代码如下：
var possiblyAcrossAllNamespacesVerbs = sets.NewString(&amp;quot;list&amp;quot;, &amp;quot;watch&amp;quot;) namespacedCRD, namespacedReq := crd.Spec.Scope == apiextensions.NamespaceScoped, len(requestInfo.Namespace) &amp;gt; 0 if !namespacedCRD &amp;amp;&amp;amp; namespacedReq { r.delegate.ServeHTTP(w, req) return } if namespacedCRD &amp;amp;&amp;amp; !namespacedReq &amp;amp;&amp;amp; !possiblyAcrossAllNamespacesVerbs.Has(requestInfo.Verb) { r.delegate.ServeHTTP(w, req) return } 当未通过检查时，delegate 将会触发一个 404 。对此问题感兴趣的朋友可以查看 #80983 。
CVE-2019-11249 则是对于之前暴出来的使用 kubectl cp 可进行恶意目录浏览的漏洞 CVE-2019-1002101 和 CVE-2019-11246 的不完整修复。有兴趣可以参考 #80436 。</description></item><item><title>K8S 生态周报| 2019-07-29~2019-08-04</title><link>https://moelove.info/2019/08/05/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-07-29~2019-08-04/</link><pubDate>Mon, 05 Aug 2019 00:47:54 +0800</pubDate><guid>https://moelove.info/2019/08/05/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-07-29~2019-08-04/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
containerd 1.3.0-beta.0 发布 containerd 2014 年从 Docker 孵化出来，最初是作为 Docker 引擎的底层管理器；在 2017 年 3 月被 CNCF 接受后，containerd 几乎成为了行业容器运行引擎的标准，它专注于简单，健壮和可移植性，任何人都可以使用它来构建自己的容器引擎/平台。它是从 CNCF 毕业的第 5 个项目，目前发展势头良好。
本次发布的 1.3.0-beta.0 版本是 containerd 的第 4 个主要版本，主要是为了提升项目的稳定性，以及为了保持项目的活力而持续加入了很多新的特性。
这次的发布和之前版本类似，保持着 containerd 的一贯作风，API 变化很小；并且也保持向后兼容。插件生态和用户的发展也促使了 containerd 变得更易用，可配置和更灵活。
在 Windows 上，此次版本带来了一个新运行时（使用 hcsshim）; 对于客户端而言，本次也带来了很多特性和升级。
这里我只说两点，其余的等正式版出来看情况再进行介绍。
增加了 devicemapper 的快照插件。这个功能本身是个好事儿，如果用过旧版本 Docker 或者系统内核较低的朋友们，应该对 Docker 的 devicemapper 存储驱动不会太陌生的（虽然现在 Docker 的新版本中已经将 devicemapper 的存储驱动废弃掉了）；至于 containerd 中增加的 devicemapper 快照插件，我还没有来得及具体测试，所以这里不说太多了。 客户端支持了跨 repository push 镜像，对此功能感兴趣的朋友可以参考 #2697 的讨论。 更多关于此版本的信息请参考 ReleaseNote</description></item><item><title>K8S 生态周报| 2019-07-21~2019-07-28</title><link>https://moelove.info/2019/07/28/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-07-21~2019-07-28/</link><pubDate>Sun, 28 Jul 2019 22:14:44 +0800</pubDate><guid>https://moelove.info/2019/07/28/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-07-21~2019-07-28/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Docker CE v19.03 正式发布 7 月 22 日，正式发布了 Docker CE v19.03 版本，按照 Docker CE 版本的生命周期，此次的 v19.03 可以说是千呼万唤始出来，原本按语义应该是在 3 月，不过之前的发布计划中开始是设定在了 5 月份，而一转眼现在已经到 7 月底了。 先跳过这次发布时间延期的问题，我们来看看此版本中最值得注意的一些变化。
首先来看看被废弃的部分：
废弃 aufs 存储驱动，在此版本之前 devicemapper 和 overlay 也都已经被废弃; 当 docker daemon 运行时，如果没有指定存储驱动，则会自动选择一个，v19.03 中增加了自动选择时跳过已被废弃的存储驱动的逻辑； 废弃 image manifest v2 schema1 以支持 v2 schema2 ，这里的废弃涉及到的内容很多，尤其是涉及到了 image registry 的部分, 所以后续还有很长的路要走。还记得之前推送过 Docker Hub 今年 6 月份停止 v1 API 进行 Pull 操作的事情吗？早年 2015 年 11 月的时候，它就已经禁止了 v1 API 的 Push 操作。从这点上也能看到 Docker 在功能弃用上其实为用户考虑了很多，并且也给了足够长的时间来让用户进行迁移。 其次，我们看看功能增强的部分：</description></item><item><title>K8S 生态周报| 2019-07-15~2019-07-21</title><link>https://moelove.info/2019/07/22/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-07-15~2019-07-21/</link><pubDate>Mon, 22 Jul 2019 00:07:54 +0800</pubDate><guid>https://moelove.info/2019/07/22/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-07-15~2019-07-21/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kubernetes v1.16.0-alpha.1 发布 Kubernetes 于近日发布了 v1.16.0-alpha.1 版本，变化是比较大，但这里暂时先不细说了，等到 9 月份正式版本发布前后再慢慢说。当然也稍微聊一些 :) 比如：
官方 etcd 镜像中不再提供 etcd 2 和 3 的兼容工具了，对 etcd 2 的兼容代码也都全部删掉了（对 etcd 2 的支持其实从 1.13 就已经停止了）#80037 ；
1.16 中对以下四种类型资源的 API 有所调整：
NetworkPolicy PodSecurityPolicy DaemonSet, Deployment, StatefulSet 和 ReplicaSet Ingress 具体调整细节如下：
NetworkPolicy 将使用从 v1.8 版本开始提供的 networking.k8s.io/v1 API; PodSecurityPolicy 将使用从 v1.10 开始提供的 policy/v1beta1 API; DaemonSet, Deployment, StatefulSet 和 ReplicaSet 将使用从 v1.9 版本开始提供的 apps/v1 API; Ingress 迁移到 networking.</description></item><item><title>K8S 生态周报| 2019-07-08~2019-07-14</title><link>https://moelove.info/2019/07/15/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-07-08~2019-07-14/</link><pubDate>Mon, 15 Jul 2019 05:44:22 +0800</pubDate><guid>https://moelove.info/2019/07/15/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-07-08~2019-07-14/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。 本周为什么发布时间比往常迟呢？因为我在忙结婚呀。
CoreDNS v1.5.2 发布 这是 CoreDNS 在 1.5.x 版本中发布的第二个小版本，关于 1.5.1 版本的说明可参考上上周的文章。
在此版本中，一个重要的变更便是移除掉了 upstream 插件相关的所有文档和说明。比如，Kubernetes 1.14 版本中默认的 CoreDNS 的配置文件的内容如下：
.:53 { errors health kubernetes cluster.local in-addr.arpa ip6.arpa { pods insecure upstream fallthrough in-addr.arpa ip6.arpa } prometheus :9153 forward . /etc/resolv.conf cache 30 loop reload loadbalance } 其中 kubernetes 插件中有一行 upstream 的配置，它是定义了用于解析指向外部主机的服务的上游解析器（也称之为外部服务，CNAME）CoreDNS 将针对自身解析该服务。
在此次变更之后， upstream 配置行便可直接移除。
另外 template 插件支持元数据了。比如说可以给它增加一个配置 .Meta &amp;quot;kubernetes/my-namespace&amp;quot;。
关于此版本的更详细说明可阅读 ReleaseNote
Envoy v1.</description></item><item><title>K8S 生态周报| 2019-07-01~2019-07-07</title><link>https://moelove.info/2019/07/07/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-07-01~2019-07-07/</link><pubDate>Sun, 07 Jul 2019 23:20:10 +0800</pubDate><guid>https://moelove.info/2019/07/07/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-07-01~2019-07-07/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kubernetes v1.16 发布周期开始 随着前段时间 Kubernetes v1.15 的发布，v1.16 的发布周期开始了。本次的发布周期一如往常，本月底增强功能冻结，下月底代码冻结，9 月初完善文档，计划在 9 月中发布 v1.16 版本。
其实按这个节奏看得话，大家如果需要维护生产中的 Kubernetes 集群的话，还是尽快测试验证并完成升级，以免所用版本 EOL，带来一些其他的问题。
Knative Serving v0.7.x 发布 本周 Knative Serving 发布了 v0.7.1 版本，Knative 近期的开发还是比较活跃的。
需要注意的是若使用 v0.7.x 版本中新增的 serving.knative.dev/v1beta1 API 的话，则需要 Kubernetes v1.14 版本以上。具体原因请参考 #4533
Non-root 容器：在这个版本中所有发布的容器均以非 root 用户运行，这使得我们可以使用更严格的 PSP。
当然此版本中也包含一些破坏性变更，比如 status 字段废弃。
关于此版本更多的细节请参考 ReleaseNote
Debian 10 buster 正式发布 Debian 10 正式发布了，其实按一般的角度来看，Linux 的一个发行版发布不会出现在 K8S 生态周报中的。
但这里有个需要注意的点，对于使用此版本部署 Kubernetes 时，需要注意一下。此版本中使用的 systemd 版本是 241.</description></item><item><title>K8S 生态周报| 2019-06-24~2019-06-30</title><link>https://moelove.info/2019/06/30/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-06-24~2019-06-30/</link><pubDate>Sun, 30 Jun 2019 23:12:13 +0800</pubDate><guid>https://moelove.info/2019/06/30/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-06-24~2019-06-30/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
kind (Kubernetes In Docker) v0.4.0 正式发布 kind (Kubernetes In Docker) 是我很喜欢并且一直持续参与贡献的项目，本周发布了 v0.4.0 版本。关于 Kind 的介绍和基础使用，可以参考我之前写的文章 《使用 Kind 搭建你的本地 Kubernetes 集群》
v0.4.0 版本中，默认的 Kubernetes 版本升级到了 v1.15 版本，且 kind.sigs.k8s.io/v1alpha2 版本的 API 已经过期，请更新使用 kind.sigs.k8s.io/v1alpha3 。
目前暂时移除了使用 apt 构建 Node 镜像的选项，之后版本中可能会加回来，直接使用上游构建好的二进制文件进行安装。
在此版本中，我们增加了一个 nodes[].extraPortMappings 的配置，可以直接通过此配置进行端口的转发，以便从宿主机上直接访问到集群上使用 NodePort 方式部署的服务，这样更容易模拟真实的网络环境，否则只能通过其他的转发或者网络代理的方式来进行通信了。
同样的，紧跟着上游的开放，这个版本中也增加了对 IPv6 的支持，可以直接通过 networking.ipFamily 的配置进行使用。
为了能让 kind 更加易用，且满足多数 CI 或者测试使用的场景，在这个版本中，我们尤其对单节点集群的启动时间做了优化，可以更快速的启动集群。
顺便公布一个数据，kind 目前的 star 数是 2.2k 上个版本发布时是 1.8k 并且还在持续增长中 :)
更多的细节和信息请参考 ReleaseNote 欢迎大家使用！</description></item><item><title>K8S 生态周报| 2019-06-17~2019-06-23</title><link>https://moelove.info/2019/06/22/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-06-17~2019-06-23/</link><pubDate>Sat, 22 Jun 2019 23:23:17 +0800</pubDate><guid>https://moelove.info/2019/06/22/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-06-17~2019-06-23/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kubernetes v1.15.0 正式发布 经过了三个月左右的开发，Kubernetes v1.15.0 正式发布了。
这是 2019 年 Kubernetes 发布的第二个版本，这个版本由 25 个增强功能组成，其中 2 个移动到 stable ，13 个 beta 以及 10 个 alpha ，整体上集中于稳定性改进和扩展的增强。
CRD (Custom Resource Definition) 是 Kubernetes 提供的一种可用于扩展其能力的方式，当前有很多使用 CRD 构建于 Kubernetes 上的平台/系统，可以说之后对 Kubernetes 的扩展，或者说想要基于 Kubernetes 开发，同时又想与上游保持同步的话，CRD 是个最佳的选择。
Kubeadm 在此版本开始有了自己独立的 LOGO ，同时在这个版本中 kubeadm 的功能也得到了很多的完善和补充。这使得 kubeadm 成为更普遍/更好用的搭建集群的工具，同时对集群生命周期的管理也做的更加到位了。这部分的功能我很喜欢也一直在关注，近期我会针对这部分写篇文章出来。感兴趣的朋友们可以关注下
关于此版本更多的介绍，可参考 Kubernetes v1.15 ReleaseNote
Istio 1.2.0 正式发布 经过三个 rc 版本之后， Istio 1.2.0 版本正式发布。
在这个版本中，它添加了对 Kubernetes IPv6 的实验性支持。Kind （Kubernetes in Docker） 项目也是本周内刚增加了 IPv6 的支持 :)</description></item><item><title>K8S 生态周报| 2019-06-10~2019-06-16</title><link>https://moelove.info/2019/06/16/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-06-10~2019-06-16/</link><pubDate>Sun, 16 Jun 2019 23:17:17 +0800</pubDate><guid>https://moelove.info/2019/06/16/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-06-10~2019-06-16/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Helm 新下载域名正式上线 https://get.helm.sh/ 正式上线。用户之后下载 Helm 预编译好的二进制文件时，可通过此域名进行下载。
原来 Kubernetes 尚未成为 CNCF 托管项目时，Helm 是作为 Kubernetes 项目的一部分的，所以很自然的使用了 Google 的一个云存储仓库。但随着项目托管至 CNCF 以及后续 Helm 的独立发展，现在使用托管于 Google 的云存储不那么合适了，一方面在于 CNCF 正在接管 K8S 的基础设施，另一方面在于在于这个仓库不只受 Helm 的控制。
考虑到项目的独立性，以及 大陆用户无法正常访问 GCloud 存储的问题 经过维护者们的慎重考虑以及实际测试，终于决定选择 Azure 的 Blob 存储 + CDN 可满足当前所有地区的快速访问（尤其是国内可以直接访问并下载），不再需要花费时间精力解决网络等问题了。
这次的更改仅限于 Helm 客户端的下载位置，类似 Tiller 或者 Chart 等并没有被包含在内。
强烈建议更新有在 CI/自动化任务中使用的 Helm 下载地址，使用 https://get.helm.sh/ 来进行替换。
对此内容感兴趣的朋友可参考 Move Helm Downloads 的讨论
Apple 作为白金终端用户成员加入 CNCF Apple 在 K8S 社区中在这之前也算相对低调，并没有像各类云厂商或其他公司那样疯狂安利或者输出之类的。但是这次突然加入 CNCF 而且作为白金会员，是可具备话语权的。</description></item><item><title>K8S 生态周报| 2019-06-03~2019-06-09</title><link>https://moelove.info/2019/06/09/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-06-03~2019-06-09/</link><pubDate>Sun, 09 Jun 2019 22:15:11 +0800</pubDate><guid>https://moelove.info/2019/06/09/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-06-03~2019-06-09/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kubernetes CVE-2019-11245 漏洞 这是一个评分为 4.9 的漏洞，算是一个中等漏洞。 受此漏洞影响的版本为 v1.13.6 和 v1.14.2 ，所以本周也加紧发布了 v1.13.7 和 v1.14.3 版本，以避免受此漏洞影响。 如果有使用 v1.13.6 和 v1.14.2 版本的小伙伴，请尽快进行 升级 以免受到影响。
上面说了最直接的解决办法，接下来对此漏洞大致做下介绍：
这个漏洞影响了 v1.13.6 和 v1.14.2 版本的 kubelet，具体表现为， 1) 如果 Pod 中的容器，开始时是以某个非 root 用户启动的，但是当它重启后，则会以 root (uid 0) 的身份启动。2) 或者是 Node 节点上已经存在了启动容器所需的镜像。
第 2 个情况比较常见，不再具体介绍。我们来看下第 1 种情况。举个栗子：
通常情况下，如果我们使用 Docker 官方的 Redis 镜像进行部署的时候，默认情况下将会以 redis 用户启动；而如果受此漏洞影响，当容器重启后，则当前的用户可能会变成 root (uid 0) 。使用 root 用户启动服务可能带来的危害，这里也不再多进行展开了。
也存在例外，比如已经显式的通过 runAsUser 指定了运行用户，则不会受到此漏洞影响。</description></item><item><title>Docker 镜像构建三部曲</title><link>https://moelove.info/2019/06/01/Docker-%E9%95%9C%E5%83%8F%E6%9E%84%E5%BB%BA%E4%B8%89%E9%83%A8%E6%9B%B2/</link><pubDate>Sat, 01 Jun 2019 00:19:03 +0800</pubDate><guid>https://moelove.info/2019/06/01/Docker-%E9%95%9C%E5%83%8F%E6%9E%84%E5%BB%BA%E4%B8%89%E9%83%A8%E6%9B%B2/</guid><description>我最近在 GitChat 写了一些 Docker 构建镜像相关的文章，这个系列写了三篇，通过这三篇将 Docker 构建镜像相关的事情基本就讲明白了，感兴趣的朋友扫描二维码或者点击链接即可。
高效构建 Docker 镜像的最佳实践 Docker 可谓是开启了容器化技术的新时代，现在无论大中小公司基本上都对容器化技术有不同程度的尝试，或是已经进行了大量容器化的改造。伴随着 Kubernetes 和 Cloud Native 等技术和理念的普及，也大大增加了业务容器化需求。
而这一切的推进，不可避免的技术之一便是构建容器镜像。
在本场 Chat 中，会讲到如下内容：
Docker 镜像是什么 Docker 镜像常规管理操作 如何构建 Docker 镜像 逐步分解构建 Docker 镜像的最佳实践 如何提升构建效率 适合人群： 对高效构建 Docker 镜像有兴趣的技术人员
地址：https://gitbook.cn/gitchat/activity/5cd527e864de19331ba79278
进阶：Dockerfile 高阶使用指南及镜像优化 在上次的 Chat 高效构建 Docker 镜像的最佳实践 中，我们重点深入内部介绍了 Docker 镜像是什么；以及构建 Docker 镜像的最佳实践等。
即将发布的 Docker 19.03 版本中 Dockerfile 及构建系统有了很多变化。
在本场 Chat 中，会讲到如下内容：
Dockerfile 高阶使用及新特性解读 Docker 19.03 构建系统解读 Docker 镜像安全实践 发现并优化镜像大小 地址：https://gitbook.</description></item><item><title>K8S 生态周报| 2019-05-27~2019-06-02</title><link>https://moelove.info/2019/05/31/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-05-27~2019-06-02/</link><pubDate>Fri, 31 May 2019 07:42:37 +0800</pubDate><guid>https://moelove.info/2019/05/31/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-05-27~2019-06-02/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kubernetes v1.15.0-beta.1 发布 随着 KubeCon EU 的结束，Kubernetes 的开发工作继续回归正常，本周相继发布了 v1.12.9 和 v1.15.0-beta.1。
随着 v1.15 的正式版临近，维护期的 Kubernetes 版本也将变成 1.12~1.15，请尽快升级。
这个版本的变化，等正式版发布时候再进行介绍好了，有兴趣可以先看 ReleaseNote
Docker v19.03.0-beta5 发布 按照正常规律 Docker 19.03 正式版也将在近期进行发布，而最近的所有测试版本中，其实变化比较大的东西主要在 构建系统 上；构建系统的升级可以使构建速度更快，同时也增加了更多的安全特性。
这次的 beta5 也是常规修复，有兴趣可以先看 ReleaseNote
Docker CVE-2018-15664 安全漏洞 在 5 月 29 日我看到了 CVE 的信息，这个漏洞会影响 Docker 的全部版本，漏洞攻击的主要途径是 docker cp 相关的操作。
但是不必太过紧张，因为这个漏洞的攻击范围其实不算太大；最主要可能被攻击的对象其实是公有云。对于普通用户而言，如果受此攻击，那前提是攻击者已经具备了机器的权限和 Docker 的操作权限（一般用户只要自行控制权限便可避免攻击的发生）。
漏洞发现者 Aleksa Sarai 开始提了一个 PR (他的实现方式是在 docker cp 操作的同时暂停容器)，不过现在已经被一个新的 PR 给取代了，毕竟暂停容器意味着停止服务，这是难以接受的。
类似 Podman 之类的其实也存在相同的问题，不过现在也已经被修复了。</description></item><item><title>K8S 生态周报| 2019-05-20~2019-05-26</title><link>https://moelove.info/2019/05/26/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-05-20~2019-05-26/</link><pubDate>Sun, 26 May 2019 23:24:46 +0800</pubDate><guid>https://moelove.info/2019/05/26/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-05-20~2019-05-26/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
KubeCon EU 举办 2019 年第一个 KubeCon + CloudNativeCon 于 5 月 20 ~ 23 日在巴塞罗那成功举办，这次大会吸引了七千多名参会者远超去年的参会人数。 这也从另一个侧面反映了 Kubernetes 和云原生在大大的普及
在大会上宣布了不少值得关注的信息, 我在此大致列一下我认为值得关注的信息（虽然有些内容之前已经关注到了）：
OpenTracing, OpenCensus 合并为 OpenTelemetry； 微软推出 Service Mesh Interface（SMI）规范； NGINX Ingress Controller 发布 1.5.0 版本； Google 宣布 GKE 将会支持 Windows Server Container； Helm 3 的发展历程；（推荐阅读我之前写的 初试 Helm 3） 当然，大会上公布的信息还有很多，还有一些 CNCF 的计划等，这里暂且不提，感兴趣的朋友可以自行搜索或者参加下个月在上海举办的 KubeCon + CloudNativeCon
微软推出 Service Mesh Interface （SMI） Service Mesh 也是一个趋势，但现在并没有一个统一的规范，各个厂商的实现也都各有不同。微软本次提出的 SMI 主要是为 Kubernetes 服务网格提供通用接口，以便能让 Service Mesh 有更加通用的规范 （就像当初 CNI/CRI 那样子）</description></item><item><title>云原生应用开发新体验：Kui</title><link>https://moelove.info/2019/05/24/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E6%96%B0%E4%BD%93%E9%AA%8CKui/</link><pubDate>Fri, 24 May 2019 10:19:03 +0800</pubDate><guid>https://moelove.info/2019/05/24/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91%E6%96%B0%E4%BD%93%E9%AA%8CKui/</guid><description>云原生（Cloud Native）应用是伴随着 Kubernetes 应用范围的扩大，基于云模型而提出的一种概念。
本文来介绍一个云原生应用开发的工具 Kui, 这是一款由 IBM 开源的工具，使用 Electron 提供 GUI 能力。
Kui Shell offers a new development experience for building cloud-native applications. By combining the power of familiar CLIs with visualizations in high-impact areas, Kui enables you to manipulate complex JSON and YAML data models, integrate disparate tooling, and provides quick access to aggregate views of operational data.
正如以上介绍中提到的，Kui 提供了一种新的开发体验（原先大多数时候我们是通过 kubectl 与 Kubernetes 中的资源进行交互），Kui 结合了原有 CLI 的强大功能，并提供一种可视化的方式，方便我们对 Kubernetes 中 YAML 或者 JSON 格式数据的处理。</description></item><item><title>K8S 生态周报| 2019-05-13~2019-05-19</title><link>https://moelove.info/2019/05/19/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-05-13~2019-05-19/</link><pubDate>Sun, 19 May 2019 23:13:42 +0800</pubDate><guid>https://moelove.info/2019/05/19/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-05-13~2019-05-19/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
kind v0.3.0 正式发布 kind (Kubernetes In Docker) 是我很喜欢并且一直持续参与贡献的项目，本周发布了 v0.3.0 版本。关于 Kind 的介绍和基础使用，可以参考我之前写的文章 《使用 Kind 搭建你的本地 Kubernetes 集群》
本次的发布主要侧重于加速集群的启动速度及提高稳定性，优化镜像大小，以及对网络的优化和一些 bugfix 等；其中最主要的内容是将默认的 CRI 从 Docker 换成了 Containerd，以此可以缩小镜像体积，以及加快集群的启动。
v0.3.0 版本中，可以通过配置文件自行部署不同的 CNI，更有利于用户测试实际的集群情况；现在版本中已经将默认的 Kubernetes 版本升级到了最新的 v1.14.2 。
当然，也还有一些正在增加的特性，预计会在 v0.4.0 版本中发布，主要集中于 IPv6 和集群重启的支持（相信很快就可以完成了）。
顺便公布一个数据，Kind 目前的 star 数是 1.8k 还在持续增长中 :)
更多的细节和信息请参考 ReleaseNote
Kubernetes v1.14.2 正式发布 这是一个常规的 bugfix 版本，但有个值得关注的点：
升级到了 golang v1.12.5 版本。 你可能要问为什么需要关注 golang 版本的升级？这是因为在此版本中 golang 有一些关于运行时的修改，尤其是其中关于二叉树查找部分的修改等部分的修改，可有效的降低 Kubernetes API server 的延迟。</description></item><item><title>初试 Helm 3</title><link>https://moelove.info/2019/05/16/%E5%88%9D%E8%AF%95-Helm-3/</link><pubDate>Thu, 16 May 2019 21:30:00 +0800</pubDate><guid>https://moelove.info/2019/05/16/%E5%88%9D%E8%AF%95-Helm-3/</guid><description>经过了长时间的开发，Helm 3 终于在今天发布了第一个 alpha 版本。本文将简单介绍 Helm 3 新特性。
移除 Tiller Helm 2 是 C/S 架构，主要分为客户端 helm 和服务端 Tiller; 与之前版本相同，Helm 3 同样在 Release 页面提供了预编译好的二进制文件。差别在于原先的二进制包下载下来你会看到 helm 和 tiller 。而 Helm 3 则只有 helm 的存在了。
Tiller 主要用于在 Kubernetes 集群中管理各种应用发布的版本，在 Helm 3 中移除了 Tiller, 版本相关的数据直接存储在了 Kubernetes 中。
现在我们直接在一个新创建的集群上来使用 Helm。测试集群的创建可以参考我之前的文章 使用 Kind 搭建你的本地 Kubernetes 集群。
与之前版本相同，我们需要先执行 helm init 来进行初始化。但现在的初始化就简单了很多，不再需要给集群中部署 Tiller 了
(MoeLove) ➜ ~ export HELM_HOME=/tmp/helm3 (MoeLove) ➜ ~ helm3 init Creating /tmp/helm3/repository Creating /tmp/helm3/repository/cache Creating /tmp/helm3/plugins Creating /tmp/helm3/starters Creating /tmp/helm3/cache/archive Creating /tmp/helm3/repository/repositories.</description></item><item><title>K8S 生态周报| 2019-05-06~2019-05-12</title><link>https://moelove.info/2019/05/12/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-05-06~2019-05-12/</link><pubDate>Sun, 12 May 2019 20:47:02 +0800</pubDate><guid>https://moelove.info/2019/05/12/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-05-06~2019-05-12/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Alpine Linux Docker 镜像漏洞 CVE-2019-5021 本周比较吓人的是 CVE-2019-5021, 根据漏洞报告，自 Alpine Linux 3.3 版本开始的所有 Docker 镜像中，root 用户包含一个空密码，这可能会导致攻击者获得 root 权限，今儿造成攻击。
报告中称：受影响范围是 Alpine Linux Docker 镜像 3.3、3.4、3.5、3.6、3.7、3.8、3.9、edge 等全部版本。
要知道由于 Alpine Linux 镜像体积较小，所以在构建 Docker 镜像时，很多人都会推荐使用 Alpine Linux 作为基础镜像；包括很多 Docker 官方镜像也基本上都提供了基于 Alpine Linux 的镜像，甚至像 Docker 镜像等是只提供了使用 Alpine Linux 作为基础镜像的版本。
当前漏洞已经修复，更多内容请阅读 关于 Alpine Docker 镜像漏洞 CVE-2019-5021 。
istio-operator 发布 0.1.12 版本 banzaicloud/istio-operator 发布 0.1.12 版本，默认已支持 istio 1.1.5 。（虽然截至目前 istio 发布了 1.</description></item><item><title>K8S 生态周报| 2019-04-28~2019-05-05</title><link>https://moelove.info/2019/05/05/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-04-28~2019-05-05/</link><pubDate>Sun, 05 May 2019 21:59:07 +0800</pubDate><guid>https://moelove.info/2019/05/05/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-04-28~2019-05-05/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Docker Hub 只读维护 在上周的推送中，有写到 Docker Hub 用户隐私数据泄漏。受此事件影响，5 月 4 日 Docker Hub 进行升级维护，在此期间 Docker Hub 有一段时间处于只读模式，包括自动构建等服务不可用；在最后有小于 15 分钟的完全宕机时间，服务完全不可用。
如果只是看事情表面的话，可能这就是一个由于发现“安全问题”而进行的升级/维护；但如果仔细考虑下，作为云原生服务，升级为何会有宕机的情况，为何会有服务完全不可用的时候？
摘录一段来自本次维护的公告内容：
Q: Is this maintenance related to recent Docker Hub data breach?
A: While we discovered unauthorized access to a single Hub database storing a subset of non-financial user data last week, which has since been remediated, we are always looking at ways to improve and enhance our security practices to protect our customers and their data.</description></item><item><title>K8S 生态周报| 2019-04-22~2019-04-28</title><link>https://moelove.info/2019/04/29/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-04-22~2019-04-28/</link><pubDate>Mon, 29 Apr 2019 00:36:25 +0800</pubDate><guid>https://moelove.info/2019/04/29/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-04-22~2019-04-28/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Docker Hub 用户隐私数据泄漏 2019 年 4 月 25 日，Docker Hub 团队发现了对存储非财务用户数据子集的单个 Hub 数据库的未授权访问。 在发现异常后官方团队迅速采取行动并保护网站免受攻击。
经过官方团队的调查，目前大概有 190000 帐号的敏感信息（小于总用户数的 5% ）包括用户名和哈希后的用户密码，当然也包括 GitHub 及 Bitbucket 等的用于自动构建的 Token 。
当前的主要措施是对可能被泄漏信息的用户发送了邮件通知，对于可能泄漏哈希密码的用户发送了重置密码的邮件，并且 主动 将密码失效，以及自动构建的 Token 也都被失效。( 所以如果你收到了 Docker Hub 团队关于此次事件的直接报告邮件，很大概率是因为你的信息已经被泄漏了 )
附上官方声明中关于此次事件的处理声明：
During a brief period of unauthorized access to a Docker Hub database, sensitive data from approximately 190,000 accounts may have been exposed (less than 5% of Hub users).</description></item><item><title>K8S 生态周报| 2019-04-15~2019-04-21</title><link>https://moelove.info/2019/04/21/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-04-15~2019-04-21/</link><pubDate>Sun, 21 Apr 2019 21:46:02 +0800</pubDate><guid>https://moelove.info/2019/04/21/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-04-15~2019-04-21/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Prometheus v2.9.0 正式发布 Prometheus 是 CNCF 毕业项目，可用于监控系统及服务状态。它整体是使用 Pull 的模式，在周期时间内采集目标的 metrics ，并且提供了 PromQL 的查询语言，以供对监控数据进行查询过滤等操作。并且可以通过配置规则来触发报警等。我首次接触 Prometheus 大概是在 2015 年 0.15.0 版本左右，当时 Prometheus 还处于比较早期的阶段，不过在进入 CNCF 后，Prometheus 基本就成为了 K8S 监控的实施标准了，并且多数软件也都增加了对 Prometheus metrics 的支持。
v2.9.0 的主要更新：
从 2.8 开始引入了的从 WAL 读取进行 remote write 有时候会丢数据的问题已经得到修复； Kubernetes 和 OpenStack 在服务发现时候增加了更多元数据； Consul 现在支持多 tag； 添加了一个 honor_timestamps 的选项； TLS 证书会自动从磁盘加载； 日志也变的更易读； 其他更新请阅读 ReleaseNote
Linkerd 2.3 正式发布 Linkerd 是一个 service mesh 旨在提供平台范围的可观察性，可靠性和安全性，而无需用户更改代码。在本月初的周报推送中，推荐了一篇关于 Linkerd v2 从产品中吸取的教育和经验的文章，Linkerd v2 使用 Go 和 Rust 进行了重写，并因此获得了巨大的收益。</description></item><item><title>K8S 生态周报| 2019.04.08~2019.04.14</title><link>https://moelove.info/2019/04/14/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.04.08~2019.04.14/</link><pubDate>Sun, 14 Apr 2019 22:53:09 +0800</pubDate><guid>https://moelove.info/2019/04/14/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.04.08~2019.04.14/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
CRI-O 成为 CNCF 托管项目 CRI-O 是基于 OCI 的 Kubernetes CRI 实现，旨在提供符合 OCI 运行时和 kubelet 之间的集成。简单来说就是完全符合 OCI 标准的 CRI 实现。（比如之前介绍的 runc 便是 OCI 标准的参考实现）
在 2016 年的时候 Kubernetes 就推出了容器运行时接口（CRI），这给了 kubelet 一种使用各种不同容器运行时的能力，现在最常用的当然还是 Docker，当然也有人使用 containerd、runc、CRI-O 等各类运行时。
CRI-O 最初由 Red Hat 和 Google 开发，现在已达到稳定状态，且已有大量的贡献者，本次成为 CNCF 托管项目，也算是给容器运行时提供一个更大的可能。
附一张官方图：
详细信息请阅读 CNCF 官方新闻
Helm 子项目 chart-testing 发布 v2.3.0 版本 chart-testing v2.3.0 版本正式发布，该项目的主要目标是用于 Helm Chart 的测试，使用该项目可更方便的检查 Chart 中是否有错误，以及定位错误位置等。
本次发布主要在于覆盖更多异常情况，详细内容建议阅读 ReleaseNote
CoreDNS v1.</description></item><item><title>恭喜 Fluentd 从 CNCF 毕业</title><link>https://moelove.info/2019/04/12/%E6%81%AD%E5%96%9C-Fluentd-%E4%BB%8E-CNCF-%E6%AF%95%E4%B8%9A/</link><pubDate>Fri, 12 Apr 2019 07:23:14 +0800</pubDate><guid>https://moelove.info/2019/04/12/%E6%81%AD%E5%96%9C-Fluentd-%E4%BB%8E-CNCF-%E6%AF%95%E4%B8%9A/</guid><description>今年新闻不断，多数早期进入 CNCF 的项目都相继宣布毕业。
CNCF（云原生计算基金会）在美国时间 2019 年 4 月 11 日宣布 fluentd 今天正式毕业了。
这是 CNCF 中毕业的第 6 个项目，之前已经毕业的项目为 Kubernetes、Prometheus、Envoy 、CoreDNS 和 containerd 。
fluentd 自 2011 年由 Treasure Data 公司的联合创始人 Sadayuki “Sada” Furuhashi 创建，作为构建统一记录层的开源数据收集器，统一记录层统一收集采集和消费，以便更好的使用和理解数据。在 2016 年 11 月，fluentd 也是第 6 个成为 CNCF 托管项目的。
fluentd 可以从多种数据源采集事件，并将它写入文件, RDBMS, NoSQL, IaaS, SaaS, Hadoop等等各类的目标地址。截至目前，fluentd 在 GitHub 上有 7629 个 star ，895 个 fork，以及 166 位贡献者，超过 4k+ commit 。
做日志相关的小伙伴基本都玩过 ELK ，我们都知道在大规模使用 Logstash 时的痛苦（还记得被 Logstash 配置文件支配的恐惧吗？ 2333） 而 fluentd 的事件路由是通过 tag 来做，相比 Logstash 使用管道将所有数据路由到单个流里再通过配置将它发送到对应的目标而言这将大大简化配置的复杂度。(是的，这里是吐槽)</description></item><item><title>K8S 生态周报| 2019.04.01~2019.04.07</title><link>https://moelove.info/2019/04/07/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.04.01~2019.04.07/</link><pubDate>Sun, 07 Apr 2019 10:03:13 +0800</pubDate><guid>https://moelove.info/2019/04/07/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.04.01~2019.04.07/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kubernetes client-go v11.0.0 正式发布 这是最后一个使用 dep 作为依赖管理的版本，后续版本将转向使用 go modules.
Kubernetes 生态中的相关项目大多都已转向或正在转向使用 go modules 了，这也是一个技术风向，理性选择。
Release
containerd 1.2.6 正式发布 这是 containerd 1.2 的第 6 个 patch 版本，主要更新：
在默认的 seccomp profile 白名单增加了 io_pgetevents 和 statx 这两个系统调用; 修复了在 1.2.5 中自定义 cgroup path 无法工作的 bug； 更新 CNI 插件到 v0.7.5 以修复 CVE-2019-9946; 更新 runc 版本，修复在无 SELinux 系统下的失败情况； 当然还有一些其他的改进和修复，比如修复了 pod 的 UTS namespace 等，建议阅读 ReleaseNote。
Docker CE 19.</description></item><item><title>K8S 生态周报| 2019.03.25~2019.03.31</title><link>https://moelove.info/2019/03/31/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.03.25~2019.03.31/</link><pubDate>Sun, 31 Mar 2019 21:52:01 +0800</pubDate><guid>https://moelove.info/2019/03/31/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.03.25~2019.03.31/</guid><description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kubernetes 1.14 正式发布 1.14 的主要更新：
对 Windows Node 和 container 的支持达到生产级别，支持 Windows Server 2019； 本地持久化数据卷正式可用，这可以方便使用本地 SSD 之类的存储，但注意这个特性容错性较差； Pod 优先级和抢占机制正式可用，(建议慎重使用)； Pod Ready++ (Pod Readiness Gates) 达到稳定，可以更好的判断 Pod 及其需要的资源是否均已就绪； 当然还有很多的改进和很多被废弃的功能特性等，建议阅读 ReleaseNote。
Minikube 1.0.0 正式发布 Minikube 是一个用于本地搭建 Kubernetes 环境的工具，使用方法可参考 使用 Minikube 搭建本地 Kubernetes 环境。
1.0.0 的主要更新：
默认 Kubernetes 版本更新至 1.14.0; 新增 --image-repository 参数，方便国内用户使用镜像解决网络问题； 其他特性请阅读 ReleaseNote
runc 1.0-rc7 发布 注意，低版本内核(尤其是 3.x)的系统，请不要升级至此版本
这个版本主要为解决之前的漏洞及修正一些规范等，版本说明请参考 runc 1.</description></item><item><title>使用 Kind 搭建你的本地 Kubernetes 集群</title><link>https://moelove.info/2019/03/25/%E4%BD%BF%E7%94%A8-Kind-%E6%90%AD%E5%BB%BA%E4%BD%A0%E7%9A%84%E6%9C%AC%E5%9C%B0-Kubernetes-%E9%9B%86%E7%BE%A4/</link><pubDate>Mon, 25 Mar 2019 21:30:24 +0800</pubDate><guid>https://moelove.info/2019/03/25/%E4%BD%BF%E7%94%A8-Kind-%E6%90%AD%E5%BB%BA%E4%BD%A0%E7%9A%84%E6%9C%AC%E5%9C%B0-Kubernetes-%E9%9B%86%E7%BE%A4/</guid><description>Kind 是我很喜欢也一直在参与的项目，我计划将 Kind 相关的文章写成一个系列。（flag++） 这是第一篇。
Kind 介绍 Kind 是 Kubernetes In Docker 的缩写，顾名思义是使用 Docker 容器作为 Node 并将 Kubernetes 部署至其中的一个工具。官方文档中也把 Kind 作为一种本地集群搭建的工具进行推荐。
安装 二进制安装 Kind 使用 Golang 进行开发，在仓库的 Release 页面，已经上传了构建好的二进制，支持多种操作系统，可直接按需下载进行使用。
e.g.
# 下载最新的 0.2.0 版本 wget -O /usr/local/bin/kind https://github.com/kubernetes-sigs/kind/releases/download/0.2.0/kind-linux-amd64 &amp;amp;&amp;amp; chmod +x /usr/local/bin/kind 通过源码安装 如果你本地已经配置好了 Golang 的开发环境，那你可以直接通过源码进行安装。
e.g.
go get -u sigs.k8s.io/kind 运行完上述命令后，会将 kind 的可执行文件放到 $(go env GOPATH)/bin 文件夹内，你可能需要将此目录加入到 $PATH 中。
或者也可以先 clone 源代码再通过 go build 进行构建。</description></item><item><title>K8S 生态周报| 2019.03.18~2019.03.24</title><link>https://moelove.info/2019/03/25/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.03.18~2019.03.24/</link><pubDate>Mon, 25 Mar 2019 20:49:06 +0800</pubDate><guid>https://moelove.info/2019/03/25/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.03.18~2019.03.24/</guid><description>我将从本篇开始维护「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。
Docker 6 岁啦 Docker 从 2013 年首次亮相，至今已 6 年之久，而 Docker 也已一度成为容器技术的代名词，很庆幸能投身 Docker 相关的领域。官方博客
Kind (Kubernetes In Docker) 发布 0.2.0 版本 Kind 是一个利用容器技术快速部署本地 Kubernetes 的工具，主要是用于对 Kubernetes 1.11+ 版本的测试。现在发布的 0.2.0 版本支持最新 Kubernetes v1.13.4 及 Docker 18.06.3 且通过了 CNCF 的一致性认证。
Rancher 发布 K8S 最佳安全实践文章 Rancher 在 CNCF 最近发布的 9 个 Kubernetes 最佳安全实践的基础上发布了一篇更安全的最佳实践，这两篇文章都值得一看。
可以通过下面二维码订阅我的文章公众号【MoeLove】</description></item><item><title>恭喜 containerd 毕业</title><link>https://moelove.info/2019/03/01/%E6%81%AD%E5%96%9C-containerd-%E6%AF%95%E4%B8%9A/</link><pubDate>Fri, 01 Mar 2019 10:18:20 +0800</pubDate><guid>https://moelove.info/2019/03/01/%E6%81%AD%E5%96%9C-containerd-%E6%AF%95%E4%B8%9A/</guid><description>今年的第一篇文章更新，带来一个重大的消息。
CNCF（云原生计算基金会）在美国时间 2019 年 2 月 28 日宣布 containerd 今天正式毕业了。
这是 CNCF 中毕业的第 5 个项目，之前已经毕业的项目为 Kubernetes、Prometheus、Envoy 和 CoreDNS 。
containerd 2014 年从 Docker 孵化出来，最初是作为 Docker 引擎的底层管理器；在 2017 年 3 月被 CNCF 接受后，containerd 几乎成为了行业容器运行引擎的标准，它专注于简单，健壮和可移植性，任何人都可以使用它来构建自己的容器引擎/平台。
“When Docker contributed containerd to the community, our goal was to share a robust and extensible runtime that millions of users and tens of thousands of organizations have already standardized on as part of Docker Engine,” said Michael Crosby, containerd maintainer and Docker engineer.</description></item><item><title>2018 小回顾</title><link>https://moelove.info/2018/12/29/2018-%E5%B0%8F%E5%9B%9E%E9%A1%BE/</link><pubDate>Sat, 29 Dec 2018 20:43:00 +0800</pubDate><guid>https://moelove.info/2018/12/29/2018-%E5%B0%8F%E5%9B%9E%E9%A1%BE/</guid><description>年底了，惯例做个小回顾，对这一年做个总结，也对下一年大致做个规划。
不过今儿与往年不同的是昨晚突然发高烧，今儿都没能去上班，感谢我的小可爱在照顾我。这篇文章也是躺在床上用手机编辑的。
还是按照惯例从工作，生活两方面来说。先聊聊工作。
工作 现在在网易有道负责 DevOPS 实践落地及 k8s 容器化平台和自动化平台的规划建设等。
总体来说，现在的工作很开心，更能发挥我的所长，也遇到了不错的团队。
说到现在负责的工作，如果大致有些了解的就会知道这个过程比较漫长，推进起来也会有各种阻力。毕竟要改变很多人的思想和习惯，我也在尽量让这一过程变的更加平滑。
同时也在 push 一些理念到行业内，到社区中，不断的进行交流碰撞总结。
社区贡献 今年下半年的贡献和分享相比去年更多一些。主要的分享有:
GITC - 《云原生时代下的 CI/CD 实践》 PyCon China - 《基于 Docker 的 CI/CD 实践》 DockerOne 社区 - 《基于 GitLab 的 CI 实践》 Tech Talk Time - 《Docker 实战和基础架构》 分享的主题基本都围绕在容器化和 CI/CD 方面，但每次分享内容却都不一样。 感谢我的小可爱，也感谢所有支持的朋友们。
社区中主要活跃在 Docker 和 Kubernetes 生态方向。维护一些官方镜像，做测试，解决问题，提交代码之类的，明年希望做的更多。
开了一个知乎专栏 『k8s生态』 明年会花更多时间进行建设。 写了一本掘金小册《Kubernetes 从上手到实践》。 其实这个名字并不能很好的概括小册里面的内容，其中也有源码分析之类的。要再次感谢小可爱，感谢编辑 Linmi ，感谢马达老板和何世友老板写的推荐语。也感谢所有人的支持，希望这本小册能对大家有所帮助。 写小册的过程其实也蛮辛苦的，一般要么晚上写，写到凌晨 2~3 点，要么早上 5~6 点钟左右起床，写到去上班。尤其要感谢小可爱，给了我很多支持。</description></item><item><title>《Kubernetes从上手到实践》正式上线</title><link>https://moelove.info/2018/12/27/Kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5%E6%AD%A3%E5%BC%8F%E4%B8%8A%E7%BA%BF/</link><pubDate>Thu, 27 Dec 2018 11:16:21 +0800</pubDate><guid>https://moelove.info/2018/12/27/Kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5%E6%AD%A3%E5%BC%8F%E4%B8%8A%E7%BA%BF/</guid><description> 时间飞逝，转眼已经到了圣诞节，今年又要结束了。感谢还在关注的小伙伴，今年确实更新很少，能不取关的都是真爱&amp;hellip;
今年发生了很多事情，留着过几天年终总结的时候再说。有很大一部分的休息时间都用来完成了我的第一本掘金小册 《Kubernetes 从上手到实践》
小册已经正式上线，特意送上各位小伙伴一份礼物，小册 8 折优惠。直接扫码 或者点击此链接即可。
以下是关于小册的一些介绍：
随着容器化及微服务等概念的普及，各个公司都在围绕着如何打造生产环境可用的，高效的容器调度平台，应用快速部署，扩容等平台进行探索。Kubernetes 是 Google 在 2014 年基于其多年在 Borg 系统实践总结出的经验而开源出的一套标准化，可扩展的系统。
而发展至现在（2018年）Kubernetes 已经基本成为了容器编排领域事实上的标准，并且大量的公司都已在生产中使用，无论是国外的 Google， Amazon, GitHub 等，还是国内的阿里，腾讯，京东，滴滴及其他中小公司都在进行着大量的探索及实践。
之前在容器化尚未大量推进的时候，开发工程师只需要关注自己业务代码的实现，而运维工程师在反复的为部署，扩容所需的环境而费时费力。
为了解决环境一致性的问题，也为了能够提高资源的利用率，容器化开始逐步推进，开发工程师的交付由原先的交付代码变成了交付镜像，运维工程师可以将精力集中于保障服务的可高用上。
但为了能够快速的发版验证功能，不再受单体化架构的拖累，微服务的概念也在实践中逐步推进，从原先的单体集中式的服务，拆分为多个松耦合的微服务。到了这时，微服务 + 容器化已经大势所趋，生产中要大量使用，则容器编排变的愈发重要。Kubernetes 在容器编排领域目前已成为事实上的标准，大量公司均已在生产中推进，此时，无论是开发工程师还是运维工程师，皆需要了解并掌握 Kubernetes 的基础技能，才不至于丢失自己的竞争力。
Kubernetes 所涉及的知识点很多, 并且版本迭代也很快，本小册将集中于 Kubernetes 的基础技能，以最常见 Case 入手，帮助大家更快的掌握相关知识并将其用于生产实践中。同时在此过程中，也会深入至 Kubernetes 必要的原理中，同时也会提供相关涉及到的 Docker 及 Linux 内核知识的补充，以便让大家不仅知其然，而且知其所以然。
你会学到什么？ Kubernetes 基础架构 Kubernetes 的基础技能, 覆盖常见 Case 从零搭建 Kubernetes 集群 与 Kubernetes 相关的 Docker 和 Linux 内核知识补充 深入 Kubernetes 组件的原理和源码解析 了解 Kubernetes 进阶相关知识体系 适宜人群 了解 Docker，希望能进入 K8S 领域的各领域工程师； 正在或即将在生产环境使用 K8S 的后端工程师； 需要维护或在公司落地 K8S 的运维工程师； 想要走在技术前沿的前端/后端/运维工程师； 准备查缺补漏的容器相关开发工程师；</description></item></channel></rss>