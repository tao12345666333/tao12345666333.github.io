<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>MoeLove</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><script async src=//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script><script>(adsbygoogle=window.adsbygoogle||[]).push({google_ad_client:"ca-pub-1876963677156202",enable_page_level_ads:true});</script><meta name=author content="张晋涛"><meta name=description content="Jintao Zhang's Blog MoeLove. Container, Docker, Go, Kubernetes, Python, Vim."><meta name=keywords content="MoeLove,Linux,Docker,Kubernetes,Golang,Python,Container,Vim,容器,k8s"><meta name=baidu-site-verification content="jO2rMlnjJi"><meta name=google-site-verification content="googlefe3fc086c62f7210.html"><meta name=generator content="Hugo 0.62.2 with theme even"><link rel=canonical href=https://moelove.info/><link href=https://moelove.info/index.xml rel=alternate type=application/rss+xml title=MoeLove><link href=https://moelove.info/index.xml rel=feed type=application/rss+xml title=MoeLove><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link href=/sass/main.min.8c3cbcb0324c2bb4875ceccba4007cbad4b4ac8377f33af9953c3e7684534a50.css rel=stylesheet><link href=/lib/fancybox/jquery.fancybox-3.1.20.min.css rel=stylesheet><meta property="og:title" content="MoeLove"><meta property="og:description" content="Jintao Zhang's Blog MoeLove. Container, Docker, Go, Kubernetes, Python, Vim."><meta property="og:type" content="website"><meta property="og:url" content="https://moelove.info/"><meta property="og:updated_time" content="2020-12-19T23:58:34+08:00"><meta itemprop=name content="MoeLove"><meta itemprop=description content="Jintao Zhang's Blog MoeLove. Container, Docker, Go, Kubernetes, Python, Vim."><meta name=twitter:card content="summary"><meta name=twitter:title content="MoeLove"><meta name=twitter:description content="Jintao Zhang's Blog MoeLove. Container, Docker, Go, Kubernetes, Python, Vim."><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>MoeLove</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/about/><li class=mobile-menu-item>About</li></a><a href=/friends/><li class=mobile-menu-item>Friends</li></a><a href=/projects/><li class=mobile-menu-item>Projects</li></a><a href=/post/><li class=mobile-menu-item>Archives</li></a><a href=/tags/><li class=mobile-menu-item>Tags</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>MoeLove</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/about/>About</a></li><li class=menu-item><a class=menu-item-link href=/friends/>Friends</a></li><li class=menu-item><a class=menu-item-link href=/projects/>Projects</a></li><li class=menu-item><a class=menu-item-link href=/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=/tags/>Tags</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><section id=posts class=posts><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/09/20/%E7%AA%81%E7%A0%B4-DockerHub-%E9%99%90%E5%88%B6%E5%85%A8%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F%E6%9C%8D%E5%8A%A1/>突破 DockerHub 限制，全镜像加速服务</a></h1><div class=post-meta><span class=post-time>2020-09-20</span></div></header><div class=post-content><div class=post-summary>最近 DockerHub 修改了定价，对于免费帐号会限制 200 pulls/6小时，对于匿名帐号则限制 100 pulls/6小时。 本文我来介绍下如何使用 Cache 来应对此问题。
背景 DockerHub 是全世界最早也是最大的容器镜像仓库，托管着众多操作系统发行版及各类软件的 Docker 镜像。
在推进业务容器化的过程中，不可避免的，我们会需要使用来自 DockerHub 上的容器镜像。 无论是在个人本地环境中使用，还是用于跑测试服务
以下是两种主要的解决方案：
构建一些公共基础镜像，存放在企业的私有镜像仓库中给业务方使用：
这种方案下，如果业务方偶尔需要一些小众的/非基础的镜像，可能只是临时测试使用，那通常情况下是没必要将此类镜像作为基础镜像维护的。
结果可能是：
使用中直接从 DockerHub pull 镜像，网络状况不佳时，就是无尽的等待； 先 pull 镜像，然后 docker tag 重 tag 后， push 到企业的私有镜像仓库中。这种情况下，如果没有较好的镜像管理规则，那么镜像仓库中就会存在各种无意义的镜像，造成存储资源的浪费。 为 docker daemon 配置 Proxy 进行加速：
众多国内镜像加速服务，仅提供 Docker 官方镜像的加速服务，个人/组织下的镜像不提供加速服务； 即使在不同节点上，下载相同的镜像，仍然需要通过网络加速，会产生额外的海外带宽成本； 并且近期 DockerHub 修改了其服务价格, 对于免费用户，进行了如下限制：
未登录用户，每 6 小时只允许 pull 100 次 已登录用户，每 6 小时只允许 pull 200 次 如果我们继续使用上述两种模式的话，由于出口 IP 是相对固定的，所以很容易触发 DockerHub 的配额限制。 此限制将于 11 月 1 日正式全面实施。</div><div class=read-more><a href=/2020/09/20/%E7%AA%81%E7%A0%B4-DockerHub-%E9%99%90%E5%88%B6%E5%85%A8%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F%E6%9C%8D%E5%8A%A1/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/09/13/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Istio-v1.7.1-%E5%8F%91%E5%B8%83/>K8S 生态周报| Istio v1.7.1 发布</a></h1><div class=post-meta><span class=post-time>2020-09-13</span></div></header><div class=post-content><div class=post-summary>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Istio v1.7.1 发布 这是 Istio v1.7 系列的第一个 patch 版本。此次更新有些值得注意的内容：
#26625 修复了 istioctl x authz check 使其能更好的兼容 v1beta1 AuthorizationPolicy ； #26617 修复了 headless services endpoint 更新不会触发任何 xds pushes 的问题； ##26938 修复了当使用 IstioCNI 时 remove-from-mesh 未移除 init container 的问题； Rook v1.4.3 发布 这是个 patch 版本，主要修复了一些和 Ceph 有关的问题, 以及引入了一些小功能：
修复：
#6232 由于 Ceph-CSI driver 在某些集群中会把垃圾回收清理掉，所以创建 csidriver 对象时不再为它设置 ownerRef 了。主要是因为 csidriver 是集群级别的对象，不应该将 namespace 级别的对象设置为它的 ownerRef； 修改：</div><div class=read-more><a href=/2020/09/13/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Istio-v1.7.1-%E5%8F%91%E5%B8%83/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/09/05/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-%E6%98%AF%E6%97%B6%E5%80%99%E4%BB%8E-k8s-v1.16-%E5%8D%87%E7%BA%A7%E4%BA%86/>K8S 生态周报| 是时候从 k8s v1.16 升级了</a></h1><div class=post-meta><span class=post-time>2020-09-05</span></div></header><div class=post-content><div class=post-summary>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kubernetes v1.16.15 发布 Kubernetes v1.16.15 是 v1.16 系列的最后一个更新，我在之前的周报中也有介绍过。
是时候考虑将 v1.16 升级至更高版本了！
以下介绍从 v1.16 升级至 v1.17 需要关注的一些重点。
etcd 就外部依赖而言，最主要的变化是 etcd 从 v3.3.13 升级到了 v3.4.3 。
在升级 etcd 前，我建议你先阅读下 etcd 的升级文档。 我从中说几个重点内容：
In the general case, upgrading from etcd 3.3 to 3.4 can be a zero-downtime, rolling upgrade:
one by one, stop the etcd v3.3 processes and replace them with etcd v3.4 processes</div><div class=read-more><a href=/2020/09/05/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-%E6%98%AF%E6%97%B6%E5%80%99%E4%BB%8E-k8s-v1.16-%E5%8D%87%E7%BA%A7%E4%BA%86/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/09/02/%E8%A2%AB-Google-%E9%80%89%E6%8B%A9%E7%9A%84%E4%B8%8B%E4%B8%80%E4%BB%A3%E6%95%B0%E6%8D%AE%E9%9D%A2-Cilium-%E6%98%AF%E4%BB%80%E4%B9%88/>被 Google 选择的下一代数据面 Cilium 是什么</a></h1><div class=post-meta><span class=post-time>2020-09-02</span></div></header><div class=post-content><div class=post-summary>背景 在我之前的文章 K8S 生态周报| Google 选择 Cilium 作为 GKE 下一代数据面 一文中，我介绍了 Google 宣布使用 Cilium 作为 GKE 的下一代数据面，及其背后的故事。
Google 选择 Cilium 主要是为了增加 GKE 平台的容器安全性和可观测性。那么，Cilium 到底是什么，为什么会有这么强的吸引力呢？
摘一段官网的介绍：
Cilium is open source software for transparently securing the network connectivity between application services deployed using Linux container management platforms like Docker and Kubernetes.
Cilium 是一个用于透明保护部署在 Linux 容器管理平台（比如 Docker 和 Kubernetes）上的应用服务之间网络连接的开源软件。
为什么着重强调是 “Linux 容器管理平台” 呢？这就不得不提到 Cilium 的实现了。Cilium 的基础是一种称为 eBPF 的 Linux 内核技术，使用 eBPF 可以在 Linux 自身内部动态的插入一些控制逻辑，从而满足可观察性和安全性相关的需求。</div><div class=read-more><a href=/2020/09/02/%E8%A2%AB-Google-%E9%80%89%E6%8B%A9%E7%9A%84%E4%B8%8B%E4%B8%80%E4%BB%A3%E6%95%B0%E6%8D%AE%E9%9D%A2-Cilium-%E6%98%AF%E4%BB%80%E4%B9%88/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/08/28/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Kubernetes-v1.19-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/>K8S 生态周报| Kubernetes v1.19 正式发布</a></h1><div class=post-meta><span class=post-time>2020-08-28</span></div></header><div class=post-content><div class=post-summary>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kubernetes v1.19 正式发布 本周 Kubernetes v1.19 正式发布，这是今年发布的第二个版本，也是耗时最长的一个版本。
在此版本中有 34 个增强功能，其中 10 个GA，15 个 beta 以及 9 个 alpha。并且从 v1.19 开始，Kubernetes 每个版本的支持周期延长至 1 年。（感谢[ Long Term Support (LTS) working group ]（https://github.com/kubernetes/community/tree/master/wg-lts#readme &ldquo;LTS WG&rdquo;））
关于此版本中重要的变更，可参考我每期周报中 “上游进展” 的部分。或者直接参考 官方博客中 v1.19 的介绍文章 。
这里我来单独介绍一个更具体且实用的特性。
API 弃用规则 Kubernetes 是一个庞大的系统，当讨论它的 API 时，我们不得不提到常用的 4 个术语，即：group（组）, version（版本）, kind（类型）和 resource（资源）。
一个 API group 是一组相关功能的集合，group + version 是确保 API 可随着时间推移，进行版本升级或功能更新的基础。
这里我来介绍下 自 Kubernetes v1.19 开始 针对 REST 资源（aka API 对象）在弃用策略相关的变更。</div><div class=read-more><a href=/2020/08/28/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Kubernetes-v1.19-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/08/23/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Google-%E9%80%89%E6%8B%A9-Cilium-%E4%BD%9C%E4%B8%BA-GKE-%E4%B8%8B%E4%B8%80%E4%BB%A3%E6%95%B0%E6%8D%AE%E9%9D%A2/>K8S 生态周报| Google 选择 Cilium 作为 GKE 下一代数据面</a></h1><div class=post-meta><span class=post-time>2020-08-23</span></div></header><div class=post-content><div class=post-summary>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Google 选择 Cilium 作为 GKE 网络的数据面 Google 声明将选择 Cilium 作为 GKE 网络的数据面 V2 以便增加其容器安全性和可观测性。
Kubernetes 最强的能力之一便是其开发者优先的网络模型，可以提供简单易用的功能，比如： L3/L4 service 和 L7 ingress 以便将流量引入 Kubernetes 集群，以及多租户的网络隔离等。
但随着越来越多的企业使用 Kubernetes , 用例范围越来越广，围绕多云，安全性，可观察性和可扩展性等方面均提出了新的要求。此外，诸如 service mesh 和 serverless 等技术，均需要来自底层 Kubernetes 的更多自定义。这些新要求最终汇聚到一起得出来的结论便是： 需要一个更具可编程性的数据平面，该平面可执行 Kubernetes 感知的数据包操作，并且还不会损失性能。
Cilium 的出现恰恰满足了这些需求，它基于 eBPF 技术的实现，使 Linux 内核具备了 Kubernetes 的意识。它可以很好的满足现在新的对容器负载的可伸缩性，可观察性以及安全等方面相关的要求。此外， Cilium 所提供的功能也远超了传统 CNI 提供的功能，不仅有传统的 Network Policy， service 和 LB ，还有 Flow & Policy logging 以及内置运维和安全侧的 metrics 等。
背后的故事 Google 首次参与 Cilium 项目大概是去年 12 月，后来越来越多的 Google 工程师加入进来，也贡献了很多核心功能，比如上文中提到的 Policy Logging 等功能。此外还有很多，比如自动检测 EndpointSlices ，对 Pod IP 的 IPv6 邻居发现的支持，还有基于 socket cookie 的负载均衡等。</div><div class=read-more><a href=/2020/08/23/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Google-%E9%80%89%E6%8B%A9-Cilium-%E4%BD%9C%E4%B8%BA-GKE-%E4%B8%8B%E4%B8%80%E4%BB%A3%E6%95%B0%E6%8D%AE%E9%9D%A2/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/08/15/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Helm-v2-%E8%BF%9B%E5%85%A5%E7%BB%B4%E6%8A%A4%E6%9C%9F%E5%80%92%E8%AE%A1%E6%97%B6/>K8S 生态周报| Helm v2 进入维护期倒计时</a></h1><div class=post-meta><span class=post-time>2020-08-15</span></div></header><div class=post-content><div class=post-summary>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Helm v2 将正式废弃 本周，Helm v2 系列发布了 v2.16.10 版本， 这是 Helm v2 的最后一个 bugfix 版本，此后不会再为 Helm v2 提供错误修复。并且在三个月后，将停止为 Helm v2 提供安全补丁。届时， Helm v2 也就完全废弃，不会再去维护了。
如果有在使用 Helm v2 的小伙伴，请尽快升级至 Helm v3， 社区也提供了 Helm 2to3 的工具，可以帮助迁移。
另外，还有个别厂商绑定 Helm v2 提供应用安装/部署服务的，也建议尽快迁移了。
我统计了下，我发布的文章中，有 25 篇与 Helm 相关。包括 Helm v3 的尝试，Helm v2 的废弃计划，从 Helm v2 迁移到 v3 等内容，感兴趣的小伙伴可以看看历史文章。
DockerHub 修改了定价和 TOS DockerHub 本周对其服务收费以及 TOS（Terms of Service）。我们重点来看看本次的修改对我们会有哪些影响吧。
这里重点来看看对免费用户/（未登录）匿名用户的影响。
流量限制</div><div class=read-more><a href=/2020/08/15/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Helm-v2-%E8%BF%9B%E5%85%A5%E7%BB%B4%E6%8A%A4%E6%9C%9F%E5%80%92%E8%AE%A1%E6%97%B6/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/08/09/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-runc-v1.0-rc92-%E5%8F%91%E5%B8%83/>K8S 生态周报| runc v1.0-rc92 发布</a></h1><div class=post-meta><span class=post-time>2020-08-09</span></div></header><div class=post-content><div class=post-summary>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
微软开源了 Open Service Mesh 微软近期开源了一个新的名为 Open Service Mesh 的项目并准备捐赠给 CNCF 。
OSM 主打轻量&可扩展，支持 Service Mesh Interface (SMI) 规范 附带开箱即用的可观察性功能。截至目前，已经发布了v0.2.0 版本。
主要特性如下：
支持 Service Mesh Interface (SMI) 的规范，主要包括 Traffic Access Control， Traffic Specs 和 Traffic Split 。剩下的 Traffic Metrics 正在开发中； 服务间的通信加密使用 mTLS ； 定义和执行服务间的访问控制策略； 通过 Prometheus 和 Grafana 完成其观察性； 可与外部证书管理服务进行集成； Envoy sidecar 自动注入； 关于 Open Service Mesh 更详细的内容，请参考我上一篇文章 初试 Open Service Mesh（OSM）</div><div class=read-more><a href=/2020/08/09/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-runc-v1.0-rc92-%E5%8F%91%E5%B8%83/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/08/07/%E5%88%9D%E8%AF%95-Open-Service-MeshOSM/>初试 Open Service Mesh（OSM）</a></h1><div class=post-meta><span class=post-time>2020-08-07</span></div></header><div class=post-content><div class=post-summary>微软近期开源了一个新的名为 Open Service Mesh 的项目并准备捐赠给 CNCF 。
基本介绍 Open Service Mesh (OSM) is a lightweight, extensible, Cloud Native service mesh that allows users to uniformly manage, secure, and get out-of-the-box observability features for highly dynamic microservice environments.
Open Service Mesh（OSM）是一个轻量级，可扩展的云原生服务网格，它使用户能够统一管理，保护和获得针对高度动态微服务环境的开箱即用的可观察性功能。
OSM 在 Kubernetes 上运行基于 Envoy 的控制平面，可以使用 SMI API 进行配置。它通过以 sidecar 的形式注入 Envoy 代理来工作。
控制面负责持续配置代理，以配置策略和路由规则等都保持最新。代理主要负责执行访问控制的规则，路由控制，采集 metrics 等。（这和目前我们常见到的 Service Mesh 方案基本都一样的）
显著特性 基于 Service Mesh Interface (SMI) 的实现，主要包括 Traffic Access Control， Traffic Specs 和 Traffic Split 。剩下的 Traffic Metrics 正在开发中； 服务间的通信加密使用 mTLS ； 定义和执行服务间的访问控制策略； 通过 Prometheus 和 Grafana 完成其观察性； 可与外部证书管理服务进行集成； Envoy sidecar 自动注入； 上手体验 只做介绍未免太过无趣，而且说实话，这么多 service mesh 实现，不亲自上手试试看，感觉不出来太多差异的。</div><div class=read-more><a href=/2020/08/07/%E5%88%9D%E8%AF%95-Open-Service-MeshOSM/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/08/02/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Istio-%E5%B7%B2%E4%BF%AE%E5%A4%8D%E5%AF%BC%E8%87%B4-Pod-%E5%B4%A9%E6%BA%83%E7%9A%84-bug/>K8S 生态周报| Istio 已修复导致 Pod 崩溃的 bug</a></h1><div class=post-meta><span class=post-time>2020-08-02</span></div></header><div class=post-content><div class=post-summary>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Istio 1.6.7 发布 Istio 1.6.7 是为了解决在 1.6.6 中引入的一个 bug。
该 bug 可能会导致 在使用 Istio 1.6.6 时，某些 Pod 进入 CrashLoopBackOff 状态，无法正常提供服务。
修复后的核心代码如下，这里主要是增加另一个返回值 expectpod 。
通过此方法获取 Pod 时，Pod 有两种情况可能为空：
该 endpoint 未关联 Pod，这时 expectpod 为 false； 该 endpoint 已关联 Pod，但未找到 Pod，这时 expectpod 为 true 而这种情况发生的最主要原因可能是由于最终一致性，或者乱序事件等。
建议如果打算升级 Istio 的读者，直接跳过 1.6.6 版本，以免影响到服务。
func getPod(c *Controller, ip string, ep *metav1.ObjectMeta, targetRef *v1.ObjectReference, host host.Name) (rpod *v1.Pod, expectPod bool) { pod := c.</div><div class=read-more><a href=/2020/08/02/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Istio-%E5%B7%B2%E4%BF%AE%E5%A4%8D%E5%AF%BC%E8%87%B4-Pod-%E5%B4%A9%E6%BA%83%E7%9A%84-bug/ class=read-more-link>阅读更多</a></div></div></article></section><nav class=pagination><a class=prev href=/><i class="iconfont icon-left"></i><span class=prev-text>上一页</span></a>
<a class=next href=/page/3/><span class=next-text>下一页</span>
<i class="iconfont icon-right"></i></a></nav></div></div></main><footer id=footer class=footer><div class=social-links><a href=mailto:zhangjintao9020@gmail.com class="iconfont icon-email" title=email></a><a href=https://twitter.com/BeierTao class="iconfont icon-twitter" title=twitter></a><a href=https://github.com/tao12345666333 class="iconfont icon-github" title=github></a><a href=http://weibo.com/9020taobeier class="iconfont icon-weibo" title=weibo></a><a href=https://www.zhihu.com/people/TaoBeier class="iconfont icon-zhihu" title=zhihu></a><a href=https://moelove.info/index.xml type=application/rss+xml class="iconfont icon-rss" title=rss></a></div><div class=copyright><span class=power-by>由 <a class=hexo-link href=https://gohugo.io>Hugo</a> 强力驱动</span>
<span class=division>|</span>
<span class=theme-info>主题 -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a></span>
<span class=copyright-year>&copy;
2013 -
2020
<span class=heart><i class="iconfont icon-heart"></i></span><span class=author>张晋涛</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script><script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script><script type=text/javascript src=/lib/fancybox/jquery.fancybox-3.1.20.min.js></script><script type=text/javascript src=/js/main.min.d7b7ada643c9c1a983026e177f141f7363b4640d619caf01d8831a6718cd44ea.js></script></body></html>