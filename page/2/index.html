<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>MoeLove</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><script async src=//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script><script>(adsbygoogle=window.adsbygoogle||[]).push({google_ad_client:"ca-pub-1876963677156202",enable_page_level_ads:true});</script><meta name=author content="张晋涛"><meta name=description content="Jintao Zhang's Blog MoeLove. Container, Docker, Go, Kubernetes, Python, Vim."><meta name=keywords content="MoeLove,Linux,Docker,Kubernetes,Golang,Python,Container,Vim,容器,k8s"><meta name=baidu-site-verification content="jO2rMlnjJi"><meta name=google-site-verification content="googlefe3fc086c62f7210.html"><meta name=generator content="Hugo 0.55.6"><link rel=canonical href=https://moelove.info/><link href=https://moelove.info/index.xml rel=alternate type=application/rss+xml title=MoeLove><link href=https://moelove.info/index.xml rel=feed type=application/rss+xml title=MoeLove><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link href="/dist/even.min.css?v=3.2.0" rel=stylesheet><link href=/lib/fancybox/jquery.fancybox-3.1.20.min.css rel=stylesheet><meta property="og:title" content="MoeLove"><meta property="og:description" content="Jintao Zhang's Blog MoeLove. Container, Docker, Go, Kubernetes, Python, Vim."><meta property="og:type" content="website"><meta property="og:url" content="https://moelove.info/"><meta property="og:updated_time" content="2020-03-29T21:26:45+08:00"><meta itemprop=name content="MoeLove"><meta itemprop=description content="Jintao Zhang's Blog MoeLove. Container, Docker, Go, Kubernetes, Python, Vim."><meta name=twitter:card content="summary"><meta name=twitter:title content="MoeLove"><meta name=twitter:description content="Jintao Zhang's Blog MoeLove. Container, Docker, Go, Kubernetes, Python, Vim."><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>MoeLove</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/about/><li class=mobile-menu-item>About</li></a><a href=/friends/><li class=mobile-menu-item>Friends</li></a><a href=/projects/><li class=mobile-menu-item>Projects</li></a><a href=/post/><li class=mobile-menu-item>Archives</li></a><a href=/tags/><li class=mobile-menu-item>Tags</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>MoeLove</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/about/>About</a></li><li class=menu-item><a class=menu-item-link href=/friends/>Friends</a></li><li class=menu-item><a class=menu-item-link href=/projects/>Projects</a></li><li class=menu-item><a class=menu-item-link href=/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=/tags/>Tags</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><section id=posts class=posts><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/02/09/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Docker-v19.03.6-rc2-%E5%8F%91%E5%B8%83/>K8S 生态周报| Docker v19.03.6-rc2 发布</a></h1><div class=post-meta><span class=post-time>2020-02-09</span></div></header><div class=post-content><div class=post-summary>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Docker v19.03.6-rc2 发布 自 2019 年 11 月 15 日 Docker v19.03.5 发布后，Docker Inc. 包括社区都发生了不少的变化。
v19.03.6 将会是 v19.03 系列的下一个 bugfix 版本。在此版本中，有几个比较值得注意的内容：
buildkit: 修复了在触发 ONBUILD 规则之后，未清理掉 ONBUILD 规则的问题。对于依赖 ONBUILD 指令，且使用 buildkit 的用户而言是个重要修复； buildkit: 修复了启用了 userns 时，可能导致权限错误的问题； 使用了 libnetwork 的短 ID, 以避免遇到 UNIX_PATH_MAX 的错误; 说到这个问题，其实也蛮有趣的，可能不少人都遇到过类似的问题。当然我也想在这个 UNIX_PATH_MAX 的问题上稍微多聊一点。
这个问题其实在四五年前我在 Docker 项目中其他的部分就遇到过，解决起来也简单就是缩短路径长度即可。但你可能会好奇，要缩短到什么程度呢？多长是合理值呢？
其实这个问题要深究的话，背后有蛮多历史的，这里我先跳过。我主要说下目前的限制是什么，这个限制可以在 Linux 的源码中找到的。
// include/uapi/linux/un.h #ifndef _LINUX_UN_H #define _LINUX_UN_H #include &lt;linux/socket.h> #define UNIX_PATH_MAX 108 struct sockaddr_un { __kernel_sa_family_t sun_family; /* AF_UNIX */ char sun_path[UNIX_PATH_MAX]; /* pathname */ }; #define SIOCUNIXFILE (SIOCPROTOPRIVATE + 0) /* open a socket file with O_PATH */ #endif /* _LINUX_UN_H */ 可以看到现在头文件中定义的是 108 。（ 注意我此处使用的是 Linux 5.</div><div class=read-more><a href=/2020/02/09/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Docker-v19.03.6-rc2-%E5%8F%91%E5%B8%83/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/02/05/%E4%BD%BF%E7%94%A8-Kind-%E5%9C%A8%E7%A6%BB%E7%BA%BF%E7%8E%AF%E5%A2%83%E5%88%9B%E5%BB%BA-K8S-%E9%9B%86%E7%BE%A4/>使用 Kind 在离线环境创建 K8S 集群</a></h1><div class=post-meta><span class=post-time>2020-02-05</span></div></header><div class=post-content><div class=post-summary>Kind 是我很喜欢也一直在参与的项目，我计划将 Kind 相关的文章写成一个系列。这是第二篇。
背景 Kind 是 Kubernetes In Docker 的缩写，顾名思义是使用 Docker 容器作为 Node 并将 Kubernetes 部署至其中的一个工具。现在包括 Kubernetes 自身在内的很多云原生基础项目都将 Kind 应用于自身的 e2e 测试或项目的入门示例中。
默认情况下使用 Kind 创建 Kubernetes 集群，只需要先安装好 Kind 执行 kind create cluster 便可， Kind 会自动下载所需的 Docker 镜像，并启动集群。
但是，在某些情况下，我们也会有需要在离线环境中启动 Kubernetes 集群的需求。本篇文章我来为你介绍两种使用 Kind 在离线环境创建 Kubernetes 集群的方式。
使用预构建镜像 Kind 在每次发布版本时，会同时构建并发布默认使用的镜像，目前托管在 Docker Hub 上。建议你使用在每次 ReleaseNote 中指定了 shasum 的镜像。
当你在离线环境中想要使用 Kind 预构建的镜像创建集群时，你可以在任意可联网的机器上或目标机器上有网络的情况下，提前下载该镜像，并拷贝至需要创建集群的目标机器上。
如果你的机器上已经安装了 Docker，那可以直接使用 docker pull 命令下载镜像：
(MoeLove) ➜ ~ docker pull kindest/node:v1.</div><div class=read-more><a href=/2020/02/05/%E4%BD%BF%E7%94%A8-Kind-%E5%9C%A8%E7%A6%BB%E7%BA%BF%E7%8E%AF%E5%A2%83%E5%88%9B%E5%BB%BA-K8S-%E9%9B%86%E7%BE%A4/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/02/02/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Rook-v1.2.3-%E5%8F%91%E5%B8%83/>K8S 生态周报| Rook v1.2.3 发布</a></h1><div class=post-meta><span class=post-time>2020-02-02</span></div></header><div class=post-content><div class=post-summary>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Rook v1.2.3 发布 Rook 昨天发布了 v1.2.3 版本，此版本中仍然重点是对 Ceph 相关的内容做了改进。值得关注的内容如下：
允许使用 Ceph-CSI v2.0.0 驱动了，不过默认还是使用 CSI v1.2.2 ； 修正了 prepare job 资源配额的处理逻辑； 改善 ceph-volume 的日志输出，暴露每个 pvc ceph-volume 日志； 修正了 CSI 驱动的垃圾回收机制，这个问题根本原因是资源的 OwnerReference 所使用的 API 错了。可能导致的情况是，某些情况下 CSI 相关的 Pod 被清掉了； 对此版本感兴趣的朋友可参考其 ReleaseNote
CoreDNS v1.6.7 发布 本周 CoreDNS v1.6.7 发布了，是个小版本的更新，需要注意的更新如下：
plugin/{kubernetes, etcd}：允许通过 CNAME 解析 TXT 记录。这个更新是为 backend_lookup.go 中的 TXT 方法增加了一个参数，需要注意的是当前已经更新了 kubernetes 和 etcd 插件的相关调用，如果有自己实现或者使用其他第三方 plugin 的话，需要注意。 其他更新请参考 ReleaseNote</div><div class=read-more><a href=/2020/02/02/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Rook-v1.2.3-%E5%8F%91%E5%B8%83/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/01/26/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-runc-v1.0.0-rc10-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/>K8S 生态周报| runc v1.0.0-rc10 正式发布</a></h1><div class=post-meta><span class=post-time>2020-01-26</span></div></header><div class=post-content><div class=post-summary>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kubernetes 发布 v1.18.0-alpha.2 版本 这个版本包含了不少变更，这里列一些我个人感觉比较重要的内容：
修复了一个 kubectl apply --prune 时，未接收 kubectl 指定 namespace 的问题 #85357; 为 kubeadm 在 pull image 时增加了自动重试，默认是 5 次； kubelet 的一些 metrics 标记过期； 可以为 kubelet 传递 --node-ip :: 默认设置 IPv6 地址为主地址了； 关于此版本的其他变更，请查看 ReleaseNote
runc v1.0.0-rc10 正式发布 runc 想必大家不会太陌生，关注我的朋友大多都看到过我之前几篇关于 runc 的文章，这里不再赘述。
本次发布的版本最主要的目的是修复 CVE-2019-19921 ，由于 runc 是个基础软件，目前也已经将 containerd 和 Docker 做了相应的更新升级以应对此漏洞。
关于这个漏洞的修复主要就是避免挂载 /proc 到非目录，以避免攻击者利用软链的方式利用 runc 将 /proc 挂载到其他的地方实现攻击。
另一个重要变更是在 runc 中增加了 cgroups2 的支持。</div><div class=read-more><a href=/2020/01/26/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-runc-v1.0.0-rc10-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/01/19/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Kind-v0.7.0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/>K8S 生态周报| Kind v0.7.0 正式发布</a></h1><div class=post-meta><span class=post-time>2020-01-19</span></div></header><div class=post-content><div class=post-summary>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Kind (Kubernetes in Docker) 正式发布 v0.7.0 Kind (Kubernetes in Docker) 是我很喜欢也一直在参与的项目，现在在 GitHub 上有 4.3k 的 star ，本周正式发布了 v0.7.0 我们一起来看看在此版本中增加了哪些有用的特性。
重大变更 Kubernetes 版本升级，现在默认的 Kubernetes 版本升级为 v1.17.0 , 在 kind v0.6+ 时候默认的 Kubernetes 版本是 v1.16.3; 使用 kind v0.7.0 构建的镜像有很多改进，需要至少 v0.5+ 版本才能保持兼容，如果是想要使用在 v0.7 版本中新增的全部特性，建议同时升级 kind 二进制文件以及更新 node 镜像; 新特性增加 通过集成 rancher.io/localhost-path 提供了开箱即用的动态存储卷的支持； 提供了使用 Ingress 暴露部署在 Kind 中服务的多种方式的文档，包括 Contour 和 NGINX Ingress ; 更新了相关的依赖，包括修复 CNI portmap 插件以提高稳定性； 修复问题 提升日志消息的可读性; 修正 kind load 镜像到 node 节点上之后的检查逻辑； 当默认的 $HOME/.</div><div class=read-more><a href=/2020/01/19/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Kind-v0.7.0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/01/12/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Istio-v1.4.3-%E5%8F%91%E5%B8%83/>K8S 生态周报| Istio v1.4.3 发布</a></h1><div class=post-meta><span class=post-time>2020-01-12</span></div></header><div class=post-content><div class=post-summary>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Prometheus v2.15.2 发布 本周 Prometheus 发布了 v2.15.2 版本，其修复了两个 TSDB 相关的问题。
修复对 2.1.0 之前版本构建的 TSDB 块的支持，这个问题直接影响的是那些直接从 2.1.0 版本之前直接升级到 2.15 的用户，根本原因是在 2.1.0 版本加入的一个对 key 排序的特性； 修复了 TSDB 在 Windows 下的压缩问题； 其他变化，感兴趣的朋友可以参看其 ReleaseNote
Istio v1.4.3 发布 Istio 发布了 v1.4.3 版本，带来了众多 bugfix 和改进，我们来具体看看：
修复了 Mixer 为 secret 创建大量 watcher 可能导致 Kubernetes api-server OOM 的问题 #19481 ; 修复了注入相关的模板。当 POD 有多个 container 但 container 未暴露端口时，istio-proxy 无法启动的问题。#18594；</div><div class=read-more><a href=/2020/01/12/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Istio-v1.4.3-%E5%8F%91%E5%B8%83/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/01/05/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-%E7%BB%88%E7%AB%AF%E4%B8%8B%E7%9A%84-K8S-%E8%B5%84%E6%BA%90%E6%A0%91%E6%9F%A5%E7%9C%8B%E5%99%A8/>K8S 生态周报| 终端下的 K8S 资源树查看器</a></h1><div class=post-meta><span class=post-time>2020-01-05</span></div></header><div class=post-content><div class=post-summary>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
上游进展 Kubernetes v1.17.0 中，如果将 CIDR 设置为低于 /16 位，则 IP 分配器可能会报错。这个问题当前已经在 #86534中修复，将随着 v1.17.1 发布，如果尚未升级至 v1.17.0 的朋友可以稍后； api-server 的 bind-address 最近稍作了调整，如果未指定或者使用 0.0.0.0 或 :: 则会监听本地的所有可用的地址。 项目推荐 kubectl-tree 是一个用于在终端内以树形结构展示 Kubernetes 资源的 Kubectl 插件。（已经登上了 GitHub 的趋势榜）
使用效果如图：
在我的终端下，它不能对齐，不过我还没来得及具体去看原因。
新项目：APISIX-ingress-controller 最近看到一个为 Apache APISIX 实现 Ingress Controller 的项目 APISIX-ingress-controller
同时也看到了一篇文章: 为什么我们重新写了一个 k8s ingress controller 文章的作者解释了为何要重新写一个 Ingress Controller。
在我个人看来，多实现一种 Ingress Controller 对社区而言是好事儿，让大家有了更多的选择，另一方面，这个项目刚起步不久，如果有对实现 APISIX Ingress Controller 感兴趣的朋友可以尽早加入。
( 抛开此项目不谈，单纯谈写一个简单的自定义 Ingress Controller 其实比较简单，倒也挺有趣的，只不过在处理一些高级特性及处理大量请求时，不同的实现会有些区别。 推荐大家都尝试下</div><div class=read-more><a href=/2020/01/05/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-%E7%BB%88%E7%AB%AF%E4%B8%8B%E7%9A%84-K8S-%E8%B5%84%E6%BA%90%E6%A0%91%E6%9F%A5%E7%9C%8B%E5%99%A8/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2020/01/01/2019-%E5%B0%8F%E5%9B%9E%E9%A1%BE/>2019 小回顾</a></h1><div class=post-meta><span class=post-time>2020-01-01</span></div></header><div class=post-content><div class=post-summary>这篇文章起笔于上周（年底），不过工作比较忙，一直耽搁到今天（1 月 1 日）才抽出时间，索性就重写了。算是一篇岁岁念，想到什么就写点。
转眼已是 2020 年 1 月 1 日了，惯例做个小回顾。 2019 年发生了太多事情，非常值得好好回顾一下。每年的回顾不仅是对过去一年的总结，也是对新的一年做个计划。 依旧按照我每年的习惯，分别从工作和生活来聊聊。
工作 2019 年我做的事情，主要涉及以下几个方面：
Docker 容器化和 Kubernetes API Gateway CI/CD 存储 监控 告警信息收敛 也算是比较典型的云原生工程师的工作内容了，感谢同事们的支持和配合。
2019 年是云原生形势大好的一年，这一年整个行业内都发生了不小的变动，关注我每周推送的「k8s 生态周报」的小伙伴可能已经发现，周报中最多的内容是 K8S 生态中比较核心的软件的版本发布及功能变更或漏洞相关的信息。
为什么这类信息会这么多呢？主要还是因为 2019 年云原生或者说 Kubernetes 的普及越来越广泛，需求增多，场景愈发复杂，相应的像 Docker, Kubernetes, Prometheus 这类基础软件也就需要提供更多的特性支持，或者 bugfix 。所以我在这方面投入的时间也就更多一些。
此外，从 19 年 3 月底，我开始了每周 「k8s 生态周报」 的推送，直到今天共计推送了 41 篇周报，未曾落下，也积累了不少读者，感谢大家关注。
今年在 PyCon China 的角色从讲师变成了出品人，原本计划会有一个主题演讲，但是由于跟我的婚礼时间冲突了，所以未能参加。感谢 PyCon China 的一众小伙伴的谅解和支持。
在国庆假期结束后，我在 GitChat 上发布的专栏《Docker 核心知识必知必会》正式上线了，至今专栏内容已经更新了一半，按照 GitChat 的字数统计现在写了大概是 9w 字左右（这个统计包括了我之前发布的五篇 Chat 文章）。感谢我的小可爱一直督促我，感谢编辑们的辛苦，感谢读者的信任和支持。</div><div class=read-more><a href=/2020/01/01/2019-%E5%B0%8F%E5%9B%9E%E9%A1%BE/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2019/12/29/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Prometheus-v2.15.0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/>K8S 生态周报| Prometheus v2.15.0 正式发布</a></h1><div class=post-meta><span class=post-time>2019-12-29</span></div></header><div class=post-content><div class=post-summary>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
Prometheus v2.15.0 正式发布 本周 Prometheus 发布了 v2.15.0 版本，这个版本在 TSDB 方面有诸多改进，以及提升了 PromQL 解析器的性能。
TSDB 方面主要是对内存使用相关的优化。
按照此版本中 对 PromQL 解析器相关变更的 PR，本次解析器性能的提升能达到之前的 7 倍。
同时，此版本中也存在一个 bug，可能会导致并发查询数据时，出现 checksum 不匹配的情况，最直接的影响就是 Grafana 的图表会显示不出来。
所以之后也快速发布了 v2.15.1 版本。建议如果使用 v2.15.0 的朋友可以快速升级至 v2.15.1 以规避此问题。
更多关于此版本的变更，请查看其 ReleaseNote
Rancher v2.4.0-alpha1 发布 Rancher 本周发布了 v2.4.0-alpha1 , 此版本中在用户角色方面有两个挺不错的改进。
管理员可以自定义全局范围内的角色，并且可以让用户登录后默认使用该角色。 在使用外部认证方式时，管理员也可以默认设置属于某个组的用户，默认授予的权限。（比较类似于 Grafana 使用 LDAP 认证时，默认给用户设置的权限，但更灵活一些。) 更多关于此版本的信息，可参考其 ReleaseNote
题外话 这是今年 「K8S 生态周报」的最后一篇了，本篇中没有上游进展，上游最近的变更并不频繁，(大概是年底休假的原因）
从 2019 年 3 月份开始，便一直保持着每周更新。新的一年，我也将继续保持更新，与你分享我所接触到的 K8S 生态相关的每周值得推荐的一些信息。</div><div class=read-more><a href=/2019/12/29/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-Prometheus-v2.15.0-%E6%AD%A3%E5%BC%8F%E5%8F%91%E5%B8%83/ class=read-more-link>阅读更多</a></div></div></article><article class=post><header class=post-header><h1 class=post-title><a class=post-link href=/2019/12/21/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-TUF-%E6%AD%A3%E5%BC%8F%E4%BB%8E-CNCF-%E6%AF%95%E4%B8%9A/>K8S 生态周报| TUF 正式从 CNCF 毕业</a></h1><div class=post-meta><span class=post-time>2019-12-21</span></div></header><div class=post-content><div class=post-summary>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
TUF 正式从 CNCF 毕业 本周 The Update Framework (TUF) 正式从 CNCF 毕业，现在 TUF 的官方 Python 实现有 954 个 star ，142 个 fork 以及 43 位贡献者和 3525 次 commit 记录。
TUF 是从 CNCF 正式毕业的第 9 个项目，没记错的话也是至今为止唯一一个 star 数未上千就正式毕业的项目。不过 TUF 项目本身与其他项目不同，star 数也说明不了项目状态。
可能不少人觉得 TUF 项目的存在感很低，或是没有了解或使用过 TUF 项目，我姑且对它做一点介绍。
TUF 项目大概是十年前启动，并于 2017 年开始托管于 CNCF，它的主要目标正如它的名字一般，提供用于更新的框架，但它更重要的点在于它的安全性设计上。
它充分考虑到了各个环节可能出现的攻击，在提供更新功能的同时，也可以很好的保护现有程序或者是验证待更新版本的安全和可靠性。你可能想问它是如何做到这一点的，其实它主要是提供了一套标准规范，并在各个环节中增加了更多的元数据和相关的检查，包括签名信息，文件 hash ，元数据签名和过期时间等。
至于它的存在感嘛，不知道你是否有使用过 Docker Content Trust(DCT) 相关的功能，简单来说你可以当作就是 docker trust 所涉及到的相关功能，这其中的部分功能是构建在 Docker Notary 之上的，而 Docker Notary 则是使用 TUF 作为其基础安全框架的。(PS：Docker Inc 也已经将 Docker Notary 捐献给了 CNCF)</div><div class=read-more><a href=/2019/12/21/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-TUF-%E6%AD%A3%E5%BC%8F%E4%BB%8E-CNCF-%E6%AF%95%E4%B8%9A/ class=read-more-link>阅读更多</a></div></div></article></section><nav class=pagination><a class=prev href=/><i class="iconfont icon-left"></i><span class=prev-text>上一页</span></a>
<a class=next href=/page/3/><span class=next-text>下一页</span>
<i class="iconfont icon-right"></i></a></nav></div></div></main><footer id=footer class=footer><div class=social-links><a href=mailto:zhangjintao9020@gmail.com class="iconfont icon-email" title=email></a><a href=https://twitter.com/BeierTao class="iconfont icon-twitter" title=twitter></a><a href=https://github.com/tao12345666333 class="iconfont icon-github" title=github></a><a href=http://weibo.com/9020taobeier class="iconfont icon-weibo" title=weibo></a><a href=https://www.zhihu.com/people/TaoBeier class="iconfont icon-zhihu" title=zhihu></a><a href=https://moelove.info/index.xml type=application/rss+xml class="iconfont icon-rss" title=rss></a></div><div class=copyright><span class=power-by>由 <a class=hexo-link href=https://gohugo.io>Hugo</a> 强力驱动</span>
<span class=division>|</span>
<span class=theme-info>主题 -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a></span>
<span class=copyright-year>&copy;
2013 -
2020
<span class=heart><i class="iconfont icon-heart"></i></span><span class=author>张晋涛</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script><script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script><script type=text/javascript src=/lib/fancybox/jquery.fancybox-3.1.20.min.js></script><script type=text/javascript src="/dist/even.min.js?v=3.2.0"></script></body></html>