<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on MoeLove</title>
    <link>https://moelove.info/post/</link>
    <description>Recent content in Posts on MoeLove</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Sun, 05 May 2019 21:59:07 +0800</lastBuildDate>
    
	<atom:link href="https://moelove.info/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>K8S 生态周报| 2019-04-28~2019-05-05</title>
      <link>https://moelove.info/2019/05/05/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-04-28~2019-05-05/</link>
      <pubDate>Sun, 05 May 2019 21:59:07 +0800</pubDate>
      
      <guid>https://moelove.info/2019/05/05/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-04-28~2019-05-05/</guid>
      <description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
 Docker Hub 只读维护 在上周的推送中，有写到 Docker Hub 用户隐私数据泄漏。受此事件影响，5 月 4 日 Docker Hub 进行升级维护，在此期间 Docker Hub 有一段时间处于只读模式，包括自动构建等服务不可用；在最后有小于 15 分钟的完全宕机时间，服务完全不可用。
如果只是看事情表面的话，可能这就是一个由于发现“安全问题”而进行的升级/维护；但如果仔细考虑下，作为云原生服务，升级为何会有宕机的情况，为何会有服务完全不可用的时候？
摘录一段来自本次维护的公告内容：
 Q: Is this maintenance related to recent Docker Hub data breach?
A: While we discovered unauthorized access to a single Hub database storing a subset of non-financial user data last week, which has since been remediated, we are always looking at ways to improve and enhance our security practices to protect our customers and their data.</description>
    </item>
    
    <item>
      <title>K8S 生态周报| 2019-04-22~2019-04-28</title>
      <link>https://moelove.info/2019/04/29/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-04-22~2019-04-28/</link>
      <pubDate>Mon, 29 Apr 2019 00:36:25 +0800</pubDate>
      
      <guid>https://moelove.info/2019/04/29/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-04-22~2019-04-28/</guid>
      <description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
 Docker Hub 用户隐私数据泄漏 2019 年 4 月 25 日，Docker Hub 团队发现了对存储非财务用户数据子集的单个 Hub 数据库的未授权访问。 在发现异常后官方团队迅速采取行动并保护网站免受攻击。
经过官方团队的调查，目前大概有 190000 帐号的敏感信息（小于总用户数的 5% ）包括用户名和哈希后的用户密码，当然也包括 GitHub 及 Bitbucket 等的用于自动构建的 Token 。
当前的主要措施是对可能被泄漏信息的用户发送了邮件通知，对于可能泄漏哈希密码的用户发送了重置密码的邮件，并且 主动 将密码失效，以及自动构建的 Token 也都被失效。( 所以如果你收到了 Docker Hub 团队关于此次事件的直接报告邮件，很大概率是因为你的信息已经被泄漏了 )
附上官方声明中关于此次事件的处理声明：
 During a brief period of unauthorized access to a Docker Hub database, sensitive data from approximately 190,000 accounts may have been exposed (less than 5% of Hub users).</description>
    </item>
    
    <item>
      <title>K8S 生态周报| 2019-04-15~2019-04-21</title>
      <link>https://moelove.info/2019/04/21/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-04-15~2019-04-21/</link>
      <pubDate>Sun, 21 Apr 2019 21:46:02 +0800</pubDate>
      
      <guid>https://moelove.info/2019/04/21/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019-04-15~2019-04-21/</guid>
      <description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
 Prometheus v2.9.0 正式发布 Prometheus 是 CNCF 毕业项目，可用于监控系统及服务状态。它整体是使用 Pull 的模式，在周期时间内采集目标的 metrics ，并且提供了 PromQL 的查询语言，以供对监控数据进行查询过滤等操作。并且可以通过配置规则来触发报警等。我首次接触 Prometheus 大概是在 2015 年 0.15.0 版本左右，当时 Prometheus 还处于比较早期的阶段，不过在进入 CNCF 后，Prometheus 基本就成为了 K8S 监控的实施标准了，并且多数软件也都增加了对 Prometheus metrics 的支持。
v2.9.0 的主要更新：
 从 2.8 开始引入了的从 WAL 读取进行 remote write 有时候会丢数据的问题已经得到修复； Kubernetes 和 OpenStack 在服务发现时候增加了更多元数据； Consul 现在支持多 tag； 添加了一个 honor_timestamps 的选项； TLS 证书会自动从磁盘加载； 日志也变的更易读；  其他更新请阅读 ReleaseNote
Linkerd 2.3 正式发布 Linkerd 是一个 service mesh 旨在提供平台范围的可观察性，可靠性和安全性，而无需用户更改代码。在本月初的周报推送中，推荐了一篇关于 Linkerd v2 从产品中吸取的教育和经验的文章，Linkerd v2 使用 Go 和 Rust 进行了重写，并因此获得了巨大的收益。</description>
    </item>
    
    <item>
      <title>K8S 生态周报| 2019.04.08~2019.04.14</title>
      <link>https://moelove.info/2019/04/14/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.04.08~2019.04.14/</link>
      <pubDate>Sun, 14 Apr 2019 22:53:09 +0800</pubDate>
      
      <guid>https://moelove.info/2019/04/14/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.04.08~2019.04.14/</guid>
      <description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
 CRI-O 成为 CNCF 托管项目 CRI-O 是基于 OCI 的 Kubernetes CRI 实现，旨在提供符合 OCI 运行时和 kubelet 之间的集成。简单来说就是完全符合 OCI 标准的 CRI 实现。（比如之前介绍的 runc 便是 OCI 标准的参考实现）
在 2016 年的时候 Kubernetes 就推出了容器运行时接口（CRI），这给了 kubelet 一种使用各种不同容器运行时的能力，现在最常用的当然还是 Docker，当然也有人使用 containerd、runc、CRI-O 等各类运行时。
CRI-O 最初由 Red Hat 和 Google 开发，现在已达到稳定状态，且已有大量的贡献者，本次成为 CNCF 托管项目，也算是给容器运行时提供一个更大的可能。
附一张官方图：
详细信息请阅读 CNCF 官方新闻
Helm 子项目 chart-testing 发布 v2.3.0 版本 chart-testing v2.3.0 版本正式发布，该项目的主要目标是用于 Helm Chart 的测试，使用该项目可更方便的检查 Chart 中是否有错误，以及定位错误位置等。
本次发布主要在于覆盖更多异常情况，详细内容建议阅读 ReleaseNote
CoreDNS v1.</description>
    </item>
    
    <item>
      <title>恭喜 Fluentd 从 CNCF 毕业</title>
      <link>https://moelove.info/2019/04/12/%E6%81%AD%E5%96%9C-Fluentd-%E4%BB%8E-CNCF-%E6%AF%95%E4%B8%9A/</link>
      <pubDate>Fri, 12 Apr 2019 07:23:14 +0800</pubDate>
      
      <guid>https://moelove.info/2019/04/12/%E6%81%AD%E5%96%9C-Fluentd-%E4%BB%8E-CNCF-%E6%AF%95%E4%B8%9A/</guid>
      <description>今年新闻不断，多数早期进入 CNCF 的项目都相继宣布毕业。
 CNCF（云原生计算基金会）在美国时间 2019 年 4 月 11 日宣布 fluentd 今天正式毕业了。
这是 CNCF 中毕业的第 6 个项目，之前已经毕业的项目为 Kubernetes、Prometheus、Envoy 、CoreDNS 和 containerd 。
fluentd 自 2011 年由 Treasure Data 公司的联合创始人 Sadayuki “Sada” Furuhashi 创建，作为构建统一记录层的开源数据收集器，统一记录层统一收集采集和消费，以便更好的使用和理解数据。在 2016 年 11 月，fluentd 也是第 6 个成为 CNCF 托管项目的。
fluentd 可以从多种数据源采集事件，并将它写入文件, RDBMS, NoSQL, IaaS, SaaS, Hadoop等等各类的目标地址。截至目前，fluentd 在 GitHub 上有 7629 个 star ，895 个 fork，以及 166 位贡献者，超过 4k+ commit 。
做日志相关的小伙伴基本都玩过 ELK ，我们都知道在大规模使用 Logstash 时的痛苦（还记得被 Logstash 配置文件支配的恐惧吗？ 2333） 而 fluentd 的事件路由是通过 tag 来做，相比 Logstash 使用管道将所有数据路由到单个流里再通过配置将它发送到对应的目标而言这将大大简化配置的复杂度。(是的，这里是吐槽)</description>
    </item>
    
    <item>
      <title>K8S 生态周报| 2019.04.01~2019.04.07</title>
      <link>https://moelove.info/2019/04/07/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.04.01~2019.04.07/</link>
      <pubDate>Sun, 07 Apr 2019 10:03:13 +0800</pubDate>
      
      <guid>https://moelove.info/2019/04/07/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.04.01~2019.04.07/</guid>
      <description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
 Kubernetes client-go v11.0.0 正式发布 这是最后一个使用 dep 作为依赖管理的版本，后续版本将转向使用 go modules.
Kubernetes 生态中的相关项目大多都已转向或正在转向使用 go modules 了，这也是一个技术风向，理性选择。
Release
containerd 1.2.6 正式发布 这是 containerd 1.2 的第 6 个 patch 版本，主要更新：
 在默认的 seccomp profile 白名单增加了 io_pgetevents 和 statx 这两个系统调用; 修复了在 1.2.5 中自定义 cgroup path 无法工作的 bug； 更新 CNI 插件到 v0.7.5 以修复 CVE-2019-9946; 更新 runc 版本，修复在无 SELinux 系统下的失败情况；  当然还有一些其他的改进和修复，比如修复了 pod 的 UTS namespace 等，建议阅读 ReleaseNote。
Docker CE 19.</description>
    </item>
    
    <item>
      <title>K8S 生态周报| 2019.03.25~2019.03.31</title>
      <link>https://moelove.info/2019/03/31/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.03.25~2019.03.31/</link>
      <pubDate>Sun, 31 Mar 2019 21:52:01 +0800</pubDate>
      
      <guid>https://moelove.info/2019/03/31/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.03.25~2019.03.31/</guid>
      <description>「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。欢迎订阅知乎专栏「k8s生态」。
 Kubernetes 1.14 正式发布 1.14 的主要更新：
 对 Windows Node 和 container 的支持达到生产级别，支持 Windows Server 2019； 本地持久化数据卷正式可用，这可以方便使用本地 SSD 之类的存储，但注意这个特性容错性较差； Pod 优先级和抢占机制正式可用，(建议慎重使用)； Pod Ready++ (Pod Readiness Gates) 达到稳定，可以更好的判断 Pod 及其需要的资源是否均已就绪；  当然还有很多的改进和很多被废弃的功能特性等，建议阅读 ReleaseNote。
Minikube 1.0.0 正式发布 Minikube 是一个用于本地搭建 Kubernetes 环境的工具，使用方法可参考 使用 Minikube 搭建本地 Kubernetes 环境。
1.0.0 的主要更新：
 默认 Kubernetes 版本更新至 1.14.0; 新增 --image-repository 参数，方便国内用户使用镜像解决网络问题；  其他特性请阅读 ReleaseNote
runc 1.0-rc7 发布 注意，低版本内核(尤其是 3.x)的系统，请不要升级至此版本
这个版本主要为解决之前的漏洞及修正一些规范等，版本说明请参考 runc 1.</description>
    </item>
    
    <item>
      <title>runc 1.0-rc7 发布之际</title>
      <link>https://moelove.info/2019/03/29/runc-1.0-rc7-%E5%8F%91%E5%B8%83%E4%B9%8B%E9%99%85/</link>
      <pubDate>Fri, 29 Mar 2019 10:42:25 +0800</pubDate>
      
      <guid>https://moelove.info/2019/03/29/runc-1.0-rc7-%E5%8F%91%E5%B8%83%E4%B9%8B%E9%99%85/</guid>
      <description>在 18 年 11 月底时，我写了一篇文章 《runc 1.0-rc6 发布之际》 。如果你还不了解 runc 是什么，以及如何使用它，请参考我那篇文章。本文中，不再对其概念和用法等进行说明。
在 runc 1.0-rc6 发布之时，给版本的别名为 &amp;ldquo;For Real This Time&amp;rdquo;，当时我们原定计划是发布 1.0 的，但是作为基础依赖软件，我们认为当时的版本还有几个问题：
 不够规范； 发布周期不明确;  为了给相关的 runtime 足够的时间进行修正/升级，以及规范版本生命周期等，最终决定了发布 runc 1.0-rc6。
为何有 runc 1.0-rc7 存在 前面已经基本介绍了相关背景，并且也基本明确了 rc6 就是在 1.0 正式发布之前的最后一个版本，那 rc7 为什么会出现呢？
CVE-2019-5736 我们首先要介绍今年 runc 的一个提权漏洞 CVE-2019-5736 。
2019 年 2 月 11 日在oss-security 邮件组正式批露该漏洞，攻击者可以利用恶意容器覆盖主机上的 runc 文件，从而达到攻击的目的；（具体的攻击方式此处略过），注意不要轻易使用来源不可信的镜像创建容器便可有效避免被攻击的可能。
简单补充下可能被攻击的方式：
 运行恶意的 Docker 镜像 在主机上执行 docker exec 进入容器内  关于容器安全或者容器的运行机制，其实涉及的点很多，我在去年的一次线上分享 《基于 GitLab 的 CI 实践》 有提到过 Linux Security Modules（LSM）等相关的内容，对容器安全感兴趣的朋友可以对 LSM 多了解下。</description>
    </item>
    
    <item>
      <title>使用 Kind 搭建你的本地 Kubernetes 集群</title>
      <link>https://moelove.info/2019/03/25/%E4%BD%BF%E7%94%A8-Kind-%E6%90%AD%E5%BB%BA%E4%BD%A0%E7%9A%84%E6%9C%AC%E5%9C%B0-Kubernetes-%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Mon, 25 Mar 2019 21:30:24 +0800</pubDate>
      
      <guid>https://moelove.info/2019/03/25/%E4%BD%BF%E7%94%A8-Kind-%E6%90%AD%E5%BB%BA%E4%BD%A0%E7%9A%84%E6%9C%AC%E5%9C%B0-Kubernetes-%E9%9B%86%E7%BE%A4/</guid>
      <description>Kind 是我很喜欢也一直在参与的项目，我计划将 Kind 相关的文章写成一个系列。（flag++） 这是第一篇。
 Kind 介绍 Kind 是 Kubernetes In Docker 的缩写，顾名思义是使用 Docker 容器作为 Node 并将 Kubernetes 部署至其中的一个工具。官方文档中也把 Kind 作为一种本地集群搭建的工具进行推荐。
安装 二进制安装 Kind 使用 Golang 进行开发，在仓库的 Release 页面，已经上传了构建好的二进制，支持多种操作系统，可直接按需下载进行使用。
e.g.
# 下载最新的 0.2.0 版本 wget -O /usr/local/bin/kind https://github.com/kubernetes-sigs/kind/releases/download/0.2.0/kind-linux-amd64 &amp;amp;&amp;amp; chmod +x /usr/local/bin/kind  通过源码安装 如果你本地已经配置好了 Golang 的开发环境，那你可以直接通过源码进行安装。
e.g.
go get -u sigs.k8s.io/kind  运行完上述命令后，会将 kind 的可执行文件放到 $(go env GOPATH)/bin 文件夹内，你可能需要将此目录加入到 $PATH 中。
或者也可以先 clone 源代码再通过 go build 进行构建。</description>
    </item>
    
    <item>
      <title>K8S 生态周报| 2019.03.18~2019.03.24</title>
      <link>https://moelove.info/2019/03/25/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.03.18~2019.03.24/</link>
      <pubDate>Mon, 25 Mar 2019 20:49:06 +0800</pubDate>
      
      <guid>https://moelove.info/2019/03/25/K8S-%E7%94%9F%E6%80%81%E5%91%A8%E6%8A%A5-2019.03.18~2019.03.24/</guid>
      <description>我将从本篇开始维护「K8S 生态周报」内容主要包含我所接触到的 K8S 生态相关的每周值得推荐的一些信息。
 Docker 6 岁啦 Docker 从 2013 年首次亮相，至今已 6 年之久，而 Docker 也已一度成为容器技术的代名词，很庆幸能投身 Docker 相关的领域。官方博客
Kind (Kubernetes In Docker) 发布 0.2.0 版本 Kind 是一个利用容器技术快速部署本地 Kubernetes 的工具，主要是用于对 Kubernetes 1.11+ 版本的测试。现在发布的 0.2.0 版本支持最新 Kubernetes v1.13.4 及 Docker 18.06.3 且通过了 CNCF 的一致性认证。
Rancher 发布 K8S 最佳安全实践文章 Rancher 在 CNCF 最近发布的 9 个 Kubernetes 最佳安全实践的基础上发布了一篇更安全的最佳实践，这两篇文章都值得一看。
可以通过下面二维码订阅我的文章公众号【MoeLove】</description>
    </item>
    
    <item>
      <title>恭喜 containerd 毕业</title>
      <link>https://moelove.info/2019/03/01/%E6%81%AD%E5%96%9C-containerd-%E6%AF%95%E4%B8%9A/</link>
      <pubDate>Fri, 01 Mar 2019 10:18:20 +0800</pubDate>
      
      <guid>https://moelove.info/2019/03/01/%E6%81%AD%E5%96%9C-containerd-%E6%AF%95%E4%B8%9A/</guid>
      <description>今年的第一篇文章更新，带来一个重大的消息。
 CNCF（云原生计算基金会）在美国时间 2019 年 2 月 28 日宣布 containerd 今天正式毕业了。
这是 CNCF 中毕业的第 5 个项目，之前已经毕业的项目为 Kubernetes、Prometheus、Envoy 和 CoreDNS 。
containerd 2014 年从 Docker 孵化出来，最初是作为 Docker 引擎的底层管理器；在 2017 年 3 月被 CNCF 接受后，containerd 几乎成为了行业容器运行引擎的标准，它专注于简单，健壮和可移植性，任何人都可以使用它来构建自己的容器引擎/平台。
 “When Docker contributed containerd to the community, our goal was to share a robust and extensible runtime that millions of users and tens of thousands of organizations have already standardized on as part of Docker Engine,” said Michael Crosby, containerd maintainer and Docker engineer.</description>
    </item>
    
    <item>
      <title>2018 小回顾</title>
      <link>https://moelove.info/2018/12/29/2018-%E5%B0%8F%E5%9B%9E%E9%A1%BE/</link>
      <pubDate>Sat, 29 Dec 2018 20:43:00 +0800</pubDate>
      
      <guid>https://moelove.info/2018/12/29/2018-%E5%B0%8F%E5%9B%9E%E9%A1%BE/</guid>
      <description>年底了，惯例做个小回顾，对这一年做个总结，也对下一年大致做个规划。
不过今儿与往年不同的是昨晚突然发高烧，今儿都没能去上班，感谢我的小可爱在照顾我。这篇文章也是躺在床上用手机编辑的。
还是按照惯例从工作，生活两方面来说。先聊聊工作。
工作 现在在网易有道负责 DevOPS 实践落地及 k8s 容器化平台和自动化平台的规划建设等。
总体来说，现在的工作很开心，更能发挥我的所长，也遇到了不错的团队。
说到现在负责的工作，如果大致有些了解的就会知道这个过程比较漫长，推进起来也会有各种阻力。毕竟要改变很多人的思想和习惯，我也在尽量让这一过程变的更加平滑。
同时也在 push 一些理念到行业内，到社区中，不断的进行交流碰撞总结。
社区贡献 今年下半年的贡献和分享相比去年更多一些。主要的分享有:
 GITC - 《云原生时代下的 CI/CD 实践》 PyCon China - 《基于 Docker 的 CI/CD 实践》 DockerOne 社区 - 《基于 GitLab 的 CI 实践》 Tech Talk Time - 《Docker 实战和基础架构》  分享的主题基本都围绕在容器化和 CI/CD 方面，但每次分享内容却都不一样。 感谢我的小可爱，也感谢所有支持的朋友们。
社区中主要活跃在 Docker 和 Kubernetes 生态方向。维护一些官方镜像，做测试，解决问题，提交代码之类的，明年希望做的更多。
 开了一个知乎专栏 『k8s生态』 明年会花更多时间进行建设。 写了一本掘金小册《Kubernetes 从上手到实践》。 其实这个名字并不能很好的概括小册里面的内容，其中也有源码分析之类的。要再次感谢小可爱，感谢编辑 Linmi ，感谢马达老板和何世友老板写的推荐语。也感谢所有人的支持，希望这本小册能对大家有所帮助。  写小册的过程其实也蛮辛苦的，一般要么晚上写，写到凌晨 2~3 点，要么早上 5~6 点钟左右起床，写到去上班。尤其要感谢小可爱，给了我很多支持。</description>
    </item>
    
    <item>
      <title>《Kubernetes从上手到实践》正式上线</title>
      <link>https://moelove.info/2018/12/27/Kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5%E6%AD%A3%E5%BC%8F%E4%B8%8A%E7%BA%BF/</link>
      <pubDate>Thu, 27 Dec 2018 11:16:21 +0800</pubDate>
      
      <guid>https://moelove.info/2018/12/27/Kubernetes%E4%BB%8E%E4%B8%8A%E6%89%8B%E5%88%B0%E5%AE%9E%E8%B7%B5%E6%AD%A3%E5%BC%8F%E4%B8%8A%E7%BA%BF/</guid>
      <description> 时间飞逝，转眼已经到了圣诞节，今年又要结束了。感谢还在关注的小伙伴，今年确实更新很少，能不取关的都是真爱&amp;hellip;
今年发生了很多事情，留着过几天年终总结的时候再说。有很大一部分的休息时间都用来完成了我的第一本掘金小册 《Kubernetes 从上手到实践》
小册已经正式上线，特意送上各位小伙伴一份礼物，小册 8 折优惠。直接扫码 或者点击此链接即可。
以下是关于小册的一些介绍：
随着容器化及微服务等概念的普及，各个公司都在围绕着如何打造生产环境可用的，高效的容器调度平台，应用快速部署，扩容等平台进行探索。Kubernetes 是 Google 在 2014 年基于其多年在 Borg 系统实践总结出的经验而开源出的一套标准化，可扩展的系统。
而发展至现在（2018年）Kubernetes 已经基本成为了容器编排领域事实上的标准，并且大量的公司都已在生产中使用，无论是国外的 Google， Amazon, GitHub 等，还是国内的阿里，腾讯，京东，滴滴及其他中小公司都在进行着大量的探索及实践。
之前在容器化尚未大量推进的时候，开发工程师只需要关注自己业务代码的实现，而运维工程师在反复的为部署，扩容所需的环境而费时费力。
为了解决环境一致性的问题，也为了能够提高资源的利用率，容器化开始逐步推进，开发工程师的交付由原先的交付代码变成了交付镜像，运维工程师可以将精力集中于保障服务的可高用上。
但为了能够快速的发版验证功能，不再受单体化架构的拖累，微服务的概念也在实践中逐步推进，从原先的单体集中式的服务，拆分为多个松耦合的微服务。到了这时，微服务 + 容器化已经大势所趋，生产中要大量使用，则容器编排变的愈发重要。Kubernetes 在容器编排领域目前已成为事实上的标准，大量公司均已在生产中推进，此时，无论是开发工程师还是运维工程师，皆需要了解并掌握 Kubernetes 的基础技能，才不至于丢失自己的竞争力。
Kubernetes 所涉及的知识点很多, 并且版本迭代也很快，本小册将集中于 Kubernetes 的基础技能，以最常见 Case 入手，帮助大家更快的掌握相关知识并将其用于生产实践中。同时在此过程中，也会深入至 Kubernetes 必要的原理中，同时也会提供相关涉及到的 Docker 及 Linux 内核知识的补充，以便让大家不仅知其然，而且知其所以然。
你会学到什么？  Kubernetes 基础架构 Kubernetes 的基础技能, 覆盖常见 Case 从零搭建 Kubernetes 集群 与 Kubernetes 相关的 Docker 和 Linux 内核知识补充 深入 Kubernetes 组件的原理和源码解析 了解 Kubernetes 进阶相关知识体系  适宜人群  了解 Docker，希望能进入 K8S 领域的各领域工程师； 正在或即将在生产环境使用 K8S 的后端工程师； 需要维护或在公司落地 K8S 的运维工程师； 想要走在技术前沿的前端/后端/运维工程师； 准备查缺补漏的容器相关开发工程师；  </description>
    </item>
    
    <item>
      <title>runc 1.0-rc6 发布之际</title>
      <link>https://moelove.info/2018/11/23/runc-1.0-rc6-%E5%8F%91%E5%B8%83%E4%B9%8B%E9%99%85/</link>
      <pubDate>Fri, 23 Nov 2018 04:28:20 +0800</pubDate>
      
      <guid>https://moelove.info/2018/11/23/runc-1.0-rc6-%E5%8F%91%E5%B8%83%E4%B9%8B%E9%99%85/</guid>
      <description>如果你在用 Docker 或者 Kubernetes 想必你对 容器运行时 这个概念应该不会太陌生。
在 Docker 中，当你使用 docker info 即可查看当前所使用的 runtime。
➜ ~ docker info ... Server Version: 18.06.1-ce Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs ... Swarm: inactive Runtimes: nvidia runc Default Runtime: runc Init Binary: docker-init containerd version: 468a545b9edcd5932818eb9de8e72413e616e86e runc version: 69663f0bd4b60df09991c08812a60108003fa340 init version: fec3683 Security Options: seccomp Profile: default ...  同时，你还可以自己在 /etc/docker/daemon.</description>
    </item>
    
    <item>
      <title>Docker 深入篇之 Build 原理</title>
      <link>https://moelove.info/2018/09/04/Docker-%E6%B7%B1%E5%85%A5%E7%AF%87%E4%B9%8B-Build-%E5%8E%9F%E7%90%86/</link>
      <pubDate>Tue, 04 Sep 2018 22:21:46 +0800</pubDate>
      
      <guid>https://moelove.info/2018/09/04/Docker-%E6%B7%B1%E5%85%A5%E7%AF%87%E4%B9%8B-Build-%E5%8E%9F%E7%90%86/</guid>
      <description>使用 Docker 时，最常用的命令无非是 docker container 和 docker image 相关的子命令，当然最初没有管理类命令（或者说分组）的时候，最常使用的命令也无非是 docker run docker commit docker build 和 docker images 这些。
今天来聊一下和 Docker 中核心概念 image 相关的重要命令， docker build 或者说 docker image build 为了简便起见，下文的命令全部使用 docker build 。
Docker Image 先简单介绍下 Docker Image， 通常情况下我们将其称之为镜像，镜像是由多个层组成的文件，这些层用于在容器内执行代码（命令）等。每个镜像基本上都是根据应用程序完整的可执行版本进行构建的，并且需要注意的是，它会依赖于主机的系统内核。当用户在运行镜像时，这将会创建一个或者多个容器实例。
Dockerd Dockerd 是 Docker 的服务端，默认情况下提供 Unix Domain Socket 连接，当然也可以监听某个端口，用于对外提供服务。 所以有时候，我们也可以使用服务器上的 Docker daemon 来提供服务，以加快构建速度及解决一些网络问题之类的。
好的，基础概念了解了， 那我们开始进入正题。
使用 Dockerfile 我们知道构建镜像的方法有多种，本文中我们只介绍使用 Dockerfile 通过 docker build 的方式构建镜像。
为了简便，我们以一个简单的 Dockerfile 开始。构建一个容器内使用的 kubectl 工具 (当然选择它的原因在于 kubectl 足够大，并不考虑可用性，这个稍后解释)</description>
    </item>
    
    <item>
      <title>GitLab CI 使用 InsecureRegistry</title>
      <link>https://moelove.info/2018/08/06/GitLab-CI-%E4%BD%BF%E7%94%A8-InsecureRegistry/</link>
      <pubDate>Mon, 06 Aug 2018 08:12:03 +0800</pubDate>
      
      <guid>https://moelove.info/2018/08/06/GitLab-CI-%E4%BD%BF%E7%94%A8-InsecureRegistry/</guid>
      <description>继上次分享后，有读者留言问 dind 使用 insecure-registry 相关的问题。
 请教个问题，基于gitlab CI做java项目持续集成，用到了docker in docker， docker build使用的Dockerfile中使用了一个insecure registry，在dind的容器中如何配置insecure registry
 我的回复是：
首先, 不推荐使用 insecure registry 毕竟有其固有限制， 如果一定要用的话， 其实在 services 层配置一个 command 就可以，这也是最简单的， 例如：
services: - name: docker:dind command: [&amp;quot;--insecure-registry=myregistry:5000&amp;quot;]  由于留言字数的限制，就单独写个小文来回复下。
这个做法实际效果如下：
(Tao) ➜ kubernetes git:(master) ✗ sudo docker run -d --privileged --name dind docker:dind --insecure-registry=&amp;quot;myregistry:5000&amp;quot; 8fb68865638ebc65255bb568fbe1fd6b4ed4fca771075d8e55ebbbbdf0aef6d2 (Tao) ➜ kubernetes git:(master) ✗ sudo docker top dind UID PID PPID C STIME TTY TIME CMD root 18270 18252 1 11:27 ?</description>
    </item>
    
    <item>
      <title>基于 GitLab 的 CI 实践</title>
      <link>https://moelove.info/2018/08/05/%E5%9F%BA%E4%BA%8E-GitLab-%E7%9A%84-CI-%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Sun, 05 Aug 2018 14:54:59 +0800</pubDate>
      
      <guid>https://moelove.info/2018/08/05/%E5%9F%BA%E4%BA%8E-GitLab-%E7%9A%84-CI-%E5%AE%9E%E8%B7%B5/</guid>
      <description>上个月受 DockOne 社区邀请，做了一次 CI 实践方面的线上分享，在此记录下。 本文讲述 GitLab CI 的架构及其能力特性，分析它在 DevOps 实践中的作用。 通过分析 Docker In Docker 的技术细节，详细讲述 CI 实践以及在生产环境中的所做的优化，包括但不限于镜像仓库等，以达到数倍的性能提升。 本次分享内容以 GitLab Community Edition 11.0.4 edb037c 为例。
 为何选择 GitLab CI 认识 GitLab CI 什么是 GitLab CI GitLab CI 是 GitLab 为了提升其在软件开发工程中作用，完善 DevOPS 理念所加入的 CI/CD 基础功能。可以便捷的融入软件开发环节中。通过 GitLab CI 可以定义完善的 CI/CD Pipeline。
优势  GitLab CI 是默认包含在 GitLab 中的，我们的代码使用 GitLab 进行托管，这样可以很容易的进行集成 GitLab CI 的前端界面比较美观，容易被人接受 包含实时构建日志，容易追踪 采用 C/S 的架构，可方面的进行横向扩展，性能上不会有影响 使用 YAML 进行配置，任何人都可以很方便的使用。  重点概念 Pipeline Pipeline 相当于一个构建任务，里面可以包含多个流程，如依赖安装、编译、测试、部署等。 任何提交或者 Merge Request 的合并都可以触发 Pipeline</description>
    </item>
    
    <item>
      <title>Install-Python3.6-on-CentOS7</title>
      <link>https://moelove.info/2017/06/30/Install-Python3.6-on-CentOS7/</link>
      <pubDate>Fri, 30 Jun 2017 00:13:16 +0000</pubDate>
      
      <guid>https://moelove.info/2017/06/30/Install-Python3.6-on-CentOS7/</guid>
      <description>拖了很久没有更新，抱歉啦~ 今天受邀写篇如何在 CentOS 7 上配置 Python 3 环境的文章。往常我都选择直接把我早年写的一篇文章源码编译MongoDB丢过去，让他们看其中的源码编译 Python 那一节，不过那节写的其实不太详细，而且最近被很多人催，所以还是单独写一篇好了。
 当前最新的 CentOS 7.3 默认安装的是 Python 2 ，并且默认的官方 yum 源中不提供 Python 3 的安装包。有些用户想要升级使用 Python 3 但实际可能有各种各样的问题，导致出错，反观一下激进的 Fedora 社区，在23的时候，就将默认的版本修改成了 Python3 （如果我没记错的话）。
先说下我所使用的系统环境， 一个新创建的 Docker 容器。 使用 cat /etc/redhat-release 可以看到运行的是 CentOS 7.3 版本。
在纯净的 CentOS 系统上安装 Python 环境主要有两种办法。 一种是通过源码编译安装，另外一种就是安装已经打好的 RPM 包。依照个人习惯，我们先来看一下如何通过源码编译的方式安装 Python 3.6 并且配置虚拟环境。
使用源码进行编译安装 基础环境  先安装安装几个必须的包，以方便后续的操作  ➜ yum install wget gcc make ➜ # wget 用于下载源码包 ➜ # gcc 和 make 用于编译   上 Python的官网 下载源码包  ➜ wget https://www.</description>
    </item>
    
    <item>
      <title>理解 Redis 的 RESP 协议</title>
      <link>https://moelove.info/2017/03/05/%E7%90%86%E8%A7%A3-Redis-%E7%9A%84-RESP-%E5%8D%8F%E8%AE%AE/</link>
      <pubDate>Sun, 05 Mar 2017 21:45:07 +0000</pubDate>
      
      <guid>https://moelove.info/2017/03/05/%E7%90%86%E8%A7%A3-Redis-%E7%9A%84-RESP-%E5%8D%8F%E8%AE%AE/</guid>
      <description>简介 Redis 的客户端和服务端之间采取了一种独立名为 RESP(REdis Serialization Protocol) 的协议，作者主要考虑了以下几个点：
 容易实现 解析快 人类可读  注意：RESP 虽然是为 Redis 设计的，但是同样也可以用于其他 C/S 的软件。
数据类型及示例 RESP 主要可以序列化以下几种类型：整数，单行回复(简单字符串)，数组，错误信息，多行字符串。Redis 客户端向服务端发送的是一组由执行的命令组成的字符串数组，服务端根据不同的命令回复不同类型的数据，但协议的每部分都是以 &amp;ldquo;\r\n&amp;rdquo; (CRLF) 结尾的。另外 RESP 是二进制安全的，不需要处理从一个进程到另一个进程的传输，因为它使用了前缀长度进行传输。
在 RESP 中, 一些数据的类型通过它的第一个字节进行判断：
 单行回复：回复的第一个字节是 &amp;ldquo;+&amp;rdquo; 错误信息：回复的第一个字节是 &amp;ldquo;-&amp;rdquo; 整形数字：回复的第一个字节是 &amp;ldquo;:&amp;rdquo; 多行字符串：回复的第一个字节是 &amp;ldquo;\$&amp;rdquo; 数组：回复的第一个字节是 &amp;ldquo;*&amp;rdquo;  单行回复 以 &amp;ldquo;+&amp;rdquo; 开头，以 &amp;ldquo;\r\n&amp;rdquo; 结尾的字符串形式。e.g.
+OK\r\n  响应的客户端库，应该返回除 &amp;ldquo;+&amp;rdquo; 和 CRLF 以外的内容，例如上面的内容，则返回 &amp;ldquo;OK&amp;rdquo;. e.g.
127.0.0.1:6379&amp;gt; set name TaoBeier +OK\r\n # 服务端实际返回 --- OK # redis-cli 客户端显示  错误信息 错误信息和单行回复很像，不过是把 &amp;ldquo;+&amp;rdquo; 替换成了 &amp;ldquo;-&amp;ldquo;。而这两者之间真正的区别是，错误信息会被客户端视为异常，并且组成错误类型的是错误消息本身。e.</description>
    </item>
    
    <item>
      <title>2016 小回顾</title>
      <link>https://moelove.info/2017/01/01/2016-%E5%B0%8F%E5%9B%9E%E9%A1%BE/</link>
      <pubDate>Sun, 01 Jan 2017 01:00:51 +0000</pubDate>
      
      <guid>https://moelove.info/2017/01/01/2016-%E5%B0%8F%E5%9B%9E%E9%A1%BE/</guid>
      <description>时间很快， 已经走到了 2016 的末尾， 惯例的做个小回顾。（注：这篇起笔的时间是圣诞节TAT）
年初定的目标除了没有能合理安排追番时间， 其他的都基本完成了！（话说今年追番的时间简直少的可怜QAQ）
2016 年发生了太多的事情，要回顾的事情很多，索性就不写那么多了, 只按时间序稍微列几件有趣的事情。
 单表亿级数据量的 MongoDB 做在线实时的数据拆分 在之前做的一些应用性能分析的方案上做了一些额外的设计和开发（明年修改下开源出来） PyCon China 2016 一些预期的计划顺利推进、落地，产出了一些系统 看了很多源码，折腾了很多东西，如果以后有空就写点东西出来（我又在给自己挖坑了） 认识了很多有趣的小伙伴~  全年的状态基本和上面的截图是一致的， 全年都在 coding （截图仅限 GitHub上的记录）倒也比较开心， 另外就是现在看到自己项目的 star/fork 数，文章的阅读/收藏/转发数之类的，也已经不像以前看到 star 数刚上百时候会有那种喜悦了，大概这也是另一种成熟？ 哈哈哈
另外写一下今年对我比较重要的几个数字：
 1354 376 105  对这些数字的解释, 放在以后吧 :-)
2017 年，希望想做的事情都能基本完成，挖的坑慢慢填。 感谢一路上陪我走过的各位！
可以通过下面二维码订阅我的文章公众号【MoeLove】</description>
    </item>
    
    <item>
      <title>关于 webpack 你可能忽略的细节（附源码分析）</title>
      <link>https://moelove.info/2016/12/26/%E5%85%B3%E4%BA%8E-webpack-%E4%BD%A0%E5%8F%AF%E8%83%BD%E5%BF%BD%E7%95%A5%E7%9A%84%E7%BB%86%E8%8A%82%E9%99%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link>
      <pubDate>Mon, 26 Dec 2016 00:43:02 +0000</pubDate>
      
      <guid>https://moelove.info/2016/12/26/%E5%85%B3%E4%BA%8E-webpack-%E4%BD%A0%E5%8F%AF%E8%83%BD%E5%BF%BD%E7%95%A5%E7%9A%84%E7%BB%86%E8%8A%82%E9%99%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</guid>
      <description>注：本篇不是入门教程，入门请直接查看官方文档。本篇的主要目标是通过实际问题来介绍 webpack 中容易被人忽略的细节, 以及源码分析(以最新发布的 release 版本1.14.0的源码为例), 并且提供几种解决方案。
 随着前端技术的火热发展，工程化，模块化和组件化的思想已逐步成为主流，与之相应的，就需要有一整套工具流可以支撑起它。
现在比较热门的前端资源模块化管理和打包工具应该非 Webpack 莫属了。
Webpack 是什么  它可以将许多松散的模块按照依赖和规则打包成符合生产环境部署的前端资源。还可以将按需加载的模块进行代码分隔，等到实际需要的时候再异步加载。通过 loader 的转换，任何形式的资源都可以视作模块，比如 CommonJs 模块、 AMD 模块、 ES6 模块、CSS、图片、 JSON、Coffeescript、 LESS 等。 &amp;ndash;引自 Webpack 中文指南
 使用举例 我们来看一下官方文档中的最小用例，新建并写入以下内容到这两个文件：
cats.js
var cats = [&#39;dave&#39;, &#39;henry&#39;, &#39;martha&#39;]; module.exports = cats;  app.js (Entry Point)
cats = require(&#39;./cats.js&#39;); console.log(cats);  这个时候，就可以使用 webpack 进行打包了：
webpack ./app.js app.bundle.js  我们来看一下发生了什么， 目录下生成了一个打包后的文件 app.bundle.js ，这就是最基础的打包过程。
提出问题 如何判断打包是否成功？
通用方案 下面是我们常用的两种判断任务是否执行成功的方案
通过 return code 通过命令执行后的 return code 来判断（在 shell 中使用 $?</description>
    </item>
    
    <item>
      <title>Composer 使用技巧简述</title>
      <link>https://moelove.info/2016/12/16/Composer-%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%E7%AE%80%E8%BF%B0/</link>
      <pubDate>Fri, 16 Dec 2016 00:49:11 +0000</pubDate>
      
      <guid>https://moelove.info/2016/12/16/Composer-%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7%E7%AE%80%E8%BF%B0/</guid>
      <description>最近使用了世界最好的语言 PHP 用来管理依赖关系的工具 Composer. 稍微做点记录, 以做备忘. 如有错误还望指出.
 安装 php -r &amp;quot;copy(&#39;https://getcomposer.org/installer&#39;, &#39;composer-setup.php&#39;);&amp;quot; php -r &amp;quot;if (hash_file(&#39;SHA384&#39;, &#39;composer-setup.php&#39;) === &#39;aa96f26c2b67226a324c27919f1eb05f21c248b987e6195cad9690d5c1ff713d53020a02ac8c217dbf90a7eacc9d141d&#39;) { echo &#39;Installer verified&#39;; } else { echo &#39;Installer corrupt&#39;; unlink(&#39;composer-setup.php&#39;); } echo PHP_EOL;&amp;quot; php composer-setup.php php -r &amp;quot;unlink(&#39;composer-setup.php&#39;);&amp;quot;  上述代码来自官网.
局部安装 上述代码执行完成后, 只是下载到了 composer.phar 文件, 可以通过 php composer.phar 在任意位置执行.
全局安装 全局安装只是把 composer.phar 安装到 PATH 下即可. 可以像下面这样:
sudo mv composer.phar /usr/local/bin/composer  国内镜像加速 使用Composer中文网提供的中国全量镜像进行加速.
单项目加速 进入项目目录(即 composer.json 文件所在目录) 执行:</description>
    </item>
    
    <item>
      <title>Git workflow 详谈</title>
      <link>https://moelove.info/2016/12/05/Git-workflow-%E8%AF%A6%E8%B0%88/</link>
      <pubDate>Mon, 05 Dec 2016 22:40:41 +0000</pubDate>
      
      <guid>https://moelove.info/2016/12/05/Git-workflow-%E8%AF%A6%E8%B0%88/</guid>
      <description>作为一名工程师， Git 在日常开发中是不可或缺的工具。 这里详细介绍几种比较常用的基于 Git 的工作流模型, 以便于团队协作的规范化和效率提升。
中心化工作流 使用过SVN的应该都知道， SVN使用的是集中式管理流程， 如果你刚从SVN 切换到 Git ， 你可以尝试使用中心化工作流的方式。这样，你几乎不需要变更之前的工作方式， 就可以完成平滑的过渡了。 而且在使用过程中还可以看到 Git 优于 SVN 的地方： 第一，每个成员都可以在本地拥有一份完整的项目代码仓库，而不只是一个工作区的副本，任何人都可以在本地执行 add 和 commit ，而不需要考虑远端仓库是否有变更，直到需要的时候再去提交即可。 第二，Git 的工作区、暂存区、引用更新等设计，可以给开发者更多自由来切换当前工作，且不会造成代码丢失。
工作细节 中心化工作流的方式是：在远端（远端可以是服务器端，也可以是本地的任意目录）新建一个仓库，默认是 master 分支，作为唯一的中心仓库。 所有人都 clone 这个仓库作为本地仓库，并在本地仓库进行开发。本地的提交是和远端仓库无关的，等需要的时候再 push 进主仓库的 master 分支即可。
在这种方式下， 远端是唯一确定的中心仓库， 所有人都要以这个仓库为准。 所以，在提交之前要先 fetch 最新提交，在这些提交之上作出自己的更改(一般我们使用 rebase来完成)。
如果本地的修改和远端仓库中的变更发生了冲突，那么 Git 会暂停 rebase ，并让你来解决这些冲突。我们可以很简单的使用 git status 和 git add 等命令完成冲突的合并。 另外, 如果我们解决不了冲突, 我们也可以使用 git rebase --abort 很容易的退出 rebase 的过程。
这样每天的工作方式就变成了，从中心仓库拉取最新代码， 然后开始一天的工作， 开发完成后，拉取中心仓库的更新， 合并代码后， 再提交至中心仓库， 结束一天的工作。 这样的好处就是不需要变更原先（使用SVN）的工作方式。当然弊端也很明显，你并不知道中心仓库的代码是否是稳定的，或者说并不能确定当你的代码和中心仓库代码合并后，是否是稳定的，带来的问题就是开发进度和回滚不那么方便控制。</description>
    </item>
    
    <item>
      <title>Git 本地仓库和裸仓库</title>
      <link>https://moelove.info/2016/12/04/Git-%E6%9C%AC%E5%9C%B0%E4%BB%93%E5%BA%93%E5%92%8C%E8%A3%B8%E4%BB%93%E5%BA%93/</link>
      <pubDate>Sun, 04 Dec 2016 01:37:39 +0000</pubDate>
      
      <guid>https://moelove.info/2016/12/04/Git-%E6%9C%AC%E5%9C%B0%E4%BB%93%E5%BA%93%E5%92%8C%E8%A3%B8%E4%BB%93%E5%BA%93/</guid>
      <description>通常我们会用 git init 命令来将我们所在的目录转换为一个 Git 本地仓库或者初始化一个新的空仓库。
用法  将当前目录转换为一个本地仓库  git init  这个命令执行后会在本地生成一个 .git 的文件夹，用来追踪仓库的所有变更。效果如下：
 指定某个目录成为本地仓库  git init &amp;lt;repo&amp;gt;  这个命令执行后， 将创建一个名为repo且只包含 .git 子文件夹的空目录。效果如下：
 指定某个目录成为中心仓库（裸仓库）  git init --bare &amp;lt;repo&amp;gt;  这个命令执行后，将在本地创建一个名为 repo 的文件夹， 里面包含着 Git 的基本目录， 我们一般会将这个文件夹命名为后面加 .git 的形式，如 repo.git （这也是为什么我们从 GitHub clone 仓库的时候，地址都是 xxx.git 这样的形式的原因）。效果如下：
详细说一下使用 --bare 参数的含义，使用 --bare 参数初始化的仓库，我们一般称之为裸仓库， 因为这样创建的仓库并不包含 工作区 ， 也就是说，我们并不能在这个目录下执行我们一般使用的 Git 命令。
对比 我们来对比一下直接使用 git init 创建的仓库和加了 --bare 参数的两个仓库。 我们直接看两个仓库的的 config 文件中的内容：</description>
    </item>
    
    <item>
      <title>源码编译Vim 8</title>
      <link>https://moelove.info/2016/09/24/%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91Vim-8/</link>
      <pubDate>Sat, 24 Sep 2016 19:46:47 +0000</pubDate>
      
      <guid>https://moelove.info/2016/09/24/%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91Vim-8/</guid>
      <description>Vim 8.0 在2016.09.12发布了, 在各 Linux 发行版还没更新包的时候就源码编译来使用吧! 以 Debian 编译 Vim 为例.
 下载Vim 源码 可以在Vim 官网下载打包好的源代码. 或者使用 Git:
git clone https://github.com/vim/vim.git  编译 cd vim/src ./configure --with-compiledby=&amp;quot;TaoBeier&amp;quot; --with-features=huge --enable-pythoninterp=yes --with-python-config-dir=/usr/lib/python2.7/config-x86_64-linux-gnu --enable-cscope --enable-perlinterp=yes --enable-rubyinterp=yes --with-luajit --enable-luainterp=yes --with-lua-prefix=/usr/include/lua5.1 --enable-multibyte --with-x --enable-fail-if-missing  上面的参数使用 ./configure --help 都可以看到对应用途. 上面使用的参数是增加了对 Python, Ruby, Perl, 以及X window的支持.
建议加上 --enable-fail-if-missing 参数, 以方便定位到哪里依赖缺失.
依赖 这里检查可能通不过, 首先是 lua 和 luajit. 需要执行
sudo apt-get install lua5.1 liblua5.1-0 luajit libluajit-5.1-dev</description>
    </item>
    
    <item>
      <title>利器系列-更高效的Vim</title>
      <link>https://moelove.info/2016/09/16/%E5%88%A9%E5%99%A8%E7%B3%BB%E5%88%97-%E6%9B%B4%E9%AB%98%E6%95%88%E7%9A%84Vim/</link>
      <pubDate>Fri, 16 Sep 2016 16:55:44 +0000</pubDate>
      
      <guid>https://moelove.info/2016/09/16/%E5%88%A9%E5%99%A8%E7%B3%BB%E5%88%97-%E6%9B%B4%E9%AB%98%E6%95%88%E7%9A%84Vim/</guid>
      <description>这是利器系列第0篇, 当然要以每天我使用率最高的Vim来开始啦!
 截图 安装 (你需要一个有Python支持的Vim版本. 请使用 vim --version | grep +python 来检查)
 依赖(Debian/Ubuntu 平台)
sudo apt-get install python vim exuberant-ctags git
sudo pip install dbgp vim-debug pep8 flake8 pyflakes isort
 依赖(RedHat/CentOS 平台)
CentOS 6.7的yum源自带的Python版本较旧，推荐自行安装Python2.7.
sudo yum install python vim ctags git
sudo pip install dbgp vim-debug pep8 flake8 pyflakes isort
 依赖(Mac OS 平台)
brew install python vim git
wget http://tenet.dl.sourceforge.net/project/ctags/ctags/5.8/ctags-5.8.tar.gz &amp;amp;&amp;amp; tar -zxvf ctags-5.8.tar.gz &amp;amp;&amp;amp; cd ctags-5.</description>
    </item>
    
    <item>
      <title>Python性能优化之工具篇</title>
      <link>https://moelove.info/2016/05/14/Python%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B%E5%B7%A5%E5%85%B7%E7%AF%87/</link>
      <pubDate>Sat, 14 May 2016 00:14:54 +0000</pubDate>
      
      <guid>https://moelove.info/2016/05/14/Python%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B%E5%B7%A5%E5%85%B7%E7%AF%87/</guid>
      <description>之前对公司的一个后端项目做了些性能优化, 学到一些值得记录的东西, 这篇主要是介绍在做性能分析时所用到的工具, 至于如何优化基本就是智者见智吧, 如果有时间可能会写的.
 Python web应用程序的常见性能指标 此处忽略外部DNS解析等方面的性能   响应时间 错误率 吞吐率 执行时间 内存占用  Python 性能分析工具 ##TODO</description>
    </item>
    
    <item>
      <title>想从二次元群体手里赚钱？你真的懂二次元吗!</title>
      <link>https://moelove.info/2016/04/16/%E6%83%B3%E4%BB%8E%E4%BA%8C%E6%AC%A1%E5%85%83%E7%BE%A4%E4%BD%93%E6%89%8B%E9%87%8C%E8%B5%9A%E9%92%B1%E4%BD%A0%E7%9C%9F%E7%9A%84%E6%87%82%E4%BA%8C%E6%AC%A1%E5%85%83%E5%90%97/</link>
      <pubDate>Sat, 16 Apr 2016 10:36:04 +0000</pubDate>
      
      <guid>https://moelove.info/2016/04/16/%E6%83%B3%E4%BB%8E%E4%BA%8C%E6%AC%A1%E5%85%83%E7%BE%A4%E4%BD%93%E6%89%8B%E9%87%8C%E8%B5%9A%E9%92%B1%E4%BD%A0%E7%9C%9F%E7%9A%84%E6%87%82%E4%BA%8C%E6%AC%A1%E5%85%83%E5%90%97/</guid>
      <description>“节操”，“鬼畜”，“萌”, &amp;ldquo;二次元&amp;rdquo;这些词是不是逐渐的融入了你的日常？ 这些词其实都是二次元产物。越来越多的人将关注点放到了“二次元群体”上，但是这里的价值和它真正的含义你懂了吗？
 什么是原本的二次元 很多人认为二次元就是指“二维平面”，“平面世界”，也有人认为是ACGN，但这个观点其实是带有误区的。
为什么这样说呢？我们一起来追溯一下“二次元”这个词是什么时候出现的，有部和我年龄相仿的动画片《机动战舰》(暴露年龄系列,我下一篇就写这个)，其中的反派们超级崇拜一部叫《激钢人3》的动画片，甚至这部动画片已经成为反派军中的圣典（除了很热血很好看外，其实是因为他们逃亡的时候就只带了这一部动画片吧，充分说明做资源党是有好处的！），当然剧中的主角也是很喜欢这部动画片的。动画（机动战舰）中的反派非常喜欢激钢人3中的女主菜菜子，但是毕竟现实和动画是不可逾越的（明明都是在动画里面！），处于伤感中的反派们相互安慰：“菜菜子再好，但她毕竟只是二次元的女子啊！”，这句话引起了很多ACG爱好者的共鸣，所以逐步的借用了其中的“二次元”来描述自己所喜爱的由ACG创造出来的世界了。
什么是现在的二次元 很多人说现在的二次元是“泛二次元”，可这个”泛“到底是泛到了什么程度呢？这就好像从15年开始，”IP“在圈子里吵得火热，但到底什么是IP？很多人只是知道一个名词或者一个模糊的概念罢了。 有多少真正爆款的IP产生呢？
现在一般指的二次元确实是”泛二次元“，不仅包含着ACGN，还包含着其相关的衍生产物（这不是废话吗？）。也就是这种模棱两可的概念让绝大多数人身处次元壁外，不得其门而入。
为了避免概念混淆，本篇不具体解释“核心二次元文化”和“泛二次元文化”（放到下篇来写），谈谈现在的二次元群体即“泛二次元”群体。
&amp;ldquo;宅&amp;rdquo; 大多数情况下，ACG爱好者被冠上了“宅”的标签，外界一般这样看我们“不爱出门”，“就知道看动漫”，“沉迷于虚拟世界”等等。实际上“宅”也分了很多种，“御宅族”应该是相对较早的称呼了，现在大多使用“宅男/宅女”来形容这部分人和长期待在家里不出去的人。并且基于当前环境和舆论等，“宅”一度被加上了变异的色彩。
但是当二次元群体以“宅”自称或称呼别人的时候，一般是指对于某种兴趣爱好的痴迷，有时候也指大触（某方面很厉害的人）。这种倾注了情感的痴迷，不仅支撑着我们可以长时间宅在家，还可以不断的利用现有资源，发展自己的圈子和技能，结识同好，分享兴趣，一起做很多好玩的事情。一般会被称为“动漫宅”，“偶像宅”，“技术宅”等，也会称为“游戏狗”，“单身汪”之类的。（但是我们都有着做现充的觉悟的！）
“腐” 这个群体中女性相比男性更多一些（目前表现出来的是这样），这个群体多表现为对“BL”（boy’s love），“GL”（girl’s love）等的喜爱。“腐”和“宅”并不能完全隔离开，会有重合，不过“宅”群体一般更多的关注点在于虚拟世界中，而很可能一个并不宅的妹子有天你突然发现她其实是腐的，并且长期YY你和其他男同事（orz）。
“Coser”，“lo娘”，“舞见” 作为一枚野生后期，对这部分群体和我接下来要谈的“唱见”等了解也相对多了一些。Coser（玩Cosplay 的人），lo娘（喜欢Lolita穿衣风格的人），舞见（一般指宅舞的舞者）都逐渐变多，这也和大众对这个群体的接受度逐渐变高了有关。这个群体相对的要辛苦一些，喜欢某些东西，喜欢到了不满足于看，而想自己亲自去尝试。
Coser需要经过服装，道具，化妆等工序打磨，而一般在网上直接买的衣服可能不合适还需要自行修改。这三类人都很容易被外界的人投以另类的目光，但是也比较容易通过活动或者交流找到同好。毕竟这些都是既看脸又走心的形式，既传达自己对原作的感情又能将自己美好的一面示人。
&amp;ldquo;唱见&amp;rdquo; “唱见”（投稿翻唱歌曲的业余歌手）也越来越多，而且很多也唱的非常棒！以动漫的OP，ED投稿较多，目前有很多的应用或网站都提供了方便的音频发布，电台之类的功能，比较容易获得粉丝。
&amp;ldquo;网配&amp;rdquo; “网配”（网络配音）大多是基于网配文或某些小说进行PIA戏，也有一部分人会选择制作广播剧之类的。
其他 其他就是一部分我不常接触或者人数相对较少的群体了。
为什么是二次元群体 在大致了解了当前二次元群体之后，我们来谈谈为什么从二次元群体入手
 群体基数大，覆盖面广。在上面我已经大致说过了，看看自己的周围，随便上微博、贴吧之类的看看，大抵就知道了; 增长迅速。看看当前A、B站，腾讯动漫等的用户增长量也可窥一斑; 付费能力强。只要戳中了二次元群体的G点，付费能力非常强，以Coser和lo娘为例，一般都会花上万块在服装上; 自我传播能力较强。二次元群体大多活跃在手Q，微博，贴吧等平台上，且有自己的圈子，自我传播能力相对更强; 用户相对忠实。由于二次元文化作为一个独特的亚文化发展起来，当前占据主体的还是90后，00后，碎片化时间相对较多，且更容易在应用/网站中形成关系链; 二次元作品相对可扩展的面更广，更容易找到增长点。  可能发展的方向 资源平台 二次元群体本就对资源有非常高的渴望和期待，当然也很挑剔，有着很完整的选择要求，用资源吸引到用户，才是解决了用户的需求。
周边产业 二次元群体对于正版周边产物是有着强烈需求的，但是目前无论是市场还是价格上都不是很好。
同人 同人资源对二次元文化的发展是有着相当大影响的，若能吸引到用户，将可能迎来爆发式的增长。
以上都是我一本正经的胡说八道，小心误入歧途 2333</description>
    </item>
    
    <item>
      <title>2015小回顾</title>
      <link>https://moelove.info/2015/12/31/2015%E5%B0%8F%E5%9B%9E%E9%A1%BE/</link>
      <pubDate>Thu, 31 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://moelove.info/2015/12/31/2015%E5%B0%8F%E5%9B%9E%E9%A1%BE/</guid>
      <description> 时间过得很快2015年最后一天。 还是继续给自己做个总结吧。 去年也有做总结，不过没有发布到Blog罢了。
2015年初在公司定了两个主要目标:
 对工具的打磨 计算机图形学  第一个目标算是基本完成，现在在用的工具都很顺手，效率能提升很多，而且用起来也很爽！现在也还会再尝试一些其他的工具，或者提升现在使用的工具的便利性。有时间的话可以写篇文章介绍一下。第二个目标目前没有什么进展，可以考虑是不是要留到今年了XD，当然还有一些其他自己定的目标基本完成，大致写写自己的收获好了。
收获 (大致按照时间来写吧)
 读了一部分 Nginx 的源码，算是对Nginx有了比以前更深入的认识，但是现在回过头来再重新审视的话，发现对它的理解还远远不够，还需要继续深入。 学习了 Haskell, Haskell我觉得是一门非常棒的语言，非常值得学习，通过对这门语言的学习，改变了我的一些思维方式。除了用它写过一些小程序以外，还没能在工程中大量使用，今后继续加油，尽量引入到工程中～ 学习了 Node.js, 同样的还缺乏工程中的实践 学习了 Backbone.js,AngularJS 和 ReactJS. Backbone记忆中应该是5月份左右学习的，ReactJS要晚很多。写Backbone的时候想起来了之前用过的Riot, 轻量，随意，但是要写完整的应用相比AngularJS之类的要写很多代码。 开源了qyweixin和一个HTTPmultipart的库，下载量各自也都已经几千了，上次在评论中也看到确实有人在使用～ 还是蛮开心的啦！ 学会了使用 Docker，也准备学习一些内部机制之类的东西。 还在翻译中的Tornado 4.3文档也会尽快抽时间翻译完成的. 此外还有学习了Lua和正在深入学习的Shell，还有一系列的框架和库, 正在用来写一些自己的小东西。 1383 Contributions. 运营了公众号 TheMoeLove  还有一些目前还无法放入*收获*这一项中的东西，在2016年尽量都再多积累一些。
另外，下面这部分也非常的重要！
 认识了很多好玩的小伙伴，从他们那里也学到了很多东西 工作中同事们都很好，感谢给予的帮助～  总结  学会拒绝。一些事情是可以容忍的，但是要遵守原则，也要考虑时间成本和效率问题。 学习和思考。这一年之间其实学到的东西也蛮多的，只不过有些东西没能在工程实践中应用，效果不是很明显。多思考，做个靠谱的人，尽量不在相同的地方摔倒两次。 多读书 尝试新东西 多深入一些。浅尝辄止不是应该有的状态。 合理安排追番时间 2333  </description>
    </item>
    
    <item>
      <title>JSLint,JSHint,ESLint对比和Vim配置</title>
      <link>https://moelove.info/2015/11/28/JSLintJSHintESLint%E5%AF%B9%E6%AF%94%E5%92%8CVim%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Sat, 28 Nov 2015 23:43:49 +0000</pubDate>
      
      <guid>https://moelove.info/2015/11/28/JSLintJSHintESLint%E5%AF%B9%E6%AF%94%E5%92%8CVim%E9%85%8D%E7%BD%AE/</guid>
      <description>最近在用React写项目，但是我的Vim配置之前并没有配置对JSX和ES6的支持，然后看着那堆报错各种不爽了，于是还是要继续折腾，顺便也增加了点知识，记录一下。
主流的JS Lint工具及介绍 JavaScript已经发展蛮长时间了，对应的Lint工具也是层出不穷，下面介绍一下比较主流的几个Lint工具(其实是我用过的几个XD)
JSLint JSLint是由Douglas Crockford开发的，可能是最早的JavaScript Lint工具了吧，它的名字来源于著名的C语言工具Lint。老道把他认为的非Good Parts的部分都报了warning，而且在它的文档中也提到了你应该欣然接受所有的JSLint的建议。最近看了下，老道还在持续更新着这个项目，而且官网上也有着一个在线的体验工具，可以尝试一下。对了，如果想要使用这个工具，建议看看老道在YouTube上关于JavaScript编程风格的视频，讲的还是很幽默的。
JSHint JSHint是由Anton Kovalyov基于JSLint的代码实现的开源项目，由于JSLint时期大多数人都在受JSLint压迫，JSHint相比较之下，更友好，也更容易配置，所以很快就发展了起来，也得到了众多IDE和编辑器的支持。但是，由于它是基于JSLint开发的，自然原有的一些问题它也继承下来了，比如不易扩展，不容易直接根据报错定位到具体的规则配置等，虽然之前好像是有过相关的讨论，但是现在仍然没有什么好的解决办法。好在它发展的不错，很多时候遇到的问题都可以在网上找到相关的解决方案，而且文档也是非常不错的。
ESLint ESLint是由Nicholas C. Zakas在2013年开始开发的，它的初衷就是为了能让开发者能自定义自己的linting rules，而且它提供了一套相当完善的插件机制，可以自由的扩展，动态加载配置规则，同时可以方便的根据报错定位到具体的规则配置。而且我比较喜欢它的一点是文档非常详细，可能这也是灵活所必须的吧。在这里还要提一点，ESLint最初并不是为了造一个重复的轮子，而是作者在实际使用中的需求没有能得到JSHint团队的回应，所以他就结合当时的JSHint和另一个代码风格的检查工具JSCS写出来了现在具备代码风格检查，自定义插件扩展功能的ESLint了。
JSLint，JSHint和ESLint的对比 这三个工具各有特色，我只是做一下对比，选择的话，看个人需求就好了。
JSLint 优点  配置是老道已经定好的，开箱即用。  不足  有限的配置选项，很多规则不能禁用 规范严格，凡是不符合老道所认为的好的风格的，都会有警告(这一项就看你是否完全认同老道了) 扩展性差 无法根据错误定位到对应的规则  JSHint 优点  有了很多参数可以配置 支持配置文件，方便使用 支持了一些常用类库 支持了基本的ES6  不足  不支持自定义规则 无法根据错误定位到对应的规则  ESLint 优点  默认规则里面包含了JSLint和JSHint的规则，易于迁移(这肯定是故意的XD) 可配置为警告和错误两个等级，或者直接禁用掉 支持插件扩展 可以自定义规则 可以根据错误定位到对应的规则 支持ES6 唯一一个支持JSX的工具  不足  需要进行一些自定义配置(因为太灵活了嘛，不过文档是很详细的) 慢 (它比其他两个都要慢)  Vim支持 我们都使用Syntastic来配置
JSLint的Vim配置 有一个jslint.vim当然版本太老了。。我们不用这种方式做。
 安装jslint  sudo npm install jslint -g   在vimrc中添加如下配置  let g:syntastic_javascript_checkers = [&#39;jslint&#39;]   JSHint的Vim配置  安装jshint</description>
    </item>
    
    <item>
      <title>用正确的姿势开源Python项目</title>
      <link>https://moelove.info/2015/10/26/%E7%94%A8%E6%AD%A3%E7%A1%AE%E7%9A%84%E5%A7%BF%E5%8A%BF%E5%BC%80%E6%BA%90Python%E9%A1%B9%E7%9B%AE/</link>
      <pubDate>Mon, 26 Oct 2015 22:17:36 +0000</pubDate>
      
      <guid>https://moelove.info/2015/10/26/%E7%94%A8%E6%AD%A3%E7%A1%AE%E7%9A%84%E5%A7%BF%E5%8A%BF%E5%BC%80%E6%BA%90Python%E9%A1%B9%E7%9B%AE/</guid>
      <description>做个备忘，也希望可以帮到别人。
 目录结构（初始化） 一般我们都会选择在项目的顶层包含较基础的文件，比如setup.py，requirements，README等文件。 一般情况下，一个预发布的Python项目中应该包含以下几类文件：
 projects (项目的主体文件) setup.py requirements Readme (项目说明) docs (项目文档) test  其中，projects文件夹要以项目命名，存放实际的Python Package. 这里放一个我的项目的目录作为例子。
➜ httpmultipart git:(master) tree -L 2 . ├── build │ ├── bdist.linux-x86_64 │ └── lib.linux-x86_64-2.7 ├── dist │ ├── httpmultipart-0.1.0-py2.py3-none-any.whl │ └── httpmultipart-0.1.0.tar.gz ├── docs │ ├── _build │ ├── conf.py │ ├── index.rst │ ├── Makefile │ ├── userguide │ └── userguide.rst ├── env │ ├── bin │ ├── include │ ├── lib │ └── local ├── httpmultipart │ ├── __init__.</description>
    </item>
    
    <item>
      <title>对监控系统的思考</title>
      <link>https://moelove.info/2015/10/16/%E5%AF%B9%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%80%9D%E8%80%83/</link>
      <pubDate>Fri, 16 Oct 2015 00:59:01 +0000</pubDate>
      
      <guid>https://moelove.info/2015/10/16/%E5%AF%B9%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%80%9D%E8%80%83/</guid>
      <description>近期在做运维监控方面的事情，也研究了一下其他人是如何做的。把自己的想法做个总结记录一下吧。
 监控期望的目标  及时发现   需要的是即时监控并报警
  及时定位   定位问题要分开讲
 运维层面 &amp;gt; 是机器硬件问题还是上面运行的基础服务的问题，或者是新上线代码的问题，需要回滚。
 代码层面 &amp;gt; 在发生问题的时候，优先解决问题。定位代码问题提交hotfix 可以在解决问题之后做。
    及时处理 提前预测（尽量减少问题的发生）   提前预测可以做的事情有很多，数据挖掘/分析之类的。当然有个更简单的方法，就是先小范围上线，进行监控。如果发现出问题了，就停止上线，进行回滚。（我们现在就是这样做的，虽然原因并不是这个 2333
 监控遇到的主要问题  监控指标多   服务器CPU,内存，网络等的指标，基础服务Redis, MongoDB等的运行指标，对外服务的API是否正常工作，还有数据是否正确等。
  监控报警多   监控指标多的时候，自然报警也会相应增加，但是报警的分组与轻重缓急也是一个很麻烦的问题。还有就是部署着不同服务的机器，触发报警时候的指标也不好确定。
  报警多而且有关联，如何查找原因   可能同时会有多个指标触发了报警，但是要定位问题的时候，如何可以快速的定位问题。
 多维度数据监控  这个话题太大(要感谢Baidu的颜大大的指点）
 数据监控符合二八原则,重要数据需要多角度进行观察，需要有meta管理，需要动态简单配置。选择 好的，合理的数据模型可以有效的进行处理。
 数据采集部分，在单机器做聚合;命名上使用正则格式化;完善的配置功能，支持数据流自定义维度。
    对开源系统的使用，需要按照自己的实际情况进行适配。保证高可用性  先写这些吧，之后有时间再写，还有QCon上对运维监控上的一些分享也非常值得思考</description>
    </item>
    
    <item>
      <title>Open-Falcon监控系统部署</title>
      <link>https://moelove.info/2015/10/13/Open-Falcon%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Tue, 13 Oct 2015 21:01:00 +0000</pubDate>
      
      <guid>https://moelove.info/2015/10/13/Open-Falcon%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2/</guid>
      <description>本文并不分析Open-Falcon的架构或者选用它的原因，官方的文档在这里，虽然还不够完善。不过这也是我写这篇的原因，官方文档并没能把整个部署过程连在一起，而且个别地方有点问题。我在这篇文章中就不介绍各个组件的作用和功能了，只是单纯的介绍如何从零部署。
 安装 下载   wget https://github.com/XiaoMi/open-falcon/releases/download/0.0.5/open-falcon-0.0.5.tar.gz -O open-falcon.tar.gz   解压   mkdir tmp tar -zxvf open-falcon.tar.gz -C ./tmp   基础环境   sudo apt-get install redis-server sudo apt-get install mysql-server pip install virtualenv # 数据库初始化的代码来源于官方文档 git clone https://github.com/open-falcon/scripts.git cd scripts mysql -h localhost -u root -p &amp;lt; db_schema/graph-db-schema.sql mysql -h localhost -u root -p &amp;lt; db_schema/dashboard-db-schema.sql mysql -h localhost -u root -p &amp;lt; db_schema/portal-db-schema.</description>
    </item>
    
    <item>
      <title>源码编译MongoDB</title>
      <link>https://moelove.info/2015/09/13/%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91MongoDB/</link>
      <pubDate>Sun, 13 Sep 2015 21:28:43 +0000</pubDate>
      
      <guid>https://moelove.info/2015/09/13/%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91MongoDB/</guid>
      <description>上周放假正好有时间，编译安装了MongoDB，虽然MongoDB用了挺长时间的，但还是第一次用源码编译。在此做个备忘。因为已经完整编译安装过了，所以写起来的时候，就按照先知视角来写了～ 2333
 下载MongoDB源码 MongoDB的官网上是有已经编译好的二进制包的，这里选择clone MongoDB在github上的仓库
git clone https://github.com/mongodb/mongo &amp;amp;&amp;amp; cd mongo  在docs/building.md中是编译所需的依赖。 * A modern C++ compiler. One of the following is required. * GCC 4.8.2 or newer * Clang 3.4 (or Apple XCode 5.1.1 Clang) or newer * Visual Studio 2013 Update 2 or newer * Python 2.7 * SCons 2.3
我这台服务器是CentOS 6.5, 上面的gcc版本比较低，这里就先更新gcc咯.
gcc --version gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-16) Copyright © 2010 Free Software Foundation, Inc.</description>
    </item>
    
    <item>
      <title>重置Ghost博客的密码</title>
      <link>https://moelove.info/2015/07/21/%E9%87%8D%E7%BD%AEGhost%E5%8D%9A%E5%AE%A2%E7%9A%84%E5%AF%86%E7%A0%81/</link>
      <pubDate>Tue, 21 Jul 2015 23:11:04 +0000</pubDate>
      
      <guid>https://moelove.info/2015/07/21/%E9%87%8D%E7%BD%AEGhost%E5%8D%9A%E5%AE%A2%E7%9A%84%E5%AF%86%E7%A0%81/</guid>
      <description>  在搭建Ghost博客的时候，尚未配置mail服务器时，重置密码的方法做个记录
 打开数据库查看用户信息 如果全部默认设置，使用生产环境的话，应该是 sqlite3 content/data/ghost.db
如果是开发环境应该是 sqlite3 content/date/ghost-dev.db
查看用户信息 sqlite&amp;gt;SELECT * FROM users;
更新用户密码  Ghost对用户密码用的是BCrypt加密，可以使用BCrypt Hash Generator之类的工具生成一个想要修改的密码，例如&amp;rdquo;mypasswd&amp;rdquo;生成的密码是 $2a$10$QecJeBdw2lONRTnHJ0RoVO6DczdJWf4h4QgaUcgKsYFZlzTe1yeEK
 假设之前查看到的用户信息，邮箱是admin@domain.com 那么，使用这样更新密码
 UPDATE users SET password=&amp;quot;$2a$10$QecJeBdw2lONRTnHJ0RoVO6DczdJWf4h4QgaUcgKsYFZlzTe1yeEK&amp;quot; WHERE email=&amp;quot;admin@domain.com&amp;quot;  退出sqlite3 .exit
  </description>
    </item>
    
    <item>
      <title>3.17</title>
      <link>https://moelove.info/2015/03/17/3.17/</link>
      <pubDate>Tue, 17 Mar 2015 00:34:34 +0000</pubDate>
      
      <guid>https://moelove.info/2015/03/17/3.17/</guid>
      <description> 8小时内求生存 8小时外求发展 </description>
    </item>
    
    <item>
      <title>近况</title>
      <link>https://moelove.info/2014/10/16/%E8%BF%91%E5%86%B5/</link>
      <pubDate>Thu, 16 Oct 2014 23:34:39 +0000</pubDate>
      
      <guid>https://moelove.info/2014/10/16/%E8%BF%91%E5%86%B5/</guid>
      <description>  博客好长时间没有更新了，今天抽空大致来说一下近况吧
 工作 用这个标题的话，其实感觉想写的确实好多，但是还是挑一些比较重要的来说吧。现在的公司说实话还确实没有让我失望，工位上配的是一个 22寸的 AOC 显示器和一个24寸的 Dell 显示器， 主机内存 12G （我每天跑个Linux是有点浪费）办公区每天有物业定时打扫神马的，下午的时候有茶歇（茶水间还有一堆零食）。同事们相处感觉都很不错,每天中午一起出去吃饭，各种聊天调侃神马的，只是一开始不太了解项目中的配置神马的，让老大费心了&amp;hellip;
这段时间还有很多有趣的事情 比如： 去金海湾度假村团建之类的。 再说一下最近的感受吧。
因为国庆前需要上线，所以放假前就每天都是在忙着开发神马的。不过那两周也是近期感觉最爽的时候 写代码高潮不断 而且也确实感觉工作是蛮有挑战性的，确实是我想要的工作 :-) 。 不过我还记得那周一，一打开邮箱看到中有7份未读的需求邮件， 确实是略惊吓。 在开发的项目，因为改变了设计思路，所以这些天主要都是在写前端。只不过一开始的时候感觉略虐心啊， 写Python时间长了已经是不习惯其他语言那种书写规范了 一堆括号写的好烦躁 但是从这两天的感觉来看，得感谢老大的这种设计思路，这段时间学到的确实很多。 从框架到一些库，一些插件， 还有程序上一些比较巧妙的用法 正在努力消化中
生活 有点后悔加上标题了 其实主要要说的应该都放在这里吧。 从搬家后基本上每天生活都很规律，目前差不多适应了。(找工作和面试神马的我写到碎碎念里面了，具体的等半年或者一年后当回忆录来写 233)值得吐槽的就是电信的客服，用的是电信的网，前几天换了路由器忘记了密码，打客服重置密码，但是一直连接不成功（691错误，明显就是帐号密码的问题嘛）结果本来想到了周末放假的时候再好好处理，结果到了周末打电话却一直没有客服啊用联通号打电信的客服我也是醉了 最后到了周一才让客服又重置才成功。
其实那也是导致我这么久没有更新博客的原因orz 。 * 一个原因是因为电脑重装了系统，环境啥的一直没有配置 * 另一个就是因为网络坑爹，实在有心无力
再者就是帝都的天气让人确实有点无奈，有天早上刚下楼，我还以为我要迈步进入寂静岭了 TAT ，感觉能幸存下来确实是很不容易啊。
最后说一下最近在网络弄好之后，挖了一个坑。打算独立开发一个网站的说， 重复造轮子的原因和大多数人是一样的 ，现有的东西没有我想要的 正好把最近学到的东西都拿来练练手
 Try My Best !  </description>
    </item>
    
    <item>
      <title>正则匹配中文及字符编码问题</title>
      <link>https://moelove.info/2014/07/22/%E6%AD%A3%E5%88%99%E5%8C%B9%E9%85%8D%E4%B8%AD%E6%96%87%E5%8F%8A%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98/</link>
      <pubDate>Tue, 22 Jul 2014 21:16:34 +0000</pubDate>
      
      <guid>https://moelove.info/2014/07/22/%E6%AD%A3%E5%88%99%E5%8C%B9%E9%85%8D%E4%B8%AD%E6%96%87%E5%8F%8A%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98/</guid>
      <description>匹配中文的正则表达式 窝写了一小段代码（虽然写的不太好，但是基本可以表达意思）
-- import re nickname = raw_input(&#39;Please input your nickname &amp;gt; &#39;) if not re.search(u&#39;^[\u4e00-\u9fa5a-zA-Z0-9]+$&#39;, unicode(nickname,&#39;utf8&#39;)): print &#39;Your nickname format is error, please try again !&#39; else: print &#39;Hello %s&#39;% nickname  如你所见，上面第5行的代码，就是匹配中文和字母，数字的正则表达式了。里面的\u4e00-\u9fa5 就是中文汉字的unicode编码所在位置。
Python字符串的编码问题 还是以上面那段代码来说。注意看第5行的代码
if not re.search(u&#39;^[\u4e00-\u9fa5a-zA-Z0-9]+$&#39;, unicode(nickname,&#39;utf8&#39;)):  其实这样的代码并不严谨。因为在Python 中默认是用unicode编码来处理字符串的，因此做编码转换的时候，一般要以unicode作为中间编码，也就是说： 其他编码格式的字符串&amp;mdash;&amp;gt;解码(decode)&amp;mdash;&amp;gt;unicode&amp;mdash;&amp;gt;编码(encode)&amp;mdash;&amp;gt;所需要的编码格式。
因此，处理字符串编码的问题的时候，先要明白需要转换的字符串的编码格式是什么。
代码中字符串的默认编码格式与代码文件本身的编码格式是一样的 比如： s = &amp;lsquo;涛&amp;rsquo; 在utf8的文件中，那么s就是utf8编码的，但是如果文件是gb2312编码，那么s就是gb2312编码的。此时，如果想要处理s这个字符串就要先decode成unicode编码了。
不过如果是酱紫 s = u&amp;rsquo;涛&amp;rsquo;，那么s就是unicode编码了，这个时候s的编码方式不会被文件的编码所影响。
如果一个字符串已经是unicode编码了，再解码就会出错 因此严谨的方式就是先对字符串进行编码格式的判别，最简单的办法就是使用Python 默认提供的isinstance() 方法.
代码可以这样写 isinstance(s, unicode) 如果不是unicode编码就会报错。
窝今天在处理用户昵称的地方，忘记字符串会直接使用文件的编码了，所以对它进行了重新编码orz果断就报错了。。。以后还是要好好注意细节的说。</description>
    </item>
    
    <item>
      <title>Bash 显示 Git 分支</title>
      <link>https://moelove.info/2014/07/17/Bash-%E6%98%BE%E7%A4%BA-Git-%E5%88%86%E6%94%AF/</link>
      <pubDate>Thu, 17 Jul 2014 21:54:33 +0000</pubDate>
      
      <guid>https://moelove.info/2014/07/17/Bash-%E6%98%BE%E7%A4%BA-Git-%E5%88%86%E6%94%AF/</guid>
      <description> 虽然一直都在用git，但是并没有注意到还有这个方便的用法 于是乎赶快学习一下 ：-）
上网查了一下资料，都说Ubuntu下如何如何方便，其他的发行版需要先下载一个文件，然后添加source，再如何如何。。
其实查再多都不如实践。以下是窝经过查资料加上对个人bash的配色后写出的配置文件，加入到 ~/.bashrc 中即可（对各个发行版通用的）
function git_branch { ref=$(git symbolic-ref HEAD 2&amp;gt; /dev/null) || return; echo &amp;quot;(&amp;quot;${ref#refs/heads/}&amp;quot;) &amp;quot;; } PS1=&amp;quot;[\[\e[1;35m\]\u\[\e[1;32m\]\w\[\e[0m\]] \[\e[0m\]\[\e[1;36m\]\$(git_branch)\[\e[0;33m\]\$&amp;quot;  或者
function git-branch-name { git symbolic-ref HEAD 2&amp;gt;/dev/null | cut -d&amp;quot;/&amp;quot; -f 3 #git rev-parse --abbrev-ref HEAD } function git-branch-prompt { local branch=`git-branch-name` if [ $branch ]; then printf &amp;quot; [%s]&amp;quot; $branch; fi } PS1=&amp;quot;\u@\h \[\033[0;36m\]\W\[\033[0m\]\[\033[0;32m\]\$(git-branch-prompt)\[\033[0m\] \$ &amp;quot;  -- 按照惯例，上一张图 </description>
    </item>
    
    <item>
      <title>Grub2 rescue 修复</title>
      <link>https://moelove.info/2014/07/02/Grub2-rescue-%E4%BF%AE%E5%A4%8D/</link>
      <pubDate>Wed, 02 Jul 2014 21:53:03 +0000</pubDate>
      
      <guid>https://moelove.info/2014/07/02/Grub2-rescue-%E4%BF%AE%E5%A4%8D/</guid>
      <description>昨天下午的时候想要把分区处理一下，突然发现硬盘里面有一个未使用的102M的分区,很果断的把这些乱七八糟的分区都给干掉了。结果呢，再次开机的时候就坑了（虽然酱紫的事情干过很多次了，这次做个记录吧）开机时提示如下：
GRUB loading.. error: unknown filesystem. Entering rescue mode.... grub rescue&amp;gt;  grub rescue 支持的命令  ls 查看硬盘的分区情况，如果你已知自己的grub的安装位置（比如我的在(hd0,msdos9)/boot/grub2），那么就直接进行下一步。 如果不知道，那就ls每个分区，比如: ls (hd0,msdos2)/,如果正确就会显示里面到内容，直到找到grub  这里一个很关键的地方就是在硬盘位置后应该加入/
 set 直接输入的话， 可以看到root 和 prefix 的设置。这里需要把这两个选项改成我们已经找到的位置。  窝的设置如下
grub rescue&amp;gt; set grub rescue&amp;gt; prefix=(hd0,msdos9)/boot/grub2 grub rescue&amp;gt; root=hd0,msdos9   insmod 载入模块。这里区别是窝这次记录的关键。 grub2和grub的一个很重要的区别就是模块的位置。grub2的模块位置在/boot/grub2/i386-pc/normal.mod 执行命令：  grub rescue&amp;gt;insmod (hd0,msdos9)/boot/grub2/i386-pc/normal.mod  执行成功之后，提示符会变成normal
 normal 进入正常模式，直接输入命令即可  grub rescue&amp;gt;normal  这个时候，就可以看到熟悉的引导界面了。
 grub2-install 进入系统后执行命令  $ sudo update-grub $ sudo grub2-install /dev/sda  如果不执行这样的命令的话，重启之后还会回到之前的界面orz</description>
    </item>
    
    <item>
      <title>Linux中Sublime中文输入</title>
      <link>https://moelove.info/2014/06/19/Linux%E4%B8%ADSublime%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5/</link>
      <pubDate>Thu, 19 Jun 2014 23:17:31 +0000</pubDate>
      
      <guid>https://moelove.info/2014/06/19/Linux%E4%B8%ADSublime%E4%B8%AD%E6%96%87%E8%BE%93%E5%85%A5/</guid>
      <description>这篇只是为了备忘所以把以前写的东西搬这边了 -.-
 代码源于网络，感谢分享 这里的关键就是以下的代码和编译 /* sublime-imfix.c Use LD_PRELOAD to interpose some function to fix sublime input method support for linux. By Cjacker Huang &amp;lt;jianzhong.huang at i-soft.com.cn&amp;gt; gcc -shared -o libsublime-imfix.so sublime_imfix.c `pkg-config --libs --cflags gtk+-2.0` -fPIC LD_PRELOAD=./libsublime-imfix.so sublime_text */ #include &amp;lt;gtk/gtk.h&amp;gt; #include &amp;lt;gdk/gdkx.h&amp;gt; typedef GdkSegment GdkRegionBox; struct _GdkRegion { long size; long numRects; GdkRegionBox *rects; GdkRegionBox extents; }; GtkIMContext *local_context; void gdk_region_get_clipbox (const GdkRegion *region, GdkRectangle *rectangle) { g_return_if_fail (region !</description>
    </item>
    
    <item>
      <title>upyun-for-pelican</title>
      <link>https://moelove.info/2014/05/16/upyun-for-pelican/</link>
      <pubDate>Fri, 16 May 2014 21:51:41 +0000</pubDate>
      
      <guid>https://moelove.info/2014/05/16/upyun-for-pelican/</guid>
      <description>这几天写了一个插件，方便把pelican生成静态博客部署到又拍云上。 整体思路就是：
 先格式化路径，以/为根目录
def formatPath(path): path = path.replace(os.sep, &#39;/&#39;) return path  定义两个列表来存储文件和目录
  之后就是验证用户，以及bucketname 之类的了。
简介 pelican 是一款基于python的静态博客生成工具，本程序可以方便的把生成的静态博客部署到又拍云上。演示地址：upyun-for-pelican 
生成网站  make html make serve (进行本地预览)  说明  程序使用了又拍云的官方SDK 需要先安装 upyun
pip install upyun  可以自定义要上传的文件目录。在最下方的local_dir 中指定即可。Pelican默认的上传目录是 output 目录
  使用  可以在 pelicanconf.py 文件中直接设置 BUCKETNAME, USERNAME, PASSWORD 参数（这些参数的使用大写命名格式也是为了符合*pelicanconf.py*中的习惯），也可以直接在 upyun-for-pelican.py文件的最下方直接设置。
 执行
python upyun-for-pelican.py  程序在 Python 2.7 环境下测试通过。
  其他说明  程序执行开始会有上传确认提示，输入Y / y 都可以继续上传。 可以使用项目中的pelicanconf.</description>
    </item>
    
    <item>
      <title>使用Pelican搭建Blog</title>
      <link>https://moelove.info/2014/05/07/%E4%BD%BF%E7%94%A8Pelican%E6%90%AD%E5%BB%BABlog/</link>
      <pubDate>Wed, 07 May 2014 21:48:59 +0000</pubDate>
      
      <guid>https://moelove.info/2014/05/07/%E4%BD%BF%E7%94%A8Pelican%E6%90%AD%E5%BB%BABlog/</guid>
      <description>安装配置Pelican 使用环境：  系统 : Linux X86_64 Pelican : 3.3.0  首先说一下安装： 网上有不少建议说使用虚拟环境 virtualenv，以免污染本地的环境。不过，如果不是去更改Python的全局设置的话，也不至于影响本地环境的。我是直接安装的。根据 Pelican 官方的文档，我是使用 pip 安装的，不过pip又是依赖于distribute 安装的。所以，我使用的命令如下：
 curl -O http://python-distribute.org/distribute_setup.py sudo python distribute_setup.py curl -O https://raw.github.com/pypa/pip/master/contrib/get-pip.py sudo python get-pip.py sudo pip install pelican  还有，如果要用 Markdown来写文章，也需要执行如下命令：
 pip install markdown  新建一个目录，用来存放你的博客文件（我直接建立了&amp;rdquo;blog&amp;rdquo;文件夹）
 mkdir blog cd blog  新建博客： 使用如下命令：
 pelican-quickstart  按照提示一步步即可完成新建， 这些配置之后可以在pelicanconf.py这个文件中修改
 Where do you want to create your new web site?[.] (你想在哪里创建你的网站，默认为当前目录) What will be the title of this web site?</description>
    </item>
    
    <item>
      <title>Hello World !</title>
      <link>https://moelove.info/2014/04/18/Hello-World-/</link>
      <pubDate>Fri, 18 Apr 2014 21:46:06 +0000</pubDate>
      
      <guid>https://moelove.info/2014/04/18/Hello-World-/</guid>
      <description> 几乎所有的程序猿的第一个演示程序都是Hello World .那我也就一样咯， 也写一个同样的吧。 其实我的博客从很早前就已经开始在写了， 换了很多的平台：
 从腾讯空间--&amp;gt; 百度空间--&amp;gt; 新浪博客--&amp;gt; 自己搭建的Wordpress博客--&amp;gt; 点点（点点我其实是用来碎碎念的） --&amp;gt; 博客园（个人感觉体验不是很好的说）--&amp;gt; 静态博客  选择了这么多，我最后决定还是使用 静态博客 来做个人博客。
 原因有以下几个：
  使用其他平台提供的博客不是很爽， 可个性化的方面不是很多， 点点相对来说做的还是很不错的 不仅提供个性化定制而且还支持绑定个人域名之类的。但是其他网站就不是那么人性化了。 写博客总是需要贴代码的，但是除了WP外，其他的我不是很满意。 用静态博客方便备份，而且是本地编辑就可以了，在线编辑的，感觉会被束缚很多。 本人属于折腾党，喜欢可以个人定制的， 直到符合个人满意的程度为止。   接下来说说这次博客的安装：
  选择Pelica是因为我对Python 比较熟悉，之前尝试过用Jekyll 和 Octopress 搭建，都比较方便 尤其是Jekyll 用户很多，文档什么的都很多了。只不过我更喜欢Python 多一些（虽然我有用ROR开发过WEB应用程序） 因为如果有什么需要的话，我也可以自己来开发插件或者自己再尝试做一个系统。 Pelican 相对来说配置也很方便， 很简单， 虽然用户不是很多，但是基本上的问题也都可以解决的 Pelican 支持restructuredText和Markdown写文章，配置灵活，扩展性强。我用的是3.3.0。  </description>
    </item>
    
    <item>
      <title>Linux 安装Android 驱动</title>
      <link>https://moelove.info/2014/03/10/Linux-%E5%AE%89%E8%A3%85Android-%E9%A9%B1%E5%8A%A8/</link>
      <pubDate>Mon, 10 Mar 2014 21:44:06 +0000</pubDate>
      
      <guid>https://moelove.info/2014/03/10/Linux-%E5%AE%89%E8%A3%85Android-%E9%A9%B1%E5%8A%A8/</guid>
      <description>在Linux下非常适合做一些对Rom 的定制以及其他的一些操作，甚至是自己制作Rom 或者从源码编译Rom 也是OK的。
不过最开始的应该就是搭建开发环境了，我先从装驱动开始说（只是做个笔记而已）
 使用数据线连接手机，打开adb调试模式。(在Linux上搭建开发环境， 以及adb 命令之类的， 就自行搜索吧，如果哪天更新了 我会附上链接的)
 输入adb devices 查看设备 如果有机型的话就说明是已经有驱动了 如果没有显示的话， 就是说明需要进行驱动安装了。
  这个时候， lsusb 查看， 会看到下面这样的信息
[tao@localhost ~]$ lsusb Bus 001 Device 002: ID 8087:0020 Intel Corp. Integrated Rate Matching Hub Bus 002 Device 002: ID 8087:0020 Intel Corp. Integrated Rate Matching Hub Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub Bus 002 Device 001: ID 1d6b:0002 Linux Foundation 2.</description>
    </item>
    
    <item>
      <title>fedora 18 Kernel driver not installed (rc=-1908)处理办法</title>
      <link>https://moelove.info/2013/12/21/fedora-18-Kernel-driver-not-installed-rc-1908%E5%A4%84%E7%90%86%E5%8A%9E%E6%B3%95/</link>
      <pubDate>Sat, 21 Dec 2013 21:42:18 +0000</pubDate>
      
      <guid>https://moelove.info/2013/12/21/fedora-18-Kernel-driver-not-installed-rc-1908%E5%A4%84%E7%90%86%E5%8A%9E%E6%B3%95/</guid>
      <description>fedora 18 升级内核之后 使用VirtualBox 可以正常打开软件,但是不能启动虚拟机系统.提示信息如下: Kernel driver not installed (rc=-1908)  经过一系列的看文档还有google 之后,很多地方写着这个问题的处理方法是
 第一种  sudo /etc/init.d/vboxdrv setup   经过实验,对feora 18 不可行
 第二种
sudo apt-get install dkms sudo /etc/init.d/vboxdrv setup  但是情况继续
 第三种
sudo aptitude update sudo aptitude install dkms sudo /etc/init.d/vboxdrv setup   最后正确的解决方法应该是酱紫的  先看看系统的内核  uname -r  找对应的包
sudo yum search kmod-VirtualBox  然后安装和你系统内核对应的包
sudo yum install kmod-VirtualBox-XXXX  运行</description>
    </item>
    
    <item>
      <title>Ruby on Rails 环境</title>
      <link>https://moelove.info/2013/09/21/Ruby-on-Rails-%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Sat, 21 Sep 2013 21:39:55 +0000</pubDate>
      
      <guid>https://moelove.info/2013/09/21/Ruby-on-Rails-%E7%8E%AF%E5%A2%83/</guid>
      <description>就这次的尝试写一下自己的记录 安装ruby 和 ruby-devel(安装ruby-devel是因为后续的工作如果没有ruby-devel的话，会报错)
sudo yum install ruby ruby-devel rubygems sqlite -y  需要的环境有了，那么就可以开始正式的工作了
sudo gem install rails  找到一个合适的目录来放自己的代码.然后执行
$ rails new mysite // 这个是建立一个叫mysite 的rails程式 ，在当前目录下面 $ cd mysite //进入这个目录 $ bundle install //因为在做测试 所以 也没有必要安装其他的gem  接下来看看它的数据库 配置文件是 config/database.yml 默认的支持是是SQLite3(当然也支持其他的比如mysql之类的)它有三种模式:
 development environment开发模式，用在你的开发的时候 test environment测试模式，用在自动测试时 production environment正式上线模式，用在实际的上线运作环境  SQLite配置大致是这样的:
development: adapter: sqlite3 database: db/development.sqlite3 pool: 5 timeout: 5000  接下来建立自己的数据库
rake db:create  在这里我遇到一个错误
rake aborted! Could not find a JavaScript runtime.</description>
    </item>
    
    <item>
      <title>利用百度BAE搭建discuz论坛</title>
      <link>https://moelove.info/2013/09/06/%E5%88%A9%E7%94%A8%E7%99%BE%E5%BA%A6BAE%E6%90%AD%E5%BB%BAdiscuz%E8%AE%BA%E5%9D%9B/</link>
      <pubDate>Fri, 06 Sep 2013 21:38:39 +0000</pubDate>
      
      <guid>https://moelove.info/2013/09/06/%E5%88%A9%E7%94%A8%E7%99%BE%E5%BA%A6BAE%E6%90%AD%E5%BB%BAdiscuz%E8%AE%BA%E5%9D%9B/</guid>
      <description>最近尝试了利用百度云应用管理*BAE*搭建discuz论坛， 这里做简要记录
创建应用 在 百度开发者中心 创建一个应用，选择WEB应用下的PC Iframe应用
托管设置 之后进行托管设置， 确定域名XXX.duapp.com
创建一个版本，并上传PHP代码包
(BAE有些函数规则发生改变，所以需要使用为BAE环境做过调整的discuz for BAE 版本)
需要注意的是在上传的代码包里面的 bcs/config.php 中的内容应该修改为
&amp;lt;?php define(&#39;BAIDU_BCS_BUCKET&#39;, &#39;创建的bucket名称&#39;); define(&#39;BAIDU_BCS_AK&#39;, getenv(&#39;HTTP_BAE_ENV_AK&#39;)); define(&#39;BAIDU_BCS_SK&#39;, getenv(&#39;HTTP_BAE_ENV_SK&#39;)); ?&amp;gt;  同时在数据库中设置为UTF-8,
注意开启缓存 cache 最少30M(亲测50M完全是OK的)
安装 之后上线应用，访问http://你的域名.duapp.com/install/index.php
即可完成安装(需要用到创建的数据库名称)</description>
    </item>
    
    <item>
      <title>fedora下安装sublime text 2的方法</title>
      <link>https://moelove.info/2013/08/30/fedora%E4%B8%8B%E5%AE%89%E8%A3%85sublime-text-2%E7%9A%84%E6%96%B9%E6%B3%95/</link>
      <pubDate>Fri, 30 Aug 2013 21:36:09 +0000</pubDate>
      
      <guid>https://moelove.info/2013/08/30/fedora%E4%B8%8B%E5%AE%89%E8%A3%85sublime-text-2%E7%9A%84%E6%96%B9%E6%B3%95/</guid>
      <description>首先去官网下载最新的压缩包  把文件解压到$HOME/.sublime_text_2文件夹中：
tar -xf (sublime压缩包的文件名).tar.bz2 sudo mv (解压后的文件夹) tools/Sublime_Text_2  在/usr/bin目录下面创建一个链接
vim sublime  在文件中写入这些代码： ``` #!/bin/bash export SUBLIME_HOME=&amp;rdquo;~/tools/Sublime_Text_2&amp;rdquo;
  $SUBLIME_HOME/sublime_text $*
修改文件权限并且移动  chmod 555 sublime &amp;amp;&amp;amp; mv sublime /usr/bin/sublime ```
这样就可以在终端中直接执行sublime了</description>
    </item>
    
    <item>
      <title>Vim7.3 for Windows 配置</title>
      <link>https://moelove.info/2013/08/10/Vim7.3-for-Windows-%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Sat, 10 Aug 2013 21:34:17 +0000</pubDate>
      
      <guid>https://moelove.info/2013/08/10/Vim7.3-for-Windows-%E9%85%8D%E7%BD%AE/</guid>
      <description>一直是在Linux下用Vim，但是有些时候在别人电脑或者机房又不得不用windows来写代码，所以也就下载了vim for windows。但是今天打开一个朋友写的网页的时候，出现了乱码的问题，所以把解决方法记录一下，也就是和在linux下面一样，修改配置文件就可以了。接下来进入正题。
 选项意义概述 Vim有四个跟字符编码方式有关的选项，分别是:encoding、fileencoding、fileencodings、termencoding (这些选项可能的取值可以参考 Vim 的帮助 :help encoding-names)，它们各自的意义:
 encoding: Vim 内部使用的字符编码方式，包括Vim的buffer(缓冲区)、菜单文本、消息文本等。用户手册上建议只在*.vimrc中改变它的值，事实上似乎也只有在.vimrc* 中改变它的值才有意义。
 fileencoding: Vim 中当前编辑的文件的字符编码方式，Vim 保存文件时也会将文件保存为这种字符编码方式 (不管是否新文件都如此)。
 fileencodings: Vim 启动时会按照它所列出的字符编码方式逐一探测即将打开的文件的字符编码方式，并且将 fileencoding 设置为最终探测到的字符编码方式。因此最好将 Unicode 编码方式放到这个列表的最前面，将拉丁语系编码方式 latin1 放到最后面。
 termencoding: Vim 所工作的终端 (或者 Windows 的 Console 窗口) 的字符编码方式。这个选项在 Windows 下对我们常用的 GUI 模式的 gVim 无效，而对 Console 模式的 Vim 而言就是Windows控制台的代码页，并且通常我们不需要改变它。（我尝试改变了它为UTF-8，但对于console模式的编码方式却没有改变）
  配置说明 由于 Unicode 能包含几乎所有的语言的字符，Unicode的UTF-8编码方式又是非常具有性价比和通用的编码方式，所以把*encoding*的值设置为utf-8。同时将encoding设置为utf-8时，Vim自动探测文件的编码方式会更准确。在中文Windows里编辑的文件，为了兼顾与其他软件的兼容性，文件编码还是设置为GB2312/GBK比较合适，因此*fileencoding*建议设置为chinese (chinese是个别名，在Unix里表示gb2312，在Windows里表示cp936，也就是GBK的代码页)。
具体配置 最后对于文件中显示乱码、菜单乱码、右键菜单乱码以及Conlse输出乱码问题的解决方案，修改Vim编辑器所对应的配置文件_vimrc（这个文件在你安装vim 的那个目录下），添加如下配置：
 关于常规设置：
&amp;quot;总是显示标签。0：不显示；1：多于1个时显示&amp;quot; set showtabline=2 &amp;quot;开启行号&amp;quot; set number &amp;quot;开启自动缩进, 7.</description>
    </item>
    
    <item>
      <title>LAMP环境的快速搭建</title>
      <link>https://moelove.info/2013/08/07/LAMP%E7%8E%AF%E5%A2%83%E7%9A%84%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Wed, 07 Aug 2013 21:30:59 +0000</pubDate>
      
      <guid>https://moelove.info/2013/08/07/LAMP%E7%8E%AF%E5%A2%83%E7%9A%84%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA/</guid>
      <description>这是我在我的centos 吧专门写的教程帖，目的也就是为了让新手可以更快的搭建起来环境，而不是一直在门外徘徊。所以就搬过来了，时间神马的就按照原帖来吧。
 写在前面 本篇文章是面向linux新手，文中采用环境是*Win7+V-BOX*，配置过程用putty进行操作（个人习惯而已），linux系统使用CentOS6.3版本。CentOS的安装方法及虚拟机中网络配置请参阅centos吧精品帖【教程】最全centos 安装方法及内容详解。为了尽量一次性可以让读者完成LAMP环境的搭建，本次安装过程都采用yum包管理机制进行安装。当然生产环境下一般都是采用源码编译的。在近期我也会再出连载文，使用源码包进行LAMP环境的搭建，欢迎关注。如果有任何意见或者建议都可以到centos吧发帖询问。 Ps:本文LAMP = Linux + Apache + Mysql + PHP
安装过程（先确保你的系统网络正常或者搭建好了本地源） 1. 首先安装Apache，使用命令： sudo yum install httpd –y
2. 然后安装Mysql，使用命令 sudo yum install mysql mysql-server –y
3. 再安装php ，使用命令 sudo yum install php –y
4. 安装完毕之后启动apache. 使用 sudo service httpd start
启动成功了，我们访问一下，在浏览器的地址栏输入虚拟机IP。
好，这里遇到了我们的第一个问题， 无法访问 &amp;gt;* apache服务已经打开，但是却无法访问 这里很可能是iptables的防御规则导致的。
执行iptables –L查看所有的iptables的规则。
关于iptables的知识可以自行了解或者关注后续讲解 我们执行 sudo iptables –F 清除所有规则
接下来在浏览器输入虚拟机地址 ，我们看到如下：
我们已经访问成功了！
  当然在这里的时候也许还有人是访问不了的，可能是因为CentOS自带的SElinux机制影响的   我们执行getenforce命令来查看SElinux的状态，使用sudo setenforce 0来改变SElinux为*permission*状态。</description>
    </item>
    
    <item>
      <title>cat 命令研究</title>
      <link>https://moelove.info/2013/03/20/cat-%E5%91%BD%E4%BB%A4%E7%A0%94%E7%A9%B6/</link>
      <pubDate>Wed, 20 Mar 2013 21:24:20 +0000</pubDate>
      
      <guid>https://moelove.info/2013/03/20/cat-%E5%91%BD%E4%BB%A4%E7%A0%94%E7%A9%B6/</guid>
      <description>有人问我关于centos里面使用cat命令的问题，我在这里简单记录一下。 在linux下，cat应该是使用最频繁的命令之一了吧。
 cat命令在Linux作以下用途：  在屏幕上显示文本文件。 复制文本文件。 合并文本文件。 创建新的文本文件。  cat命令支持的语法如下： cat filename cat options filename cat file1 file2 cat file1 file2 &amp;gt; newcombinedfile  显示文件的内容： cat /tmp/test  上面的命令就是查看文件/tmp/test的内容，把内容输出到屏幕。 但是也可以使用
cat /tmp/test &amp;gt; /tmp/test2  使用上面的命令，可以把文件内容重定向到/tmp/test2文件中
串联文件： 串联文件是把文件内容一起输出，但是不会改变源文件的内容
cat /tmp/test1 /tmp/test2 /tmp/test3  以上命令会将/tmp 目录下的 test1 ,test2 ,test3 三个文件的内容一起输出，当然也可以使用重定向命令查看输出内容
cat /tmp/test1 /tmp/test2 /tmp/test3 &amp;gt;/tmp/testoutputs  重定向至/tmp 下的testoutputs 文件中
当然查看的时候可以配合管道命令使用
cat /tmp/test1 /tmp/test2 /tmp/test3 | less</description>
    </item>
    
    <item>
      <title>fedora安装后最初的事情</title>
      <link>https://moelove.info/2013/03/09/fedora%E5%AE%89%E8%A3%85%E5%90%8E%E6%9C%80%E5%88%9D%E7%9A%84%E4%BA%8B%E6%83%85/</link>
      <pubDate>Sat, 09 Mar 2013 21:21:14 +0000</pubDate>
      
      <guid>https://moelove.info/2013/03/09/fedora%E5%AE%89%E8%A3%85%E5%90%8E%E6%9C%80%E5%88%9D%E7%9A%84%E4%BA%8B%E6%83%85/</guid>
      <description> 更新源 sudo yum localinstall --nogpgcheck http://mirrors.163.com/rpmfusion/free/fedora/rpmfusion-free-release-stable.noarch.rpm http://mirrors.163.com/rpmfusion/nonfree/fedora/rpmfusion-nonfree-release-stable.noarch.rpm (这个是添加国内的软件源) sudo yum update  网络相关 firefox sudo yum install firefox  chrome / chromium 我本人比较习惯用chrome的 不过最近网络不是很稳定 先补充chromium 的安装方法吧
 chromium的安装 首先添加chromium的fedora源,将下载好的 .repo 文件移动到/etc/yum.repos.d/下， 执行
sudo yum install chromium  chrome的安装 从官网上下载chrome 的rpm包，或者从我的网盘下载对应的32位 或 64位 的rpm 包 执行
sudo rpm -ivh google-chrome.rpm   安装证书 sudo yum localinstall --nogpgcheck http://download1.rpmfusion.org/free/fedora/rpmfusion-free-release-branched.noarch.rpm http://download1.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-branched.noarch.rpm  压缩/解压软件 sudo yum install unrar sudo yum install p7zip  影音播放 sudo yum install gstreamer-plugins-good gstreamer-plugins-bad gstreamer-plugins-ugly libtunepimp-extras-freeworld xine-lib-extras-freeworld(安装音频解码器) sudo yum install ffmpeg ffmpeg-libs gstreamer-ffmpeg libmatroska xvidcore(安装视频解码器)  编辑器  vim  sudo yum install vim  Sublime Text 我也很喜欢因为运行速度快，而且免费。安装方法可以参考我的fedora下安装sublime text 2这篇文章。  </description>
    </item>
    
  </channel>
</rss>